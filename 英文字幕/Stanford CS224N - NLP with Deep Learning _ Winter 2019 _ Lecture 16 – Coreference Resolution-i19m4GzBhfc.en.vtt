WEBVTT
Kind: captions
Language: en

00:00:04.790 --> 00:00:09.660
Hi everybody, time to get started.

00:00:09.660 --> 00:00:18.755
Okay. Um, so, so today what we're gonna talk about is a topic that's, um,

00:00:18.755 --> 00:00:23.745
coreference resolution and I'll explain in just a minute what that is,

00:00:23.745 --> 00:00:27.060
um, but before getting on to that just a,

00:00:27.060 --> 00:00:29.565
uh, couple of words on the announcements.

00:00:29.565 --> 00:00:35.770
Um, so the TAs are feverishly working on getting homework five grades worked out,

00:00:35.770 --> 00:00:39.170
so we hope that we can deliver those to you, um,

00:00:39.170 --> 00:00:41.600
tomorrow just in case you're anxious to know

00:00:41.600 --> 00:00:44.750
them before you make your final decisions about things.

00:00:44.750 --> 00:00:48.290
And then, the other thing that you should be remembering

00:00:48.290 --> 00:00:52.580
is that the milestone for the final project is this Tuesday.

00:00:52.580 --> 00:00:55.780
Now, I will confess that even to me it seems like,

00:00:55.780 --> 00:00:58.925
"Boy, boy this milestone came around really quickly."

00:00:58.925 --> 00:01:01.680
So you probably feel that doubly, I realize.

00:01:01.680 --> 00:01:06.530
And so you know, I do apologize for that a little bit,

00:01:06.530 --> 00:01:11.435
but you know, really our hope was that we could actually use this to be helpful,

00:01:11.435 --> 00:01:15.050
and to give you feedback on what you're doing and suggestions,

00:01:15.050 --> 00:01:17.120
and it just really seemed like, well,

00:01:17.120 --> 00:01:19.880
the only chance in which we can kind of, um,

00:01:19.880 --> 00:01:23.900
turn around giving more feedback on the projects, um,

00:01:23.900 --> 00:01:28.825
before it goes into the final week of the quarter is if we can kind of get stuff,

00:01:28.825 --> 00:01:30.710
um, Tuesday, and hope to be then,

00:01:30.710 --> 00:01:32.810
sort of turning it around again by the end of the week.

00:01:32.810 --> 00:01:36.040
So the hope is to help you not to just,

00:01:36.040 --> 00:01:39.685
um, create obstacles and roadblocks in your life.

00:01:39.685 --> 00:01:44.420
Okay. So today what we're gonna do, um, is, uh,

00:01:44.420 --> 00:01:47.750
learn more about a linguistic topic for a change and learn

00:01:47.750 --> 00:01:51.920
some more stuff about what goes on in coreference resolution.

00:01:51.920 --> 00:01:54.185
So first of all, I'm gonna talk about the task,

00:01:54.185 --> 00:01:57.380
and then go on to some of the kinds of models that people,

00:01:57.380 --> 00:01:59.990
um, do for coreference resolution.

00:01:59.990 --> 00:02:03.035
So first of all, what is it?

00:02:03.035 --> 00:02:08.850
Um, so the idea of coreference resolution is what we do, which we have a text,

00:02:08.850 --> 00:02:13.175
"Barack Obama nominated Hillary Rodham Clinton as his Secretary of State on

00:02:13.175 --> 00:02:18.230
Monday," and this text like most texts are about entities,

00:02:18.230 --> 00:02:21.200
where entities are commonly human beings,

00:02:21.200 --> 00:02:26.000
but they can be other things like God saw talking giraffes or whatever it is.

00:02:26.000 --> 00:02:28.580
So it seems like we want to make,

00:02:28.580 --> 00:02:32.225
find where entities are mentioned.

00:02:32.225 --> 00:02:34.040
So my entities are mentioned,

00:02:34.040 --> 00:02:35.990
they're referred to as mentions.

00:02:35.990 --> 00:02:39.500
So things like Barack Obama and Secretary of State,

00:02:39.500 --> 00:02:43.265
he, her, they are mentions of entities.

00:02:43.265 --> 00:02:46.990
And then, when we talk about coreference resolution,

00:02:46.990 --> 00:02:50.270
the task that we're wanting to do is say,

00:02:50.270 --> 00:02:54.680
which of these mentions refer to the same entity,

00:02:54.680 --> 00:02:57.170
the same real thing in the world.

00:02:57.170 --> 00:03:02.330
So well, one entity that's mentioned in this text is Barack Obama,

00:03:02.330 --> 00:03:06.919
and then he's referred to later in the text as his and he,

00:03:06.919 --> 00:03:12.425
and so these three red noun phrases are all coreferent to each other.

00:03:12.425 --> 00:03:17.270
And that then, refers to this real-world entity.

00:03:17.270 --> 00:03:21.110
Um, and then, we have these references Hillary Rodham Clinton,

00:03:21.110 --> 00:03:22.700
Secretary of State, her,

00:03:22.700 --> 00:03:28.445
she, First Lady, they're all references to a different entity.

00:03:28.445 --> 00:03:31.520
And so they all refer to this person.

00:03:31.520 --> 00:03:34.390
And so those are examples of our coreference.

00:03:34.390 --> 00:03:40.745
Um, in a way this is triv- sort of seems obvious to a human being,

00:03:40.745 --> 00:03:42.635
um, looking at things, um,

00:03:42.635 --> 00:03:45.590
but it can actually be kind of tricky and hard.

00:03:45.590 --> 00:03:50.480
Um, so, um, I thought we could spend a few minutes doing

00:03:50.480 --> 00:03:55.655
interactive working out coreferents together so that you guys can,

00:03:55.655 --> 00:03:57.980
um, think about it all for a few minutes.

00:03:57.980 --> 00:04:01.010
Um, so here's part of a little story.

00:04:01.010 --> 00:04:04.270
Um, it's a story by Shruthi Rao called The Star.

00:04:04.270 --> 00:04:08.089
Um, now, I confess that since this is a CS class,

00:04:08.089 --> 00:04:10.250
um, not a literature class,

00:04:10.250 --> 00:04:11.840
I did a little bit of, um,

00:04:11.840 --> 00:04:15.049
helpful editing of this text to make it shorter,

00:04:15.049 --> 00:04:16.630
so I could fit more of,

00:04:16.630 --> 00:04:18.800
what was going on, um,

00:04:18.800 --> 00:04:22.145
onto the page, um, but, um,

00:04:22.145 --> 00:04:24.439
everything that is a sort of a linguistic

00:04:24.439 --> 00:04:27.300
[inaudible] is something that comes from the original text.

00:04:27.300 --> 00:04:31.605
Okay. So, um, in this text,

00:04:31.605 --> 00:04:36.400
um, who is the first entity that's mentioned?

00:04:37.970 --> 00:04:41.100
Vanaja, okay.

00:04:41.100 --> 00:04:42.570
Okay. So it's Vanaja.

00:04:42.570 --> 00:04:45.255
Now, where, let's do it forward.

00:04:45.255 --> 00:04:51.040
Where else is Vanaja mentioned in this text?

00:04:52.580 --> 00:04:54.720
Her son, right?

00:04:54.720 --> 00:04:56.460
So this her not the son,

00:04:56.460 --> 00:05:00.400
but this her is a reference of Vanaja, right?

00:05:05.120 --> 00:05:08.520
Um, she resigned.

00:05:08.520 --> 00:05:12.090
Okay. After that?

00:05:12.090 --> 00:05:15.810
She bought.

00:05:15.810 --> 00:05:17.535
Okay. So there's another she.

00:05:17.535 --> 00:05:20.205
Was there another reference before that?

00:05:20.205 --> 00:05:24.750
Herself, right? So herself is also a reference to Vanaja.

00:05:25.280 --> 00:05:27.770
Um, okay. So then, it's again,

00:05:27.770 --> 00:05:32.750
she made this, she, okay.

00:05:32.750 --> 00:05:33.980
So we've done Vanaja.

00:05:33.980 --> 00:05:36.140
Okay, that's a good start.

00:05:36.140 --> 00:05:40.270
Okay. So then, um, we've got Akhila.

00:05:40.270 --> 00:05:45.495
Okay. Um, where's Akhila next referred to?

00:05:45.495 --> 00:05:48.450
As Akhila. Okay, there we go.

00:05:48.450 --> 00:05:54.940
Um, are there other references, um, to Akhila?

00:05:58.280 --> 00:06:04.390
Maybe not. Okay. What's the next entity that's mentioned?

00:06:07.820 --> 00:06:10.200
Prajwal.

00:06:10.200 --> 00:06:15.150
Okay. So what other references are there to Prajwal?

00:06:19.060 --> 00:06:20.180
They.

00:06:20.180 --> 00:06:24.330
They? Okay. So here's a tricky one, right?

00:06:24.330 --> 00:06:26.430
So this they, I mean,

00:06:26.430 --> 00:06:29.020
who does that refer to?

00:06:30.440 --> 00:06:35.790
It occ- refers to Prajwal and Akash.

00:06:35.790 --> 00:06:40.500
Yeah, so this they refers both to Prajwal and this Akash.

00:06:40.500 --> 00:06:44.180
So that's, that's something that happens in human languages.

00:06:44.180 --> 00:06:46.790
This is referred to as split antecedents,

00:06:46.790 --> 00:06:49.220
where you have one thing that they,

00:06:49.220 --> 00:06:54.245
that's sort of referring to two distributed things that came before it.

00:06:54.245 --> 00:07:01.085
Um, so here's one of my first sad admissions of natural language processing technology.

00:07:01.085 --> 00:07:04.940
None of the NLP systems that we're gonna talk about later

00:07:04.940 --> 00:07:09.920
today or in general that have been built deal with split antecedents.

00:07:09.920 --> 00:07:13.790
They automatically lose as soon as there's split antecedents.

00:07:13.790 --> 00:07:15.435
Um, so that's a bit sad,

00:07:15.435 --> 00:07:17.300
um, but that's the state of technology.

00:07:17.300 --> 00:07:18.710
So it's something, um,

00:07:18.710 --> 00:07:20.390
we could still work to improve,

00:07:20.390 --> 00:07:26.030
but okay there's this sort of they that's kind of half Prajwal. Um, okay.

00:07:26.030 --> 00:07:29.195
So there's directly Prajwal here,

00:07:29.195 --> 00:07:36.580
but was there another place early in the text that Prajwal is effectively mentioned?

00:07:40.190 --> 00:07:46.565
Yeah. So Akhila's son is really another mention of Prajwal, right?

00:07:46.565 --> 00:07:52.590
Okay. Um, okay.

00:07:52.590 --> 00:07:56.130
Um, any other mentions of Prajwal? Maybe not.

00:07:56.130 --> 00:07:57.765
Okay. Then we go on.

00:07:57.765 --> 00:08:00.315
Okay. Who's the next entity?

00:08:00.315 --> 00:08:04.305
Akash. So we have Akash here,

00:08:04.305 --> 00:08:05.700
and that then again,

00:08:05.700 --> 00:08:09.150
we have that her son referring to Akash.

00:08:09.150 --> 00:08:12.435
Um, and here was Akash.

00:08:12.435 --> 00:08:17.530
Okay. What other, what other mentions of Akash are there?

00:08:20.450 --> 00:08:29.010
Okay so there's another Akash here, um, fourth him.

00:08:29.010 --> 00:08:35.340
Okay. Uh, there's another Akash.

00:08:35.340 --> 00:08:42.555
Okay, um, but, so, um, here.

00:08:42.555 --> 00:08:45.330
Okay. So are the obvious Akash's.

00:08:45.330 --> 00:08:47.760
There's sort of a tricky case here which

00:08:47.760 --> 00:08:50.280
you could wonder what the right treatment of this, right?

00:08:50.280 --> 00:08:55.800
You know, it's sort of says Akash was to be a tree, all right.

00:08:55.800 --> 00:09:00.195
So in some sense the tree is Akash.

00:09:00.195 --> 00:09:05.430
Um, so really in terms of reference in this story,

00:09:05.430 --> 00:09:09.990
the reference of the tree is the same as Akash.

00:09:09.990 --> 00:09:12.795
And you could think, um,

00:09:12.795 --> 00:09:16.440
that means you should treat the instances of,

00:09:16.440 --> 00:09:18.645
um, the tree, the,

00:09:18.645 --> 00:09:20.925
the instances here of the tree,

00:09:20.925 --> 00:09:25.500
and later on when the nicest tree right that really,

00:09:25.500 --> 00:09:28.215
that's sort of this Akash as well.

00:09:28.215 --> 00:09:30.255
That doesn't quite feel right,

00:09:30.255 --> 00:09:33.030
but this is something that comes up in coreference, right?

00:09:33.030 --> 00:09:38.145
So here we have a sort of a predictive construction um,

00:09:38.145 --> 00:09:39.770
with, you know, B.

00:09:39.770 --> 00:09:41.810
And when you set,

00:09:41.810 --> 00:09:46.760
when you have sentences such as like, um, you know,

00:09:46.760 --> 00:09:52.270
my child is the smartest kid in the class or something like that, in some sense,

00:09:52.270 --> 00:09:54.960
you're sort of saying that the smartest kid in

00:09:54.960 --> 00:09:58.560
the class has the same reference as my child.

00:09:58.560 --> 00:10:04.635
And some systems count links over that kind of predication,

00:10:04.635 --> 00:10:07.215
and say that is coreference whereas

00:10:07.215 --> 00:10:10.890
other ones don't and think that that's not quite reasonable.

00:10:10.890 --> 00:10:12.780
So different things go on.

00:10:12.780 --> 00:10:14.985
Okay. So, um, those,

00:10:14.985 --> 00:10:17.925
those are fair number of entities.

00:10:17.925 --> 00:10:23.025
I mean, so there are obviously lots of other things that are mentioned,

00:10:23.025 --> 00:10:25.440
um that sort of, um, right?

00:10:25.440 --> 00:10:27.660
So there's the local park, right,

00:10:27.660 --> 00:10:30.450
that's a mention of some entity.

00:10:30.450 --> 00:10:36.360
Um, there's, um, the school, um right?

00:10:36.360 --> 00:10:44.475
So there's this school here and so that the school is coreferent with pre,

00:10:44.475 --> 00:10:47.370
the preschool right here, right?

00:10:47.370 --> 00:10:49.380
Um, and then there's,

00:10:49.380 --> 00:10:52.155
um, again this sort of tricky one,

00:10:52.155 --> 00:10:56.090
of how to treat the naughty child Lord Krishna because,

00:10:56.090 --> 00:10:59.525
you know, in some sense Prajwal is representing that.

00:10:59.525 --> 00:11:02.510
And then there are lots of other entities that are mentioned, right?

00:11:02.510 --> 00:11:05.195
There's a t-shirt, and there's trousers,

00:11:05.195 --> 00:11:08.355
um, and, um, things like that.

00:11:08.355 --> 00:11:12.060
Another tricky thing that turns up here when you get later on into

00:11:12.060 --> 00:11:16.950
the story is you can have entities that have parts.

00:11:16.950 --> 00:11:19.425
So we not only have a tree,

00:11:19.425 --> 00:11:21.840
but that tree then has a lot of parts, right?

00:11:21.840 --> 00:11:23.370
So the tree has a trunk,

00:11:23.370 --> 00:11:25.169
and the tree has foliage,

00:11:25.169 --> 00:11:28.275
um, and things like that.

00:11:28.275 --> 00:11:31.170
And there are these red balls that are representing fruits, right?

00:11:31.170 --> 00:11:35.400
So there's a lot of stuff that's somehow connected together and somehow separate.

00:11:35.400 --> 00:11:39.330
And that sort of, that doesn't fit terribly well with the kind of models we

00:11:39.330 --> 00:11:43.425
use with coreference either because really we make our coreference,

00:11:43.425 --> 00:11:48.015
um, reference models basically out of this notion of entities.

00:11:48.015 --> 00:11:50.325
Um, but somehow there's this complexity that,

00:11:50.325 --> 00:11:52.290
you know, human beings have parts too, right?

00:11:52.290 --> 00:11:53.744
We have hands and faces,

00:11:53.744 --> 00:11:56.145
and we can't say, oh, that's a separate entity,

00:11:56.145 --> 00:11:59.895
but they're somehow in, um, involved with the other entity.

00:11:59.895 --> 00:12:04.740
Okay. Um, hope that's sort of useful to give some idea.

00:12:04.740 --> 00:12:07.665
Why is coreference resolution useful?

00:12:07.665 --> 00:12:11.895
Um, so there are all kinds of things that we'd like to do well

00:12:11.895 --> 00:12:16.379
in natural language processing that you really can't do well unless,

00:12:16.379 --> 00:12:19.845
uh, you know how to do coreference resolution.

00:12:19.845 --> 00:12:25.410
So anything that we want to do in terms of question-answering, summarization,

00:12:25.410 --> 00:12:28.500
extracting facts from texts or anything like that,

00:12:28.500 --> 00:12:32.985
there are places we are gonna fail unless we can do coreference resolution.

00:12:32.985 --> 00:12:35.025
Because if we're reading a piece of text,

00:12:35.025 --> 00:12:38.640
and it says he was born in 1961, um,

00:12:38.640 --> 00:12:41.610
we can get a fact out or answer a question,

00:12:41.610 --> 00:12:43.845
if we can work out who he was,

00:12:43.845 --> 00:12:46.780
but we probably can't otherwise.

00:12:49.040 --> 00:12:53.580
Um, there are, there's sort of another place that where

00:12:53.580 --> 00:12:57.480
this is very useful is in machine translation,

00:12:57.480 --> 00:13:02.130
so that lots of languages drop pronouns.

00:13:02.130 --> 00:13:04.935
So you don't have to give explicit pronouns,

00:13:04.935 --> 00:13:09.105
but you need to be able to work out how to fill them in.

00:13:09.105 --> 00:13:12.765
And this is making coreference decisions about,

00:13:12.765 --> 00:13:15.075
um, arguments of verbs.

00:13:15.075 --> 00:13:18.030
And so here are a couple of examples,

00:13:18.030 --> 00:13:22.545
um, that, um, covering from Spanish to English.

00:13:22.545 --> 00:13:27.660
So in Spanish, you can freely drop the subjects of verbs and in these sentences,

00:13:27.660 --> 00:13:29.520
in the because clause,

00:13:29.520 --> 00:13:31.725
there's no overt subject.

00:13:31.725 --> 00:13:35.625
And so he gets Alicia likes Juan because he's smart.

00:13:35.625 --> 00:13:40.620
And so Google Translate is stuck in a he and that is right.

00:13:40.620 --> 00:13:42.600
And to stick in that he,

00:13:42.600 --> 00:13:47.700
it's implicitly making a coreference decision and saying, "Okay well,

00:13:47.700 --> 00:13:49.605
the subject of this, um,

00:13:49.605 --> 00:13:54.224
adjective smart should be Juan who's male,

00:13:54.224 --> 00:13:56.985
and therefore, I should say he."

00:13:56.985 --> 00:14:00.060
But, you know, the reality is Google Translate knows

00:14:00.060 --> 00:14:03.615
nothing about coreference and making these coreference decisions.

00:14:03.615 --> 00:14:05.280
And as has been um,

00:14:05.280 --> 00:14:10.365
covered quite a bit in the media now and I think came up earlier in an earlier class,

00:14:10.365 --> 00:14:15.240
that, um, Google Translate mainly just defaults to male default.

00:14:15.240 --> 00:14:18.075
Um, so if you sort of swap- sweep it, uh,

00:14:18.075 --> 00:14:19.770
if you flip it around and say,

00:14:19.770 --> 00:14:23.370
Juan likes Alicia, it also says because he's smart.

00:14:23.370 --> 00:14:28.005
Uh, whereas probably it should be because she's smart in that case.

00:14:28.005 --> 00:14:31.755
And indeed you notice the bad effects of that everywhere.

00:14:31.755 --> 00:14:36.225
So many languages, um, Turkish, Indonesian, um,

00:14:36.225 --> 00:14:38.070
don't actually have gender,

00:14:38.070 --> 00:14:41.910
so that they're much less sexist languages than English,

00:14:41.910 --> 00:14:43.350
French or Germany is.

00:14:43.350 --> 00:14:45.495
But what happens, um,

00:14:45.495 --> 00:14:48.060
when you then translate where you just have

00:14:48.060 --> 00:14:52.275
a generic pronoun that means third person pronoun, um,

00:14:52.275 --> 00:14:56.460
that Google Translate is essentially using its language model,

00:14:56.460 --> 00:14:59.055
which means that reconstructs, um,

00:14:59.055 --> 00:15:01.635
the worst of stereotypes of she is a cook,

00:15:01.635 --> 00:15:03.855
and he is an engineer, he is a doctor.

00:15:03.855 --> 00:15:07.500
And well, in a connected piece of this course,

00:15:07.500 --> 00:15:10.905
if you'd like Google Translate to be able to do better than that,

00:15:10.905 --> 00:15:14.160
well again, what would be required is that you could actually do

00:15:14.160 --> 00:15:19.755
coreference resolution and track along the actors in the text as you go along.

00:15:19.755 --> 00:15:23.970
Um, one final example we haven't really talked about yet,

00:15:23.970 --> 00:15:27.480
but we'll get back to soon now because the class is almost over

00:15:27.480 --> 00:15:31.440
is doing things with dialogue agents or chat systems.

00:15:31.440 --> 00:15:36.240
That, as soon as you are going to do anything more than a single turn,

00:15:36.240 --> 00:15:39.840
um, dialog, that you need to start dealing with reference.

00:15:39.840 --> 00:15:41.655
So if you've got something like, um,

00:15:41.655 --> 00:15:44.115
booked tickets to see James Bond,

00:15:44.115 --> 00:15:46.200
um, then you want to say something like,

00:15:46.200 --> 00:15:49.050
"Spectre is playing near you at 2:00 and 3:00 today.

00:15:49.050 --> 00:15:51.030
How many tickets would you like?"

00:15:51.030 --> 00:15:54.270
Um, two tickets for the showing at three.

00:15:54.270 --> 00:15:56.265
That as shown in the color,

00:15:56.265 --> 00:16:02.340
there are various kinds of reference going on here where things have related reference,

00:16:02.340 --> 00:16:04.680
but it's kind of complicated here.

00:16:04.680 --> 00:16:07.470
And this is something that we'll come back to in a moment.

00:16:07.470 --> 00:16:13.035
So James Bond and Spectre aren't obviously the same thing,

00:16:13.035 --> 00:16:16.530
but in a context like, um, booking movies,

00:16:16.530 --> 00:16:23.460
they are the same thing because one is the name of a character in a movie series,

00:16:23.460 --> 00:16:28.530
and the other is the name of a movie that's currently showing that belongs to that,

00:16:28.530 --> 00:16:30.960
so that they're sort of associated, um,

00:16:30.960 --> 00:16:33.900
in a sort of subtle way that isn't exact identity,

00:16:33.900 --> 00:16:37.125
but is relevant to a lot of the things that we want to do.

00:16:37.125 --> 00:16:39.480
I'll come back to that in a little bit when we

00:16:39.480 --> 00:16:41.655
talk a bit more about the linguistics of this.

00:16:41.655 --> 00:16:45.760
Okay. So if we want to do the task of coreference resolution,

00:16:45.760 --> 00:16:47.660
there are essentially two steps.

00:16:47.660 --> 00:16:51.425
So the first step is gee, we want to work out

00:16:51.425 --> 00:16:55.835
what mentions there are in the text that we should be doing something with.

00:16:55.835 --> 00:16:58.640
And this one is effectively pretty easy,

00:16:58.640 --> 00:17:01.430
but I'll have just a few slides on that immediately.

00:17:01.430 --> 00:17:04.835
And then what the bulk of the class is gonna be on is,

00:17:04.835 --> 00:17:08.810
um, working out coreference between mentions.

00:17:08.810 --> 00:17:10.400
And if you think about this,

00:17:10.400 --> 00:17:13.355
coreference is essentially a clustering task.

00:17:13.355 --> 00:17:15.275
Because if you do the first task,

00:17:15.275 --> 00:17:18.770
you have a set of mentions and then you want to be saying well,

00:17:18.770 --> 00:17:22.710
how can I group these into clusters that have the same reference?

00:17:22.710 --> 00:17:25.750
And so that's what we're going to look more at doing.

00:17:25.750 --> 00:17:28.080
So quickly on mention detection.

00:17:28.080 --> 00:17:29.730
So, um, for mention,

00:17:29.730 --> 00:17:34.085
we wanna find all the spans that are candidates for,

00:17:34.085 --> 00:17:36.110
um, referring to some entity.

00:17:36.110 --> 00:17:38.725
And the answer to what these, um,

00:17:38.725 --> 00:17:43.620
candidates are is basically they're all the noun phrases in the text.

00:17:43.620 --> 00:17:48.125
And so normally people think of there being three types of mentions that we identify.

00:17:48.125 --> 00:17:49.730
There are pronouns, I,

00:17:49.730 --> 00:17:50.990
you, he, she, it,

00:17:50.990 --> 00:17:52.790
etc., that are, um,

00:17:52.790 --> 00:17:54.605
referring to different entities.

00:17:54.605 --> 00:17:57.170
They're explicit names of people like that was

00:17:57.170 --> 00:17:59.960
that Barack Obama and Hillary Clinton examples.

00:17:59.960 --> 00:18:02.210
And then many of the tricky examples,

00:18:02.210 --> 00:18:04.685
and then when we have common noun phrases

00:18:04.685 --> 00:18:07.670
like a dog or the big fluffy cat stuck in the tree.

00:18:07.670 --> 00:18:11.690
That the big fluffy cat stuck in the tree is a mention.

00:18:11.690 --> 00:18:14.405
Um, it's actually a complex mention because it

00:18:14.405 --> 00:18:17.975
also has embedded inside it other mentions.

00:18:17.975 --> 00:18:22.230
Um, so the tree is also a mention.

00:18:22.500 --> 00:18:26.560
Okay. So how can we detect mentions?

00:18:26.560 --> 00:18:28.180
Well, one answer is to say,

00:18:28.180 --> 00:18:30.055
well we've looked at, um,

00:18:30.055 --> 00:18:32.740
various other NLP systems on and off.

00:18:32.740 --> 00:18:39.250
And we can just use those NLP systems as preprocessing systems to find mentions.

00:18:39.250 --> 00:18:43.900
So for pronouns, they're part of speech taggers that say what's a noun,

00:18:43.900 --> 00:18:45.475
or a verb, or a pronoun,

00:18:45.475 --> 00:18:48.910
and so we can run those and find all the pronouns and we're done.

00:18:48.910 --> 00:18:52.180
From- for, um, the names of things like Barack Obama.

00:18:52.180 --> 00:18:54.970
We've talked a couple of times about named entity recognizers,

00:18:54.970 --> 00:18:57.730
so we can run those and find all the named entities.

00:18:57.730 --> 00:19:00.475
Um, then for common noun phrases,

00:19:00.475 --> 00:19:03.400
that's sort of where we need parsers to find

00:19:03.400 --> 00:19:06.925
the structure of the sentence and find where the noun phrases are.

00:19:06.925 --> 00:19:09.745
And we have talked about dependency parsers and well,

00:19:09.745 --> 00:19:14.380
one choice is you can use a dependency parser to find the sort of nominal arguments,

00:19:14.380 --> 00:19:15.670
and work with them.

00:19:15.670 --> 00:19:19.180
That's sort of actually a little bit subtler than just sort of wanting to pick

00:19:19.180 --> 00:19:22.525
out spans that refer to common noun phrases.

00:19:22.525 --> 00:19:25.855
So the other notion of parsing which we come back to,

00:19:25.855 --> 00:19:28.150
um, next week is constituency parsing.

00:19:28.150 --> 00:19:30.280
In some sense, constituency parsers are

00:19:30.280 --> 00:19:34.465
the simplest way to find mentions for this process.

00:19:34.465 --> 00:19:39.310
Um, most of it seems and is easy,

00:19:39.310 --> 00:19:44.200
um, there are sort of tricky cases as to what counts as a mention or not.

00:19:44.200 --> 00:19:47.785
So, um, if it's kind of it is sunny,

00:19:47.785 --> 00:19:49.975
I mean, is it a mention of something?

00:19:49.975 --> 00:19:51.880
It's sort of seems like it's not really,

00:19:51.880 --> 00:19:55.870
it's just it seems like it's an it that you stick at the start of the sentence,

00:19:55.870 --> 00:19:57.340
um, that doesn't mean anything.

00:19:57.340 --> 00:19:59.215
So that's maybe not a mention.

00:19:59.215 --> 00:20:00.730
Um, every student.

00:20:00.730 --> 00:20:02.695
Is every student a mention?

00:20:02.695 --> 00:20:07.810
I mean, it's certainly, at best it's some kind of collective,

00:20:07.810 --> 00:20:11.965
um, but it's not sort of a very clear concrete reference, um.

00:20:11.965 --> 00:20:15.520
That goes further, if I sort of use different quantifiers,

00:20:15.520 --> 00:20:17.920
so if it was like, every and no are called quantifiers.

00:20:17.920 --> 00:20:21.070
I mean no student definitely doesn't have reference,

00:20:21.070 --> 00:20:23.560
because it's not pointing at anything, right?

00:20:23.560 --> 00:20:25.990
It's asserting a claim of nonexistence.

00:20:25.990 --> 00:20:28.015
So that there's definitely, um,

00:20:28.015 --> 00:20:31.090
no- it isn't a mention of anything.

00:20:31.090 --> 00:20:34.420
Um, yeah, the best donut in the world.

00:20:34.420 --> 00:20:37.675
Um, does that have reference?

00:20:37.675 --> 00:20:40.125
Um, that's unclear.

00:20:40.125 --> 00:20:44.460
This is the kind of thing that actual philosophers of language debate over, right?

00:20:44.460 --> 00:20:48.315
So if there was agreement on what the best donut in the world is,

00:20:48.315 --> 00:20:50.535
then maybe it has reference, um,

00:20:50.535 --> 00:20:52.815
but I can say sentences like,

00:20:52.815 --> 00:20:56.130
I'm searching everywhere to find the best donut in the world.

00:20:56.130 --> 00:20:57.960
And then in that sentence,

00:20:57.960 --> 00:20:59.340
it doesn't have any reference, right?

00:20:59.340 --> 00:21:03.975
It's sort of an intentional description of what I'm hoping to find,

00:21:03.975 --> 00:21:06.995
that there's no concrete thing it refers to.

00:21:06.995 --> 00:21:11.605
Um, things like quantities, 100 miles.

00:21:11.605 --> 00:21:14.170
That sort of behaves like a noun phrase,

00:21:14.170 --> 00:21:17.995
but it is in- it's sort of really a quantity that doesn't really have reference.

00:21:17.995 --> 00:21:23.200
Um, and so then there's the question of how can you deal with this stuff?

00:21:23.200 --> 00:21:27.355
Um, well, um, our tool whenever we want to deal with stuff,

00:21:27.355 --> 00:21:30.265
is we train classifiers,

00:21:30.265 --> 00:21:34.150
as in they pick out things that are mentioned and things that aren't.

00:21:34.150 --> 00:21:38.800
And so that's something that you could do is write a classifier that filters out,

00:21:38.800 --> 00:21:42.940
um, these spurious things that you want to say aren't really mentions.

00:21:42.940 --> 00:21:44.980
And people absolutely have done that.

00:21:44.980 --> 00:21:47.650
But commonly actually people skip that step,

00:21:47.650 --> 00:21:54.295
and you just sort of instead have your mention detector find all candidate mentions.

00:21:54.295 --> 00:21:57.610
Because it turns out that that tends to work pretty well.

00:21:57.610 --> 00:22:01.510
Because after we found all of our mentions, um,

00:22:01.510 --> 00:22:05.815
we're then going to be doing this clustering process to find coreferent mentions.

00:22:05.815 --> 00:22:08.440
And if there are just a few stray mentions like

00:22:08.440 --> 00:22:12.655
no student and we don't cluster them wrongly with anything else,

00:22:12.655 --> 00:22:18.490
it kind of doesn't do any harm because we are mainly involved in this clustering process.

00:22:18.490 --> 00:22:23.440
Okay. Um, something you might be wondering is,

00:22:23.440 --> 00:22:25.090
well I've sort of implied now,

00:22:25.090 --> 00:22:26.605
we have a pipeline.

00:22:26.605 --> 00:22:29.770
I'm saying we're going to run a part of speech tagger,

00:22:29.770 --> 00:22:31.810
and we're going to run a named entity recognizer,

00:22:31.810 --> 00:22:33.265
and we're going to run a parser.

00:22:33.265 --> 00:22:35.455
And we're going to run a, um,

00:22:35.455 --> 00:22:38.185
a named mention detector.

00:22:38.185 --> 00:22:41.530
And then eventually, we're going to run this coref clustering system,

00:22:41.530 --> 00:22:44.290
so we have a sort of a five-step pipeline.

00:22:44.290 --> 00:22:50.950
Um, is that the only way you can do, um, coreference resolution?

00:22:50.950 --> 00:22:53.020
And the traditional answer was yup,

00:22:53.020 --> 00:22:55.030
that's the way you did coreference resolution.

00:22:55.030 --> 00:22:59.275
That essentially, all systems for coreference resolution,

00:22:59.275 --> 00:23:05.800
until approximately 2016 where a pipeline that went through about those stages.

00:23:05.800 --> 00:23:09.735
Um, but just recently and I will dico- cover one such system,

00:23:09.735 --> 00:23:12.180
um, later in the class, um,

00:23:12.180 --> 00:23:15.570
that people in the neural world have started doing what's been

00:23:15.570 --> 00:23:19.560
effective in a lot of places in the neural network world of saying,

00:23:19.560 --> 00:23:22.815
can we just build an end-to-end coreference system

00:23:22.815 --> 00:23:26.385
that starts with just plain text of a paragraph,

00:23:26.385 --> 00:23:33.685
and feeds out coreference clusters without there being any intervening pipeline steps?

00:23:33.685 --> 00:23:36.625
And I'll show you a bit more about how that works.

00:23:36.625 --> 00:23:40.090
Um, but before we get into systems,

00:23:40.090 --> 00:23:45.220
I just wanted to say a little bit more about the linguistics of coreference.

00:23:45.220 --> 00:23:49.570
Um, there's actually quite a lot of interesting stuff here,

00:23:49.570 --> 00:23:52.360
and to a fair degree,

00:23:52.360 --> 00:23:55.810
it's not actually stuff that's been thought about

00:23:55.810 --> 00:23:59.065
very much by people who build NLP systems, right?

00:23:59.065 --> 00:24:01.150
I already mentioned, um,

00:24:01.150 --> 00:24:03.505
from the Shruthi Rao story, um,

00:24:03.505 --> 00:24:06.250
the example of split antecedents, right?

00:24:06.250 --> 00:24:09.969
That that's just a clear linguistic phenomenon that happens,

00:24:09.969 --> 00:24:12.160
and it's not even incredibly rare, right?

00:24:12.160 --> 00:24:14.095
Um, that, you know, um,

00:24:14.095 --> 00:24:19.585
people build these simple machine learning models that just can't deal with that.

00:24:19.585 --> 00:24:22.630
And there's really quite a bit more structure

00:24:22.630 --> 00:24:25.750
to what happens in the linguistics of coreference,

00:24:25.750 --> 00:24:30.280
it isn't really being exploited in most of the systems people bui- build.

00:24:30.280 --> 00:24:33.145
So I just wanted to show people a bit more of that.

00:24:33.145 --> 00:24:38.200
And essentially, to sort of understanding, um,

00:24:38.200 --> 00:24:41.095
more about how people see things linguistically,

00:24:41.095 --> 00:24:46.945
there are two concepts that are related and commonly confused,

00:24:46.945 --> 00:24:48.370
that are really different.

00:24:48.370 --> 00:24:50.635
So one is coreference.

00:24:50.635 --> 00:24:54.700
So we say that things are coreferent when there are

00:24:54.700 --> 00:24:59.230
two mentions and they refer to the same entity in the world.

00:24:59.230 --> 00:25:00.970
So if it's sort of,

00:25:00.970 --> 00:25:05.140
um, Donald Trump and the current president, right?

00:25:05.140 --> 00:25:09.205
They're two mentions and they refer to the same person in the world.

00:25:09.205 --> 00:25:12.190
And so that is a relationship of coreference.

00:25:12.190 --> 00:25:16.345
Um, and that's then contrasted, um, with anaphora.

00:25:16.345 --> 00:25:24.595
And so the idea of anaphora is some terms in text don't have independent reference,

00:25:24.595 --> 00:25:30.835
and you work out their reference by relating them back to another thing in the text.

00:25:30.835 --> 00:25:32.800
So if we have the sentence,

00:25:32.800 --> 00:25:35.500
Barack Obama said he would sign the bill.

00:25:35.500 --> 00:25:37.225
He is an anaphor.

00:25:37.225 --> 00:25:39.430
And if I just say, he,

00:25:39.430 --> 00:25:41.905
what does he refer to in the abstract?

00:25:41.905 --> 00:25:45.775
Well, you know, apart from saying something male, right?

00:25:45.775 --> 00:25:47.050
You've got no idea, right?

00:25:47.050 --> 00:25:50.110
Because you can't work out what he means just by knowing he.

00:25:50.110 --> 00:25:54.370
You have to be looking at a text and interpreting it relative to the text.

00:25:54.370 --> 00:25:56.515
And then if you're interpreting it,

00:25:56.515 --> 00:25:58.795
um, relative to the text,

00:25:58.795 --> 00:26:00.370
you're then in this situation of,

00:26:00.370 --> 00:26:03.880
okay I see, this refers back to Barack Obama.

00:26:03.880 --> 00:26:07.600
So he is another mention of Barack Obama,

00:26:07.600 --> 00:26:10.915
then- and this then is this concept of anaphora.

00:26:10.915 --> 00:26:13.615
So the picture we have is sort of like this,

00:26:13.615 --> 00:26:17.635
that you can either have these independent mentions,

00:26:17.635 --> 00:26:19.690
which do refer, um,

00:26:19.690 --> 00:26:21.310
to the same thing in the world.

00:26:21.310 --> 00:26:22.765
They're coreferent.

00:26:22.765 --> 00:26:24.580
But in many cases,

00:26:24.580 --> 00:26:27.969
such as when they're full mentions like President Obama,

00:26:27.969 --> 00:26:31.990
versus Barack Obama, they don't have any textual relationship.

00:26:31.990 --> 00:26:35.455
It's just they happen to refer to the same thing in the world.

00:26:35.455 --> 00:26:40.825
And that then contrast with cases like Barack Obama said he would do something,

00:26:40.825 --> 00:26:45.265
where the he has a textual relationship back to Barack Obama.

00:26:45.265 --> 00:26:47.530
And that's an example of anaphora.

00:26:47.530 --> 00:26:54.985
Um, this might up until now feel like an almost meaningless distinction.

00:26:54.985 --> 00:26:59.425
But something that maybe gives you more of a sense that there's something useful here is,

00:26:59.425 --> 00:27:04.420
um, these textual relationships exist even when there isn't coreference.

00:27:04.420 --> 00:27:06.790
So we sort of mentioned before,

00:27:06.790 --> 00:27:09.430
these cases like no dancer, right?

00:27:09.430 --> 00:27:12.610
So no dancer doesn't have reference, right?

00:27:12.610 --> 00:27:14.305
It refers to nothing.

00:27:14.305 --> 00:27:16.810
Um, but if you have a sentence like,

00:27:16.810 --> 00:27:22.615
"no dancer twisted her knee," well we have an anaphor here.

00:27:22.615 --> 00:27:26.260
And that anaphor is referring back to "no

00:27:26.260 --> 00:27:30.520
dancer" despite the fact that "no dancer" doesn't have reference.

00:27:30.520 --> 00:27:34.150
So we can still have the anaphoric textual relationship.

00:27:34.150 --> 00:27:36.070
And indeed, you know,

00:27:36.070 --> 00:27:39.280
her knee is then a part of her.

00:27:39.280 --> 00:27:42.040
And so these are the sort of part relationships again.

00:27:42.040 --> 00:27:45.370
But her knee, in a sense that I'll just come back to,

00:27:45.370 --> 00:27:51.325
is also an anaphor which is interpreted with respect, um, to the dancer.

00:27:51.325 --> 00:27:54.370
So we have two anaphoric relationships here,

00:27:54.370 --> 00:27:57.250
even though we have no reference.

00:27:57.250 --> 00:28:00.865
There's another interesting case of

00:28:00.865 --> 00:28:04.795
anaphoric relationships which aren't the same as reference,

00:28:04.795 --> 00:28:08.380
which is you could have looser forms of anaphoric relationships.

00:28:08.380 --> 00:28:10.810
So you get lots of sentences like this.

00:28:10.810 --> 00:28:13.135
"We went to see a concert last night,

00:28:13.135 --> 00:28:15.250
the tickets were really expensive."

00:28:15.250 --> 00:28:18.925
So we have this mentioned here of the tickets.

00:28:18.925 --> 00:28:22.465
Um, but really to interpret the tickets,

00:28:22.465 --> 00:28:26.995
we have to interpret them with respect to this,

00:28:26.995 --> 00:28:28.735
um, mention back here,

00:28:28.735 --> 00:28:31.465
a concept, because really what this is saying,

00:28:31.465 --> 00:28:35.095
the tickets for the concert were really expensive.

00:28:35.095 --> 00:28:39.205
So this is also referred to as an anaphoric relationship,

00:28:39.205 --> 00:28:42.190
where the meaning of the tickets has to be interpreted

00:28:42.190 --> 00:28:46.600
textually based on another, um, noun phrase.

00:28:46.600 --> 00:28:49.690
But it's not a coreference relationship that

00:28:49.690 --> 00:28:53.335
the concert and the tickets are clearly two different entities.

00:28:53.335 --> 00:28:56.979
So these kinda looser cases are referred to as bridging anaphora,

00:28:56.979 --> 00:29:00.805
because you sort of have to supply for yourself the bridge,

00:29:00.805 --> 00:29:07.105
the relation that connects together the antecedent and the anaphor.

00:29:07.105 --> 00:29:10.780
Okay. So that's how- we then have these pictures,

00:29:10.780 --> 00:29:14.890
that we have this sort of not in- not complete crossovers

00:29:14.890 --> 00:29:19.510
between coreference and anaphora that we've sort of talked about.

00:29:19.510 --> 00:29:24.200
Um, I have one other note on anaphora. Um,

00:29:24.200 --> 00:29:28.825
Who- has anyone here ever done any Ancient Greek?

00:29:28.825 --> 00:29:34.020
Any Ancient Greek? [LAUGHTER] Yes.

00:29:34.020 --> 00:29:36.035
Okay. Um, so, um,

00:29:36.035 --> 00:29:40.745
from- from the origins of the words anaphora,

00:29:40.745 --> 00:29:47.135
anaphora is meant to be that you're finding your textual reference before you.

00:29:47.135 --> 00:29:53.300
Um, and so there's actually a- a complementary, um,

00:29:53.300 --> 00:29:56.940
term of art which is referred to as

00:29:56.940 --> 00:30:02.140
cataphora where you're finding your reference after you.

00:30:02.140 --> 00:30:05.700
Um, so here is a beautiful example of cataphora.

00:30:05.700 --> 00:30:07.380
So this is from Oscar Wilde's,

00:30:07.380 --> 00:30:09.330
The Picture of Dorian Gray.

00:30:09.330 --> 00:30:14.339
"From the corner of the divan of Persian saddle-bags on which he was lying,

00:30:14.339 --> 00:30:16.620
smoking, as was his custom,

00:30:16.620 --> 00:30:20.690
innumerable cigarettes, Lord Henry Wotton could just catch

00:30:20.690 --> 00:30:25.470
the gleam of the honey-sweet and honey-colored blossoms of a laburnum."

00:30:25.470 --> 00:30:28.865
Um, right. So here we have this, um, mentioned,

00:30:28.865 --> 00:30:33.060
Lord Henry Wotton and there are two anaphors,

00:30:33.060 --> 00:30:35.940
um, that refer to Lord Henry Wotton.

00:30:35.940 --> 00:30:39.300
Um, he and his,

00:30:39.300 --> 00:30:41.730
and that they both come before,

00:30:41.730 --> 00:30:43.995
um, Lord Henry Wotton.

00:30:43.995 --> 00:30:47.010
And so these are referred to, um,

00:30:47.010 --> 00:30:53.670
as instances of cataphora among a certain kind of classical scholar.

00:30:53.670 --> 00:30:56.460
Um, and in case you don't know what a laburnum is,

00:30:56.460 --> 00:30:58.680
um, this is a laburnum.

00:30:58.680 --> 00:31:01.890
[LAUGHTER] Right. But, yeah,

00:31:01.890 --> 00:31:03.365
so thi- this is cataphora.

00:31:03.365 --> 00:31:05.940
Now- now there are two sad things to say.

00:31:05.940 --> 00:31:09.630
Um, the first sad thing is in modern linguistics,

00:31:09.630 --> 00:31:12.375
the term cataphora is completely disused.

00:31:12.375 --> 00:31:18.185
And we mean- we just used the word um, anaphors everywhere as meaning

00:31:18.185 --> 00:31:21.300
a word that gets referenced from some other mention in

00:31:21.300 --> 00:31:24.525
the text and it doesn't matter what side it's on.

00:31:24.525 --> 00:31:28.560
Um, so, um, that we go downhill one stage to

00:31:28.560 --> 00:31:34.055
linguistics but then we get to NLP and we go downhill a second stage.

00:31:34.055 --> 00:31:38.160
Because what you'll see is that in general,

00:31:38.160 --> 00:31:40.485
the systems that people are building for,

00:31:40.485 --> 00:31:47.355
um, reference resolution, they don't make any distinction of direction at all.

00:31:47.355 --> 00:31:49.155
That once you find a mention,

00:31:49.155 --> 00:31:52.230
you're always looking backwards for its reference.

00:31:52.230 --> 00:31:54.875
Um, and you've got no idea that,

00:31:54.875 --> 00:31:57.630
well, maybe sometimes you could look forwards.

00:31:57.630 --> 00:31:59.280
So effectively, what it means,

00:31:59.280 --> 00:32:01.370
that the systems end up doing is saying,

00:32:01.370 --> 00:32:02.930
well, there's a he here,

00:32:02.930 --> 00:32:05.955
there are various other things, there's a his, etc.,

00:32:05.955 --> 00:32:09.650
and you'll eventually get to Lord Henry Wotton and you'll be able to

00:32:09.650 --> 00:32:13.995
be trying to find its reference by looking backwards,

00:32:13.995 --> 00:32:17.760
even though that's sort of ill-formed from any kind of linguistic sense

00:32:17.760 --> 00:32:22.305
whereas really he and his that should have been looking for their reference forward.

00:32:22.305 --> 00:32:29.140
Okay. Um, is everyone good up to there, any questions?

00:32:29.840 --> 00:32:34.110
Okay. We'll move ahead and, um,

00:32:34.110 --> 00:32:38.610
try and move on to kinds of coreference, um, models.

00:32:38.610 --> 00:32:41.715
So I wanted to, um, tell you, um,

00:32:41.715 --> 00:32:45.300
as much as I can and I have 45 minutes, um,

00:32:45.300 --> 00:32:49.055
left about, so the kinda models people build with coreference.

00:32:49.055 --> 00:32:53.670
And I hope to mention quickly four different ways that people have looked at coreference.

00:32:53.670 --> 00:32:57.800
I wanna tell you a teeny bit about classical rule-based coreference.

00:32:57.800 --> 00:33:02.010
Um, then, um, mention- mention pair coreference.

00:33:02.010 --> 00:33:04.930
Spend the most time on mention ranking systems which have

00:33:04.930 --> 00:33:07.995
tended to be the easiest simple systems.

00:33:07.995 --> 00:33:09.580
And then just say a little bit about

00:33:09.580 --> 00:33:12.780
clustering systems which should be the right way to do

00:33:12.780 --> 00:33:18.150
it but in practice has been a way that's been hard to get the best performance from.

00:33:18.150 --> 00:33:20.900
Okay. So here's a bit of history.

00:33:20.900 --> 00:33:22.980
Um, this guy here is Jerry Hobbs.

00:33:22.980 --> 00:33:28.320
He just had his retirement party from University of Southern California last month.

00:33:28.320 --> 00:33:29.670
Um, so Jerry Hobbs,

00:33:29.670 --> 00:33:31.815
way back when, um,

00:33:31.815 --> 00:33:33.660
wrote a famous paper,

00:33:33.660 --> 00:33:37.905
it was in 1976 on coreference resolution.

00:33:37.905 --> 00:33:41.520
And in that paper, um, he proposed,

00:33:41.520 --> 00:33:45.600
um, what's normally now referred to as the Hobbs Algorithm.

00:33:45.600 --> 00:33:47.895
But actually, um, in his paper,

00:33:47.895 --> 00:33:51.180
he refers to it as a naive algorithm.

00:33:51.180 --> 00:33:54.680
Um, and I'll come back to that distinction in just a moment.

00:33:54.680 --> 00:33:57.630
Um, but what the Hobbs algorithm was,

00:33:57.630 --> 00:34:01.980
is if you have a sentence- so actually I should say this,

00:34:01.980 --> 00:34:05.430
this algorithm is just for finding the reference of pronouns.

00:34:05.430 --> 00:34:08.500
So one can extend out to other cases but the part I'm gonna show

00:34:08.500 --> 00:34:11.760
you is just the part for doing the reference of pronouns.

00:34:11.760 --> 00:34:12.935
So when you find out,

00:34:12.935 --> 00:34:17.925
find a pronoun and you wanna say what is it, um, coreferent with?

00:34:17.925 --> 00:34:22.700
What you're going to do is run this mechanical algorithm

00:34:22.700 --> 00:34:27.945
that's looking at a parse of a sentence and is working out what to do with it.

00:34:27.945 --> 00:34:30.824
Begin at the NP immediately dominating the pronoun,

00:34:30.824 --> 00:34:35.325
go up the trees or the first NP or S. Call this X and the path p,

00:34:35.325 --> 00:34:37.760
traverse along, ah, it goes on and on.

00:34:37.760 --> 00:34:39.015
Um, there's more of it.

00:34:39.015 --> 00:34:40.110
That was only the beginning of it.

00:34:40.110 --> 00:34:41.475
There are a lot more stages.

00:34:41.475 --> 00:34:43.230
Um, but, you know,

00:34:43.230 --> 00:34:46.890
I'm not- I don't really wanna go into the details of this.

00:34:46.890 --> 00:34:50.070
Um, but, you know, to try and explain the flavor of it,

00:34:50.070 --> 00:34:51.665
here's a piece of text.

00:34:51.665 --> 00:34:53.980
"Niall Ferguson is prolific,

00:34:53.980 --> 00:34:56.220
well-paid, and a snappy dresser.

00:34:56.220 --> 00:34:58.395
Stephen Moss hated him."

00:34:58.395 --> 00:35:02.854
Um, and so if you can remember any of the steps of that algorithm,

00:35:02.854 --> 00:35:06.275
here's our, um, pronoun him.

00:35:06.275 --> 00:35:11.535
Um, and then, what it said to do was begin at the NP,

00:35:11.535 --> 00:35:14.210
the noun phrase above the pronoun.

00:35:14.210 --> 00:35:19.010
And then it said, to go up to the first noun phrase or S above that,

00:35:19.010 --> 00:35:21.370
um, here is the S above that.

00:35:21.370 --> 00:35:24.765
Um, and then what you're meant to do is, from there,

00:35:24.765 --> 00:35:30.185
you're meant to go left to right through stuff that came before that.

00:35:30.185 --> 00:35:32.980
So there's a lot of cleverness in this handwritten algorithm.

00:35:32.980 --> 00:35:36.440
You know, this is in the space of clever handwritten algorithms.

00:35:36.440 --> 00:35:40.140
And so what this is reflecting is that you might just think you

00:35:40.140 --> 00:35:44.045
should go to the closest thing to find reference,

00:35:44.045 --> 00:35:48.735
but actually if you have reference within the same sentence,

00:35:48.735 --> 00:35:51.730
it's much more common for the sort of

00:35:51.730 --> 00:35:56.085
highest syntactic roles to be what you're coreferent with.

00:35:56.085 --> 00:35:59.780
So you're more likely to be coreferent with a subject than an object,

00:35:59.780 --> 00:36:03.760
and you're more likely to be coreferent with an object than something like

00:36:03.760 --> 00:36:08.935
a noun phrase and that's inside a prepositional phrase that follows the object.

00:36:08.935 --> 00:36:11.855
So we're gonna start from the left here and we're gonna

00:36:11.855 --> 00:36:14.710
say here's a noun phrase, Stephen Moss.

00:36:14.710 --> 00:36:16.520
That's the first one we come to.

00:36:16.520 --> 00:36:20.265
And then there's this clever bit of text that says,

00:36:20.265 --> 00:36:24.820
um, traversal branches, um, below X,

00:36:24.820 --> 00:36:27.080
that are to the left- left to right,

00:36:27.080 --> 00:36:31.040
propose as antecedent and noun phrase, um,

00:36:31.040 --> 00:36:37.220
that has a noun phrase or sentence between it's an ec- in the S. So it was saying,

00:36:37.220 --> 00:36:38.990
this will be a candidate,

00:36:38.990 --> 00:36:40.520
if and only if,

00:36:40.520 --> 00:36:44.345
there's some other noun phrase or S in-between.

00:36:44.345 --> 00:36:48.870
Um, and so what that's saying is Stephen Moss hated him.

00:36:48.870 --> 00:36:52.210
It- this him cannot refer back to

00:36:52.210 --> 00:36:55.830
Stephen Moss and that sort of pretty much a fact of English syntax.

00:36:55.830 --> 00:37:00.090
But what it's wanting to do is distinguish between,

00:37:00.090 --> 00:37:02.940
another thing that we could have had here was

00:37:02.940 --> 00:37:09.100
a noun phrase that had another possessive noun phrase inside it.

00:37:09.100 --> 00:37:17.595
Um, so if we had something like Stephen Moss's mother hated him, right?

00:37:17.595 --> 00:37:22.620
Then the Stephen mother- Moss's mother hated him, then that would,

00:37:22.620 --> 00:37:28.055
in that case, it would be perfectly okay for him to be coreferent with Stephen Moss.

00:37:28.055 --> 00:37:31.120
And the algorithm allows that because relative to

00:37:31.120 --> 00:37:35.760
this noun phrase is another noun phrase above it and between.

00:37:35.760 --> 00:37:38.205
Okay. So that didn't work, um,

00:37:38.205 --> 00:37:40.740
as an antece- as an antecedent,

00:37:40.740 --> 00:37:43.415
so then we go onto the next step of the algorithm.

00:37:43.415 --> 00:37:44.920
And then, the next step says,

00:37:44.920 --> 00:37:49.095
we should proceed backwards through preceding sentences,

00:37:49.095 --> 00:37:50.595
um, right to left.

00:37:50.595 --> 00:37:55.085
And so that captures an important heuristic that proximity is actually

00:37:55.085 --> 00:37:58.085
a good heuristic to find coreference

00:37:58.085 --> 00:38:02.115
because coreference for pronouns is usually close by overall.

00:38:02.115 --> 00:38:05.055
And so we go to the first sentence back.

00:38:05.055 --> 00:38:07.885
And then in this sentence, again,

00:38:07.885 --> 00:38:09.610
we go into within the sentence,

00:38:09.610 --> 00:38:13.335
go left to right because there's the same kind of subject prominence role.

00:38:13.335 --> 00:38:15.685
And so we're gonna start in this sentence,

00:38:15.685 --> 00:38:16.990
and we're gonna say okay,

00:38:16.990 --> 00:38:18.710
here's a noun phrase.

00:38:18.710 --> 00:38:21.315
And now because we're in a different sentence,

00:38:21.315 --> 00:38:23.360
there's nothing wrong with this one.

00:38:23.360 --> 00:38:24.725
So we say, aha,

00:38:24.725 --> 00:38:27.340
we have a candidate, Niall Ferguson,

00:38:27.340 --> 00:38:32.385
um, is a possible antecedent and it's the first one we found.

00:38:32.385 --> 00:38:35.700
And therefore, we say that him refers back to Niall Ferguson.

00:38:35.700 --> 00:38:38.640
And this algorithm actually gives the right answer,

00:38:38.640 --> 00:38:40.750
if you could follow along all of that.

00:38:40.750 --> 00:38:43.320
Um, though that sounds like, um,

00:38:43.320 --> 00:38:47.020
horrible handwritten stuff.

00:38:47.020 --> 00:38:56.810
But, um, so Jerry Hobbs was aware of that this was horrible handwritten stuff,

00:38:56.810 --> 00:39:01.805
but he was interested in this algorithm for a couple of reasons.

00:39:01.805 --> 00:39:04.970
I mean, reason one is, you know,

00:39:04.970 --> 00:39:09.980
this is actually one of the first places in natural language processing,

00:39:09.980 --> 00:39:12.740
that someone produced the baseline, right.

00:39:12.740 --> 00:39:15.620
In for final projects and elsewhere,

00:39:15.620 --> 00:39:17.750
um, and stuff we gave you, right,

00:39:17.750 --> 00:39:21.260
it's seen now in NLP and other areas,

00:39:21.260 --> 00:39:22.490
that anything you are doing,

00:39:22.490 --> 00:39:24.620
the first thing you should do is have a baseline,

00:39:24.620 --> 00:39:27.440
a simple system and see how well it works.

00:39:27.440 --> 00:39:31.955
And this was his simple rule-based system for doing coreference,

00:39:31.955 --> 00:39:36.575
um, and he wanted to observe that actually this baseline was pretty good.

00:39:36.575 --> 00:39:40.925
It actually gave the right answer a lot of the time.

00:39:40.925 --> 00:39:47.360
And so the challenge was how to build a system that did better than this baseline.

00:39:47.360 --> 00:39:49.220
And so he was well aware of it,

00:39:49.220 --> 00:39:50.780
you know, it was a dumb algorithm,

00:39:50.780 --> 00:39:55.580
but he proposed that as a good baseline for doing coreference resolution.

00:39:55.580 --> 00:39:57.920
So what he was interested in,

00:39:57.920 --> 00:40:00.980
um, remember that we're back in the 1970s here,

00:40:00.980 --> 00:40:06.860
was how to do knowledge-based pronominal coreference resolution.

00:40:06.860 --> 00:40:12.250
And so, um, essentially what he was noticing is well,

00:40:12.250 --> 00:40:16.360
these kinds of syntactic factors that I was mentioning prefer subjects,

00:40:16.360 --> 00:40:18.430
prefer close by, etc,

00:40:18.430 --> 00:40:20.785
they're all useful predictors.

00:40:20.785 --> 00:40:23.830
But there are lots of cases where they don't give the right answer,

00:40:23.830 --> 00:40:25.750
and to know when they give, when,

00:40:25.750 --> 00:40:29.005
to know what's really the coreferent thing,

00:40:29.005 --> 00:40:33.000
you have to actually understand what's being described in the world.

00:40:33.000 --> 00:40:35.105
So if I have this sentence,

00:40:35.105 --> 00:40:39.005
she poured water from the pitcher into the cup until it was full.

00:40:39.005 --> 00:40:41.700
What is it coreferent with?

00:40:44.530 --> 00:40:45.740
Cup.

00:40:45.740 --> 00:40:46.700
[NOISE] The cup.

00:40:46.700 --> 00:40:48.350
Thank you. [LAUGHTER] Okay.

00:40:48.350 --> 00:40:50.870
So that, it refers to the cup.

00:40:50.870 --> 00:40:53.225
But then let's look at this example.

00:40:53.225 --> 00:40:57.530
She poured water from the pitcher into the cup until it was empty.

00:40:57.530 --> 00:40:59.375
What does it refer to?

00:40:59.375 --> 00:40:59.900
The [OVERLAPPING].

00:40:59.900 --> 00:41:01.775
The pitcher. [LAUGHTER] Okay.

00:41:01.775 --> 00:41:06.125
So the crucial thing to notice in these two sentences is,

00:41:06.125 --> 00:41:10.940
these sentences have identical syntactic structure, right.

00:41:10.940 --> 00:41:15.695
So Jerry Hobbs's algorithm can't possibly work,

00:41:15.695 --> 00:41:18.365
um, for both of these sentences.

00:41:18.365 --> 00:41:20.615
It's gonna work for one of them,

00:41:20.615 --> 00:41:22.550
but not the other one.

00:41:22.550 --> 00:41:26.030
Um, since it's working from left to right within a sentence,

00:41:26.030 --> 00:41:28.865
it's gonna say the pitcher both times actually, right.

00:41:28.865 --> 00:41:35.360
So you can't get the answer right by Jerry Hobbs' algorithm and Jerry believed,

00:41:35.360 --> 00:41:37.415
and still believes, um,

00:41:37.415 --> 00:41:40.475
that the only way to get these kind of examples right,

00:41:40.475 --> 00:41:43.415
is actually if you understand the world,

00:41:43.415 --> 00:41:46.640
and you actually know what's going on in the world,

00:41:46.640 --> 00:41:49.040
so you can see what, what this is talking about.

00:41:49.040 --> 00:41:51.020
And there are lots of examples like this.

00:41:51.020 --> 00:41:53.765
Um, this is another very famous example.

00:41:53.765 --> 00:41:58.310
The city council refused the women a permit because they feared violence.

00:41:58.310 --> 00:42:00.140
Um, who does that they refer to?

00:42:00.140 --> 00:42:01.550
[inaudible].

00:42:01.550 --> 00:42:03.125
The city councilors.

00:42:03.125 --> 00:42:05.360
Um, but here's another sentence.

00:42:05.360 --> 00:42:10.415
The city council refused the women a permit because they advocated violence.

00:42:10.415 --> 00:42:12.785
Who does that they refer to?

00:42:12.785 --> 00:42:14.000
The women.

00:42:14.000 --> 00:42:16.340
The women. Okay. So this time it refers to the women.

00:42:16.340 --> 00:42:18.245
Um, and again, you know,

00:42:18.245 --> 00:42:24.185
identical syntactic structure, it couldn't possibly be done right by the Hobbs algorithm.

00:42:24.185 --> 00:42:27.365
Um, so this particular pair of examples,

00:42:27.365 --> 00:42:29.270
um, comes from Terry Winograd.

00:42:29.270 --> 00:42:31.610
Um, how long ti- uh,

00:42:31.610 --> 00:42:35.150
so Terry Winograd was originally an NLP faculty, um,

00:42:35.150 --> 00:42:39.410
he sort of got disillusioned with NLP because there wasn't making much progress, um,

00:42:39.410 --> 00:42:42.065
and ventured off into the land of HCI,

00:42:42.065 --> 00:42:43.880
um, that became his career.

00:42:43.880 --> 00:42:46.250
Um, but in his early work, um,

00:42:46.250 --> 00:42:48.109
he was interested in these phenomena,

00:42:48.109 --> 00:42:50.150
and came up with this example.

00:42:50.150 --> 00:42:52.955
And so this example really stuck with people.

00:42:52.955 --> 00:42:56.030
And so these kind of contrasts are referred to by

00:42:56.030 --> 00:42:59.615
other people as Winograd sentences or Winograd schema.

00:42:59.615 --> 00:43:04.505
And so this is actually something that's interesting that's revived recently.

00:43:04.505 --> 00:43:07.190
Um, so Hector Le- Levesque, um,

00:43:07.190 --> 00:43:09.875
wrote a paper, I guess five years ago now,

00:43:09.875 --> 00:43:14.030
where he was trying to advocate for return to doing

00:43:14.030 --> 00:43:18.515
more in the way of knowledge and world modeling and artificial intelligence,

00:43:18.515 --> 00:43:21.710
and arguing that there are lots of problems that you just

00:43:21.710 --> 00:43:25.595
can't solve by the kind of crude statistical methods,

00:43:25.595 --> 00:43:28.250
that our machine learning systems are using.

00:43:28.250 --> 00:43:31.370
And that you really needed to do more world understanding.

00:43:31.370 --> 00:43:33.080
And so he proposed that

00:43:33.080 --> 00:43:38.240
these Winograd schema would be a good te- alternative to the Turing test,

00:43:38.240 --> 00:43:40.760
as a way of measuring intelligence.

00:43:40.760 --> 00:43:43.850
And actually they're just coreference decisions, right.

00:43:43.850 --> 00:43:47.165
So, um, so there's sort of a claim here that,

00:43:47.165 --> 00:43:50.675
if you can do a coreference right 100 percent of the time,

00:43:50.675 --> 00:43:54.110
you've solved artificial intelligence in that you're, sort of you can,

00:43:54.110 --> 00:43:58.745
can code knowledge of the world into coreference problems.

00:43:58.745 --> 00:44:04.010
Um, yes so people have then tried to work on these Winograd schemas,

00:44:04.010 --> 00:44:07.070
and Levesque's feeling was, you know,

00:44:07.070 --> 00:44:09.664
you just couldn't do these,

00:44:09.664 --> 00:44:11.240
um, using kind of,

00:44:11.240 --> 00:44:14.360
the kind of statistical factors, um,

00:44:14.360 --> 00:44:17.870
that people put into their machine learning systems.

00:44:17.870 --> 00:44:22.520
He was partly wrong about that because subsequent work, um,

00:44:22.520 --> 00:44:27.050
both neural systems and otherwise has shown that actually you can

00:44:27.050 --> 00:44:32.165
get f- a nontrivial distance with these kind of problems because, you know,

00:44:32.165 --> 00:44:33.709
if it is the case,

00:44:33.709 --> 00:44:35.270
um, that, you know,

00:44:35.270 --> 00:44:38.120
you can somehow see enough examples,

00:44:38.120 --> 00:44:41.120
where the city council refuses permits,

00:44:41.120 --> 00:44:42.755
fearing violence, you know.

00:44:42.755 --> 00:44:44.390
If you've go- if you're collecting

00:44:44.390 --> 00:44:48.560
your neural language model over tens of billions of words,

00:44:48.560 --> 00:44:51.530
you might have seen some instances of things like that,

00:44:51.530 --> 00:44:54.845
and you could sort of predict it just on statistical patterning.

00:44:54.845 --> 00:44:56.015
But the question is, you know,

00:44:56.015 --> 00:44:58.340
how far can you actually get doing that,

00:44:58.340 --> 00:45:00.605
without having a bit more of a world model?

00:45:00.605 --> 00:45:02.030
And so that was, you know,

00:45:02.030 --> 00:45:05.705
what Hobbs was interested in way back in 1978.

00:45:05.705 --> 00:45:10.010
So he wrote, the naive approach is quite good,

00:45:10.010 --> 00:45:14.809
computationally speaking it will be a long time before a semantically based algorithm,

00:45:14.809 --> 00:45:17.585
is sophisticated enough to perform as well.

00:45:17.585 --> 00:45:21.650
And these results set a very high standard for any other approach to aim for.

00:45:21.650 --> 00:45:23.990
He was totally right about that, um,

00:45:23.990 --> 00:45:28.655
that it really wasn't until the 2010s that anybody

00:45:28.655 --> 00:45:33.830
managed to produce an algorithm for pronominal anaphora resolution,

00:45:33.830 --> 00:45:35.900
that outperformed the Hobbs algorithm.

00:45:35.900 --> 00:45:38.420
Even though it was just, uh,

00:45:38.420 --> 00:45:40.535
what he called a naive algorithm,

00:45:40.535 --> 00:45:44.000
or he might call a crude set of linguistic rules.

00:45:44.000 --> 00:45:46.325
Um, but he says,

00:45:46.325 --> 00:45:50.090
yet there is every reason to pursue a semantically based approach,

00:45:50.090 --> 00:45:52.325
the naive algorithm does not work.

00:45:52.325 --> 00:45:55.055
Anyone can think of examples where it fails.

00:45:55.055 --> 00:45:57.409
In these cases it not only fails,

00:45:57.409 --> 00:45:59.660
it gives no indication that it has failed,

00:45:59.660 --> 00:46:03.170
and offers no help in finding the real antecedent.

00:46:03.170 --> 00:46:05.510
Um, so food for thought there.

00:46:05.510 --> 00:46:08.135
Um, but, um, notwithstanding that,

00:46:08.135 --> 00:46:10.400
I'm gonna just rush ahead at this point,

00:46:10.400 --> 00:46:12.350
and tell you about some of the, um,

00:46:12.350 --> 00:46:14.450
statistical and neural algorithms,

00:46:14.450 --> 00:46:17.120
um, that have been used for coreference resolution.

00:46:17.120 --> 00:46:20.945
So the simplest form of algorithm that's commonly used,

00:46:20.945 --> 00:46:24.215
is what is called mention pair models.

00:46:24.215 --> 00:46:29.135
So what we mean by mention pair models is, um,

00:46:29.135 --> 00:46:32.030
we are gonna take pairs of mentions,

00:46:32.030 --> 00:46:36.110
and we're gonna train a binary classifier that says,

00:46:36.110 --> 00:46:39.230
is coreferent or isn't coreferent.

00:46:39.230 --> 00:46:44.105
And so then we're gonna proceed left to right through the text.

00:46:44.105 --> 00:46:49.325
And every time we get to a new mention,

00:46:49.325 --> 00:46:55.895
we're gonna then evaluate our classifier with respect to every preceding mention,

00:46:55.895 --> 00:46:58.835
and we're gonna say, are they coreferent?

00:46:58.835 --> 00:47:01.235
And it's gonna say yes or no.

00:47:01.235 --> 00:47:03.500
And we're gonna find out that some of them.

00:47:03.500 --> 00:47:06.155
It says yes for, um,

00:47:06.155 --> 00:47:10.160
I voted for Nader because he was like, most aligned with my value.

00:47:10.160 --> 00:47:13.100
She said, if we have a good classifier,

00:47:13.100 --> 00:47:18.470
it will say yes to the two bu- blue ones and not to the rest of them.

00:47:18.470 --> 00:47:22.190
Um, and so then we'll have at training time,

00:47:22.190 --> 00:47:26.540
negative examples that Nader and he are negative examples.

00:47:26.540 --> 00:47:30.860
[NOISE] So if you have data marked for coreference,

00:47:30.860 --> 00:47:33.530
we have the sort of positive and negative examples,

00:47:33.530 --> 00:47:35.120
and we can train a model.

00:47:35.120 --> 00:47:36.980
And so for training a model,

00:47:36.980 --> 00:47:42.230
we have a sort of the classifier outcome is one or zero,

00:47:42.230 --> 00:47:45.665
based on whether two mentions are coreferent.

00:47:45.665 --> 00:47:47.960
We're gonna have a coreference model that

00:47:47.960 --> 00:47:50.960
predicts the probability of them being coreferent.

00:47:50.960 --> 00:47:54.350
And we're gonna train it with the same kind of cross entropy loss,

00:47:54.350 --> 00:47:57.275
we've used other places and, um,

00:47:57.275 --> 00:48:01.160
try and learn a model that predicts coreference.

00:48:01.160 --> 00:48:04.550
And so then when we get to test time, um,

00:48:04.550 --> 00:48:08.495
and we have a piece of text with mentions, um,

00:48:08.495 --> 00:48:12.230
we're gonna run this classifier and it's gonna say,

00:48:12.230 --> 00:48:16.400
um, yes or no, with some probability.

00:48:16.400 --> 00:48:19.205
And if we pick a threshold like 0.5,

00:48:19.205 --> 00:48:22.565
we'll add certain coreference links.

00:48:22.565 --> 00:48:25.490
And that sort of looks pretty good.

00:48:25.490 --> 00:48:29.480
Um, but we're gonna sort of complete it off by saying well,

00:48:29.480 --> 00:48:34.280
if A is coreferent to B and B is K coreferent to C. Then really

00:48:34.280 --> 00:48:40.040
also A is coreferent to C. So we're gonna do a transitive closure,

00:48:40.040 --> 00:48:42.410
and that will give us our clustering.

00:48:42.410 --> 00:48:46.160
Um, note here that there's a certain danger in this.

00:48:46.160 --> 00:48:48.650
Because this means, if we make,

00:48:48.650 --> 00:48:51.755
since we're sor- with the transitive closure,

00:48:51.755 --> 00:48:54.425
that's always adding clustering links.

00:48:54.425 --> 00:48:58.310
And so that means the danger is that we're gonna over cluster,

00:48:58.310 --> 00:49:04.400
because if we make a single mistake and we link things that should be kept separate.

00:49:04.400 --> 00:49:06.920
So for example, if we wrongly said,

00:49:06.920 --> 00:49:08.870
he and my are coreferent,

00:49:08.870 --> 00:49:10.565
then everything of this, um,

00:49:10.565 --> 00:49:13.774
discourse would collapse together into one cluster,

00:49:13.774 --> 00:49:16.920
and everything would be deemed coreferent.

00:49:16.920 --> 00:49:20.995
Okay, um, and this,

00:49:20.995 --> 00:49:25.480
something that I haven't really emphasized, but comes up,

00:49:25.480 --> 00:49:30.070
is well, there's some mentions that are coreferent to nothing, right.

00:49:30.070 --> 00:49:32.890
In the Shruthi Rao story, there was a park,

00:49:32.890 --> 00:49:35.875
which was just mentioned once in the text, and so on,

00:49:35.875 --> 00:49:38.190
in this form of algorithm,

00:49:38.190 --> 00:49:41.540
what we'd like the classifier to say is, no,

00:49:41.540 --> 00:49:42.755
no, no, no, no,

00:49:42.755 --> 00:49:44.615
for all of the decisions.

00:49:44.615 --> 00:49:46.970
And so it's deemed coreferent to nothing.

00:49:46.970 --> 00:49:49.915
And then it's just a singleton mention.

00:49:49.915 --> 00:49:52.360
This sort of works,

00:49:52.360 --> 00:49:58.660
but it hasn't proven to be the best way of doing coreference.

00:49:58.660 --> 00:50:03.585
And a lot of the reason why it's not the best way to do coreference

00:50:03.585 --> 00:50:09.410
is because we have this phenomenon of anaphora where we have textural dependence.

00:50:09.410 --> 00:50:11.065
A lot of the time,

00:50:11.065 --> 00:50:14.535
it seems that we're not really,

00:50:14.535 --> 00:50:19.815
um, what- sort of wanting to make this all coreference decisions.

00:50:19.815 --> 00:50:24.185
We'd like to make the anaphora decisions of textural dependence.

00:50:24.185 --> 00:50:27.410
So we'd like to say that he is,

00:50:27.410 --> 00:50:33.140
um, dependent on Nader and my is dependent on I.

00:50:33.140 --> 00:50:35.115
These are anaphora relationships.

00:50:35.115 --> 00:50:41.285
So we'd like to just choose one example of what is this anaphora relationship.

00:50:41.285 --> 00:50:44.870
And so that's led to people then looking at what is called,

00:50:44.870 --> 00:50:47.475
um, Mention Pair Models, right?

00:50:47.475 --> 00:50:52.100
That the problem is that if we have a long document with lots of mentions,

00:50:52.100 --> 00:50:57.050
um, that we want to not be saying- trying to find all of them and say, yes.

00:50:57.050 --> 00:51:00.160
We just want to be saying there's a particular- we

00:51:00.160 --> 00:51:03.695
just want to be saying that there's a particular one.

00:51:03.695 --> 00:51:05.770
So for the he at the end here,

00:51:05.770 --> 00:51:11.350
its anaphor relationship is back to Nader and you don't wanna be trying to say this

00:51:11.350 --> 00:51:17.600
he is also coreferent back to all of these other things that are earlier in the text.

00:51:17.600 --> 00:51:22.355
So it's not something that's been explored much.

00:51:22.355 --> 00:51:24.940
But arguably, this is a case again,

00:51:24.940 --> 00:51:30.905
where you should be separating coreference from anaphors because for anaphors it seems like

00:51:30.905 --> 00:51:32.980
the right way to think is that they have

00:51:32.980 --> 00:51:37.630
one prior thing in the text that they're textually dependent on.

00:51:37.630 --> 00:51:43.345
Whereas true coreferents, when you just have various mentions in the text of Ralph Nader,

00:51:43.345 --> 00:51:44.650
this Ralph Nader that,

00:51:44.650 --> 00:51:48.050
Nader did that, those aren't textually dependent

00:51:48.050 --> 00:51:52.070
and they should all be being grouped together as coreferents.

00:51:52.070 --> 00:51:58.520
Um, but our models sort of don't normally try and do some one way and some the other way,

00:51:58.520 --> 00:52:00.725
but you choose one of the models.

00:52:00.725 --> 00:52:02.815
So in the other one,

00:52:02.815 --> 00:52:06.010
we do it for- to do the other way,

00:52:06.010 --> 00:52:08.160
you do what's mention rankings.

00:52:08.160 --> 00:52:09.695
So for mention ranking,

00:52:09.695 --> 00:52:13.400
the idea is for each mention,

00:52:13.400 --> 00:52:15.545
we're going to find- try and find it

00:52:15.545 --> 00:52:20.640
an antecedent that comes before- before it in the text,

00:52:20.640 --> 00:52:22.650
that is- that it is, um,

00:52:22.650 --> 00:52:26.810
coreferent with, and we're going to make a one of N decision.

00:52:26.810 --> 00:52:29.509
So that when we see she here,

00:52:29.509 --> 00:52:30.815
we're going to say,

00:52:30.815 --> 00:52:35.400
"Okay, um, what is this coreferent with?"

00:52:35.400 --> 00:52:37.660
And we're going to pick one thing that it's coreferent

00:52:37.660 --> 00:52:41.130
with even though there might be others in the text.

00:52:41.130 --> 00:52:44.155
Um, so if we're doing that,

00:52:44.155 --> 00:52:47.490
we then have a problem with singleton mentions because if

00:52:47.490 --> 00:52:51.160
we're trying to- for every mention we find say,

00:52:51.160 --> 00:52:55.430
choose the thing that came before it in the text with which it's coreferent,

00:52:55.430 --> 00:52:58.575
the right answer might be that there's no such thing.

00:52:58.575 --> 00:53:00.580
So what we do is we add

00:53:00.580 --> 00:53:06.410
one additional dummy mention right at the front here, the NA mention.

00:53:06.410 --> 00:53:11.340
So one choice is you're gonna say there isn't anything preceding.

00:53:11.340 --> 00:53:13.935
So effectively, when you get to I,

00:53:13.935 --> 00:53:17.525
since this is, um, the first, um,

00:53:17.525 --> 00:53:19.265
real mention in the text,

00:53:19.265 --> 00:53:21.775
you're necessarily gonna choose as,

00:53:21.775 --> 00:53:24.260
um, its antecedent NA.

00:53:24.260 --> 00:53:27.815
You then go on to Nader and you have two choices.

00:53:27.815 --> 00:53:34.110
You can either say it's coreferent to I or it's coreferent to NA.

00:53:34.110 --> 00:53:38.410
I, it's a new mention- a new entity that's being mentioned in the text and

00:53:38.410 --> 00:53:43.280
the right answer is it's a new mention in- a new entity being mentioned in the text.

00:53:43.280 --> 00:53:46.935
Then you get to he and now you have three choices,

00:53:46.935 --> 00:53:51.100
and the right thing is to say that it's coreferent to Nader.

00:53:51.110 --> 00:53:55.199
Okay. Um, so this time,

00:53:55.199 --> 00:53:57.640
it's- for training our models,

00:53:57.640 --> 00:54:00.525
it's sort of the same, um,

00:54:00.525 --> 00:54:04.510
apart from this, sort of this different one of semantics.

00:54:04.510 --> 00:54:09.820
So now- previously, we wanted to say that for our, um,

00:54:09.820 --> 00:54:15.030
mention pair classifier that is going to try and classify I and she,

00:54:15.030 --> 00:54:16.355
and my and she,

00:54:16.355 --> 00:54:19.220
and both of them had to get a high score,

00:54:19.220 --> 00:54:22.030
where now it's sufficient that just one of them gets

00:54:22.030 --> 00:54:26.150
a high score because that's sort of enough for us to do.

00:54:26.150 --> 00:54:30.605
So what we're gonna use is our good old softmax and so for she,

00:54:30.605 --> 00:54:34.550
we're gonna put a softmax over the antecedents.

00:54:34.550 --> 00:54:39.660
And our hope is simply that we get a high probability with one of the antecedents,

00:54:39.660 --> 00:54:43.700
if it has an antecedent or a high score with NA,

00:54:43.700 --> 00:54:46.755
if it doesn't have any prior referents.

00:54:46.755 --> 00:54:51.365
And so then when we're doing classification at run-time,

00:54:51.365 --> 00:54:56.355
we're going to sort of add only the highest scoring coreference link.

00:54:56.355 --> 00:54:58.990
So that means we train it just slightly

00:54:58.990 --> 00:55:03.180
differently because now what we're going to do is that,

00:55:03.180 --> 00:55:06.200
when we're- what we're wanting to say is,

00:55:06.200 --> 00:55:13.025
we want a high score of coreference between at least one of the antecedents.

00:55:13.025 --> 00:55:15.010
And so one possible model is,

00:55:15.010 --> 00:55:17.300
we can maximize this probability.

00:55:17.300 --> 00:55:21.105
So for the ones that are coreferent in the gold standard data,

00:55:21.105 --> 00:55:24.885
we want the sum of their assigned probabilities to be high.

00:55:24.885 --> 00:55:31.135
And so what that means is that it's sort of sufficient if we have,

00:55:31.135 --> 00:55:34.300
um, one of them giving

00:55:34.300 --> 00:55:38.375
a high probability and they don't all have to give a high probability.

00:55:38.375 --> 00:55:41.219
So providing it's giving 0.9 probability,

00:55:41.219 --> 00:55:43.535
say it a one of the correct antecedents,

00:55:43.535 --> 00:55:45.695
we're getting a high score.

00:55:45.695 --> 00:55:49.660
Okay. So we're gonna turn that into a loss function in the kind of

00:55:49.660 --> 00:55:53.585
standard way we do in which we take log probabilities,

00:55:53.585 --> 00:55:56.260
um, and then we want to, um,

00:55:56.260 --> 00:55:58.590
or negative log probabilities to give us

00:55:58.590 --> 00:56:02.150
a loss and then we're wanting to minimize that loss.

00:56:02.150 --> 00:56:05.909
So with the mention ranking model,

00:56:05.909 --> 00:56:07.870
um, at test time,

00:56:07.870 --> 00:56:09.360
it's pretty much the same,

00:56:09.360 --> 00:56:16.280
but our softmax classifier is just going to assign one antecedent for each mention.

00:56:16.280 --> 00:56:20.470
And so we're then gonna hope that those sort of give us the kind

00:56:20.470 --> 00:56:25.640
of clusters that we want and there's no subsequent clustering phase.

00:56:25.820 --> 00:56:30.875
So there's a big part of this that I left out which was,

00:56:30.875 --> 00:56:32.510
I've just said, "Okay,

00:56:32.510 --> 00:56:38.590
we have this probability of MI and MJ as the- are they coreferent?"

00:56:38.590 --> 00:56:41.050
But I've sort of said, zero as to

00:56:41.050 --> 00:56:43.760
how you can determine whether they're coreferent or not.

00:56:43.760 --> 00:56:46.640
Um, so briefly, um,

00:56:46.640 --> 00:56:49.775
here- here's the classical way of doing it.

00:56:49.775 --> 00:56:51.895
The classical way of doing it is,

00:56:51.895 --> 00:56:56.090
you had a whole bunch of features and you had

00:56:56.090 --> 00:57:00.480
a feature based statistical classifier which gave a score.

00:57:00.480 --> 00:57:02.650
And these are the kind of features you could use.

00:57:02.650 --> 00:57:06.490
So there are sort of strong features of person, number, gender agreement.

00:57:06.490 --> 00:57:09.720
So if you have a masculine or feminine pronoun,

00:57:09.720 --> 00:57:12.290
you wanna find an appropriate antecedent for it.

00:57:12.290 --> 00:57:16.630
There are weaker, um, semantic compatibility features.

00:57:16.630 --> 00:57:18.980
So the mining conglomerate, the company,

00:57:18.980 --> 00:57:21.755
the conglomerate might be sort of similar to a company.

00:57:21.755 --> 00:57:25.700
You could use something like word2vec similarity and assess that.

00:57:25.700 --> 00:57:28.120
There are syntactic constraints.

00:57:28.120 --> 00:57:30.730
So this is then kind of like, um,

00:57:30.730 --> 00:57:34.570
what Hobbs's algorithm was all about us working out

00:57:34.570 --> 00:57:38.700
how likely different syntactic configurations are gonna mean coreference.

00:57:38.700 --> 00:57:40.950
And indeed it is the case, you know,

00:57:40.950 --> 00:57:46.150
that a lot of these feature-based systems used Hobbs' algorithm as a feature inside

00:57:46.150 --> 00:57:51.860
the system that was weighted and was normally a very strong feature to decide coreference.

00:57:51.860 --> 00:57:55.425
Um, there are lots of other things you can put in as features.

00:57:55.425 --> 00:57:56.860
Um, recency.

00:57:56.860 --> 00:57:58.240
So John went to a movie,

00:57:58.240 --> 00:57:59.290
Jack went as well,

00:57:59.290 --> 00:58:00.600
he was not busy.

00:58:00.600 --> 00:58:05.180
The most likely referent for he is the closer candidate Jack.

00:58:05.180 --> 00:58:10.120
Um, I've mentioned subjects are more likely to be, um, the antecedent.

00:58:10.120 --> 00:58:11.550
John went to a movie with Jack,

00:58:11.550 --> 00:58:12.930
he was not busy.

00:58:12.930 --> 00:58:15.990
Um, John seems a more likely antecedent.

00:58:15.990 --> 00:58:18.155
So that's the sort of subject preference.

00:58:18.155 --> 00:58:20.395
There's also a parallelism preference.

00:58:20.395 --> 00:58:22.295
So John went with Jack to a movie,

00:58:22.295 --> 00:58:24.170
Joe went with him to a bar.

00:58:24.170 --> 00:58:28.405
I think it's sort of reasonable to think that him there is probably Jack,

00:58:28.405 --> 00:58:32.825
and that's sort of for parallelism reasons as opposed to going with the subject.

00:58:32.825 --> 00:58:36.480
So there are various kind of linguistic features and constraints and so on,

00:58:36.480 --> 00:58:39.970
and you can throw these all into a statistical classifier and that's

00:58:39.970 --> 00:58:44.910
sort of 2000s decade coref systems as to how they're built.

00:58:44.910 --> 00:58:49.350
Um, more recently, people have built neural systems.

00:58:49.350 --> 00:58:50.560
And so for these,

00:58:50.560 --> 00:58:53.810
we are kind of normally using the same kind of embeddings.

00:58:53.810 --> 00:58:58.250
So we'll have a candidate antecedent that will have embeddings,

00:58:58.250 --> 00:59:00.510
we'll have a mention that has embeddings.

00:59:00.510 --> 00:59:01.785
And this will be something like

00:59:01.785 --> 00:59:05.595
average word vectors or something like that for the mention.

00:59:05.595 --> 00:59:09.935
And we're gonna feed these into a neural network that will give us our score.

00:59:09.935 --> 00:59:13.070
But what you find is that

00:59:13.070 --> 00:59:16.995
most of these systems as well as having something like word vectors,

00:59:16.995 --> 00:59:20.610
they also have additional features, um,

00:59:20.610 --> 00:59:23.910
and these features still capture some of

00:59:23.910 --> 00:59:28.265
the things that were in the feature-based statistical classifiers.

00:59:28.265 --> 00:59:31.865
So there will be often features that reflect things like,

00:59:31.865 --> 00:59:37.270
what grammatical relation does this mention have? Is it a subject?

00:59:37.270 --> 00:59:38.515
Is it an object?

00:59:38.515 --> 00:59:42.825
That's something you could put into the features of a mention.

00:59:42.825 --> 00:59:46.565
But then, closer things are more likely to be coreferent.

00:59:46.565 --> 00:59:51.270
So you might have additional features here which record how far apart dimensions are,

00:59:51.270 --> 00:59:54.180
and those things get thrown in as well.

00:59:54.180 --> 01:00:00.935
Um, and so these kind of features are still important even in neural systems.

01:00:00.935 --> 01:00:07.165
And so I'll skip ahead now and show you a bit about, um,

01:00:07.165 --> 01:00:11.450
what is the kind of current state of the art for coreference resolution,

01:00:11.450 --> 01:00:14.950
and this was a system that was done at the University of Washington in

01:00:14.950 --> 01:00:20.495
2017 by Kenton Lee and assorted other, um, authors.

01:00:20.495 --> 01:00:26.910
Um, so the goal here was to produce an end-to-end coreference system that it was text in,

01:00:26.910 --> 01:00:30.715
um, mention clusters that are coreferent out.

01:00:30.715 --> 01:00:35.335
Um, and so they're wanting to use sort of a more complex

01:00:35.335 --> 01:00:40.420
neural network that can do the whole thing end-to-end. So I'll go through,

01:00:40.420 --> 01:00:41.730
um, the steps of that.

01:00:41.730 --> 01:00:45.985
So the first step is we just start off with words.

01:00:45.985 --> 01:00:47.705
And so for each word,

01:00:47.705 --> 01:00:53.020
we're going to look up a word embedding for it and that's in other stuff we've seen.

01:00:53.020 --> 01:00:55.795
We're also going to put in a character level CNN,

01:00:55.795 --> 01:01:00.885
and the two of those concatenated are going to give the representation of each token.

01:01:00.885 --> 01:01:02.600
That much should look familiar.

01:01:02.600 --> 01:01:05.065
Okay. Then after that,

01:01:05.065 --> 01:01:11.255
we're going to run a deep bidirectional LSTM back and forth across the sentence.

01:01:11.255 --> 01:01:15.440
Again, that should look familiar from stuff that we've seen before.

01:01:15.440 --> 01:01:21.700
Um, the next step gets us a bit into doing something more special, um,

01:01:21.700 --> 01:01:24.115
For coreference.

01:01:24.115 --> 01:01:30.790
So what they wanted to do after that is have a representation for spans.

01:01:30.790 --> 01:01:32.635
And so by span,

01:01:32.635 --> 01:01:38.050
we mean any contiguous subphrase of the word, of the sentence.

01:01:38.050 --> 01:01:40.030
So this is a span.

01:01:40.030 --> 01:01:41.380
This is a span.

01:01:41.380 --> 01:01:42.670
This is a span.

01:01:42.670 --> 01:01:46.315
Electric said the postal is a span, every sub-sequence.

01:01:46.315 --> 01:01:48.250
Um, so I'll come back to that.

01:01:48.250 --> 01:01:50.215
But, you know, they'll- in principle,

01:01:50.215 --> 01:01:53.155
you're working this out for every sub-sequence.

01:01:53.155 --> 01:01:55.360
So for every sub-sequence,

01:01:55.360 --> 01:01:58.675
they want to come up with a span representation.

01:01:58.675 --> 01:02:04.975
And so this span representation is going to be in three parts,

01:02:04.975 --> 01:02:09.325
um, that represent one of these sub-sequences.

01:02:09.325 --> 01:02:13.660
Um, so each of these will get its own representation.

01:02:13.660 --> 01:02:15.640
And so the question is, what?

01:02:15.640 --> 01:02:18.910
And so we have this span representation,

01:02:18.910 --> 01:02:22.375
and it's gonna be in these three parts here.

01:02:22.375 --> 01:02:26.770
Um, so what these parts are is,

01:02:26.770 --> 01:02:28.420
well, first of all,

01:02:28.420 --> 01:02:31.450
we're going to have a representation, um,

01:02:31.450 --> 01:02:35.035
which is just looking at the first word of

01:02:35.035 --> 01:02:40.450
the span and the last word of the span according to the BiLSTM.

01:02:40.450 --> 01:02:43.135
So if we're looking at the span, the postal service,

01:02:43.135 --> 01:02:45.670
we're going to take this BiLSTM and

01:02:45.670 --> 01:02:50.245
this BiLSTM and use them as part of the representation of the span.

01:02:50.245 --> 01:02:52.225
Um, that's a good start,

01:02:52.225 --> 01:02:54.730
but then they actually do something a little tricky.

01:02:54.730 --> 01:02:59.710
So kind of like when we're doing dependency parsing, the idea was,

01:02:59.710 --> 01:03:02.815
well, phrases are going to have a headword,

01:03:02.815 --> 01:03:05.050
um, so that if it's,

01:03:05.050 --> 01:03:10.420
um, you know, my younger sister that the headword of that is sister,

01:03:10.420 --> 01:03:14.905
and there- if it's something like the goat in the corner of the field,

01:03:14.905 --> 01:03:16.960
the headword of that is going to be goat.

01:03:16.960 --> 01:03:21.520
So they want to find a way of capturing headwords out of the text.

01:03:21.520 --> 01:03:26.200
Um, and so what they're going to do for that is use attention.

01:03:26.200 --> 01:03:30.820
So they're going to say we have this span, the postal service,

01:03:30.820 --> 01:03:33.640
and we're going to use attention as

01:03:33.640 --> 01:03:38.050
a span internal mechanism to sort of approximate a head.

01:03:38.050 --> 01:03:42.205
So what we're going to do, uh, here,

01:03:42.205 --> 01:03:45.520
what we're going to do is we're going to want to

01:03:45.520 --> 01:03:50.020
learn attention weights, I'm just gonna, yeah.

01:03:50.020 --> 01:03:54.220
Um, what we're gonna do is for this span, um,

01:03:54.220 --> 01:03:58.810
we're going to be learning based on the hope,

01:03:58.810 --> 01:04:03.250
the ends of the span which words to pay how much attention to.

01:04:03.250 --> 01:04:06.970
So we're gonna put attention weights on the different words,

01:04:06.970 --> 01:04:09.730
and then we're going to, in the usual attention way,

01:04:09.730 --> 01:04:15.220
make this weighted sum of having put the word pair-

01:04:15.220 --> 01:04:19.360
the bidirectional LSTM pairs through a feed-forward network and end

01:04:19.360 --> 01:04:23.695
up with this new representation of a weighted representation.

01:04:23.695 --> 01:04:25.450
And the hope is that in this case,

01:04:25.450 --> 01:04:28.630
most of the weight will go on this final servers,

01:04:28.630 --> 01:04:30.445
which will be the headword.

01:04:30.445 --> 01:04:32.755
But there'll be sort of distributed across it.

01:04:32.755 --> 01:04:36.055
And so that gives them a model of

01:04:36.055 --> 01:04:41.875
sort of mentions that use both ends and hope to find the key word of the mention.

01:04:41.875 --> 01:04:46.015
Okay. Um, so, um,

01:04:46.015 --> 01:04:48.010
that's two-thirds of the span,

01:04:48.010 --> 01:04:51.235
but they still have over here these additional features.

01:04:51.235 --> 01:04:54.235
And so they still have some additional features.

01:04:54.235 --> 01:04:58.195
They want to be able to mark speakers and addressees.

01:04:58.195 --> 01:05:02.200
Um, they want to mark other things like the grammatical role.

01:05:02.200 --> 01:05:03.970
But if things occur, you know,

01:05:03.970 --> 01:05:07.240
it is still useful to have some additional features.

01:05:07.240 --> 01:05:08.620
And so what they do is,

01:05:08.620 --> 01:05:11.860
this is a representation of each span,

01:05:11.860 --> 01:05:16.390
and then they're going to want to say are two spans coreferent.

01:05:16.390 --> 01:05:22.120
And so they're going to have one score for the two, two split, each of two spans,

01:05:22.120 --> 01:05:23.365
which is essentially saying,

01:05:23.365 --> 01:05:24.850
is that a good mention?

01:05:24.850 --> 01:05:26.920
And then you're going to have scores of,

01:05:26.920 --> 01:05:29.170
do they look coreferent?

01:05:29.170 --> 01:05:34.870
And so having calculated these representations for each span,

01:05:34.870 --> 01:05:39.220
you're running three- through things through a fully connected feed-forward network,

01:05:39.220 --> 01:05:41.245
multiplying by a weight factor,

01:05:41.245 --> 01:05:42.490
and that's giving you, uh,

01:05:42.490 --> 01:05:44.635
is that a good mention score?

01:05:44.635 --> 01:05:46.960
And then for are they coreferent,

01:05:46.960 --> 01:05:49.330
you're taking two spans,

01:05:49.330 --> 01:05:53.650
the pointwise Hadamard product of two spans and

01:05:53.650 --> 01:05:56.140
some extra features like distance apart in

01:05:56.140 --> 01:05:59.469
the text and putting them through another neural network,

01:05:59.469 --> 01:06:01.285
and that's then giving you, are

01:06:01.285 --> 01:06:03.475
these two spans coreferent?

01:06:03.475 --> 01:06:05.590
But all of these pieces,

01:06:05.590 --> 01:06:10.480
um, give you an overall loss function.

01:06:10.480 --> 01:06:14.815
So you can say that your model is, um, okay.

01:06:14.815 --> 01:06:16.885
We're going to run these LSTMs,

01:06:16.885 --> 01:06:18.880
we're going to take all spans,

01:06:18.880 --> 01:06:20.829
we're going to score this,

01:06:20.829 --> 01:06:24.370
and we know the gold answer for our coreference system.

01:06:24.370 --> 01:06:29.200
And so we want to be predicting things that are coreferent and have

01:06:29.200 --> 01:06:34.375
a loss based on the probability that we calculate with these scores,

01:06:34.375 --> 01:06:35.770
um, as I had mentioned,

01:06:35.770 --> 01:06:39.205
ranking model using a softmax loss like before.

01:06:39.205 --> 01:06:42.775
So if you put all of this together and train it end to end,

01:06:42.775 --> 01:06:48.685
you've got a whole coreference system that goes from words to coreference decisions.

01:06:48.685 --> 01:06:52.045
Um, there's a huge problem with that,

01:06:52.045 --> 01:06:55.810
um, which is if you actually applied this naively, well,

01:06:55.810 --> 01:06:58.930
the problem is the number of spans in a piece of

01:06:58.930 --> 01:07:03.055
text is the square of the length of the text in words.

01:07:03.055 --> 01:07:06.400
And so therefore, if you're making coreference decisions,

01:07:06.400 --> 01:07:10.060
which are between, um, pairs of spans,

01:07:10.060 --> 01:07:13.060
you've then got an algorithm that's, um,

01:07:13.060 --> 01:07:15.415
O- OT to the fourth,

01:07:15.415 --> 01:07:18.025
where the length of the text is T words.

01:07:18.025 --> 01:07:22.375
So that's sort of really, really computationally impractical.

01:07:22.375 --> 01:07:23.515
So at this point,

01:07:23.515 --> 01:07:26.350
they sort of say, well, actually,

01:07:26.350 --> 01:07:29.905
we do want to use our mouths a little and we want to work out

01:07:29.905 --> 01:07:34.090
how likely different things are to be mentions.

01:07:34.090 --> 01:07:38.650
So effectively, um, then they're putting in a lot of pruning to

01:07:38.650 --> 01:07:43.765
decide which spans are actually things that they want to consider in their model.

01:07:43.765 --> 01:07:45.730
And so at this point, in some sense,

01:07:45.730 --> 01:07:47.170
it's a little bit of a cheat, right?

01:07:47.170 --> 01:07:50.440
Because really this pruning step here is okay,

01:07:50.440 --> 01:07:51.760
we're going to stick in

01:07:51.760 --> 01:07:54.205
a mention detection module,

01:07:54.205 --> 01:07:57.040
um, just like a conventional system.

01:07:57.040 --> 01:08:01.225
Um, but the prettiness of it is in terms of

01:08:01.225 --> 01:08:05.440
the algor- in terms of the loss function that's defined.

01:08:05.440 --> 01:08:09.730
The loss function is really defined end to end from just a sequence of

01:08:09.730 --> 01:08:14.380
tokens through to the mention ranking decisions.

01:08:14.380 --> 01:08:18.204
And so it is an end-to-end model,

01:08:18.204 --> 01:08:20.320
even though in practice to make it practical,

01:08:20.320 --> 01:08:24.680
you have to have something like a mention detector to get it to work.

01:08:26.100 --> 01:08:30.520
Okay. Pause for breath. Um, yeah,

01:08:30.520 --> 01:08:34.510
so there's one last.

01:08:34.510 --> 01:08:40.180
So we've done sort of mention pair model and mention ranking model.

01:08:40.180 --> 01:08:42.370
Um, and so for both of those,

01:08:42.370 --> 01:08:44.830
you're just taking individual mentions and saying,

01:08:44.830 --> 01:08:46.870
here's another mention, what,

01:08:46.870 --> 01:08:48.550
what shall I do with it?

01:08:48.550 --> 01:08:53.125
Let's look at mentions and see if we're coreferent to each other.

01:08:53.125 --> 01:09:00.280
And that there's no real concept of entities which are clusters of mentions.

01:09:00.280 --> 01:09:02.680
You're just making these sort of one-off decisions

01:09:02.680 --> 01:09:06.040
between pairs of mentions, and somehow,

01:09:06.040 --> 01:09:09.610
sort of the entities as clusters just

01:09:09.610 --> 01:09:14.050
emerge as a consequence of those mention pair decisions.

01:09:14.050 --> 01:09:19.555
So there's been this sort of long-standing feeling that,

01:09:19.555 --> 01:09:22.570
oh that can't really be right,

01:09:22.570 --> 01:09:28.060
the right way to do coreference must be really to do it as a clustering task,

01:09:28.060 --> 01:09:30.040
and people often refer to this as saying,

01:09:30.040 --> 01:09:33.235
we want entities as first-class citizens.

01:09:33.235 --> 01:09:34.600
So we want to be,

01:09:34.600 --> 01:09:40.300
sort of putting together mentions into clusters that represent the entities.

01:09:40.300 --> 01:09:45.010
And the obvious way to do that is to do a kind of bottom-up agglomerative clustering.

01:09:45.010 --> 01:09:46.900
So you start off by saying,

01:09:46.900 --> 01:09:49.855
each mention is its own singleton cluster,

01:09:49.855 --> 01:09:55.585
and then you're making decisions to merge clu- clusters which is initially,

01:09:55.585 --> 01:09:58.150
um, saying two mentions are coreferent.

01:09:58.150 --> 01:09:59.695
But as you go on with it,

01:09:59.695 --> 01:10:04.285
you're then making decisions that two clusters are coreferent or not.

01:10:04.285 --> 01:10:07.120
So the idea here is you'll have a piece of text,

01:10:07.120 --> 01:10:09.265
Google recently blah blah blah blah,

01:10:09.265 --> 01:10:12.055
the company announced Google Plus, blah blah blah blah,

01:10:12.055 --> 01:10:14.380
the product features blah blah blah blah.

01:10:14.380 --> 01:10:17.170
And so you have here some mentions.

01:10:17.170 --> 01:10:20.950
And so what you're going to do is start off saying that okay,

01:10:20.950 --> 01:10:24.445
there are these four mentions that each their own cluster.

01:10:24.445 --> 01:10:26.170
And then what we're gonna do,

01:10:26.170 --> 01:10:28.525
is we're going to make some decisions.

01:10:28.525 --> 01:10:32.740
Um, so we might decide that these two clusters

01:10:32.740 --> 01:10:37.375
are coreferent and merge them into one cluster.

01:10:37.375 --> 01:10:41.965
And then we might decide that these two,

01:10:41.965 --> 01:10:48.095
um, clusters are coreferent and merge them into one cluster.

01:10:48.095 --> 01:10:51.255
And so we're progressively clustering.

01:10:51.255 --> 01:10:54.030
And so then, we're going to look at these two clusters,

01:10:54.030 --> 01:10:56.835
cluster one and cluster two, and say,

01:10:56.835 --> 01:11:00.585
no we don't think those ones are coreferent,

01:11:00.585 --> 01:11:03.030
and therefore we're going to keep them apart.

01:11:03.030 --> 01:11:10.645
And so your, your coreference algorithm stops when there's nothing left to merge.

01:11:10.645 --> 01:11:15.430
And the reason why people think that this is the right thing to do is,

01:11:15.430 --> 01:11:19.930
the feeling is that if we sort of build partial clusters like this,

01:11:19.930 --> 01:11:22.405
that you'll be able to do a better job.

01:11:22.405 --> 01:11:24.040
Because if I just sort of say,

01:11:24.040 --> 01:11:25.615
well here are two mentions,

01:11:25.615 --> 01:11:27.459
Google and Google Plus,

01:11:27.459 --> 01:11:32.020
should they be regarded as co- coreferent or not?

01:11:32.020 --> 01:11:34.450
Um, well, since you're smart human beings,

01:11:34.450 --> 01:11:36.640
and know what Google is and know what Google Plus is,

01:11:36.640 --> 01:11:39.070
of course you'll answer no, of course not.

01:11:39.070 --> 01:11:40.495
Um, but, you know,

01:11:40.495 --> 01:11:43.180
if you're just a computer trying to make a decision,

01:11:43.180 --> 01:11:45.325
it's sort of hard to know the right answer,

01:11:45.325 --> 01:11:49.240
because there are lots of other cases when there are shortenings,

01:11:49.240 --> 01:11:52.030
where the right answer is that they're coreferent, right.

01:11:52.030 --> 01:11:56.199
Because if this is being Google and Google Corp,

01:11:56.199 --> 01:11:59.200
then it would have been right to regard them as coreferent.

01:11:59.200 --> 01:12:01.435
Or if it was sort of, um,

01:12:01.435 --> 01:12:04.210
something like Hillary Clinton and Hillary,

01:12:04.210 --> 01:12:06.610
it would have been right to regard them as coreferent.

01:12:06.610 --> 01:12:09.895
So it can often be kind of hard to tell what's coreferent.

01:12:09.895 --> 01:12:11.830
Um, but the hope is that,

01:12:11.830 --> 01:12:14.980
if you've made some of the easy decisions first,

01:12:14.980 --> 01:12:17.830
so if you decide Google and the company are coreferent

01:12:17.830 --> 01:12:20.950
and Google Plus and the product are coreferent,

01:12:20.950 --> 01:12:24.580
then it should be much easier to tell and to say,

01:12:24.580 --> 01:12:25.990
well product and company,

01:12:25.990 --> 01:12:27.865
they're definitely different things.

01:12:27.865 --> 01:12:31.510
And therefore we should keep these things separate.

01:12:31.510 --> 01:12:34.405
Um, and so that is the goal,

01:12:34.405 --> 01:12:36.955
and so to follow that goal,

01:12:36.955 --> 01:12:39.160
the kind of models people build.

01:12:39.160 --> 01:12:43.675
And this was actually a model that Kevin Clark is one of the PhD students here,

01:12:43.675 --> 01:12:46.080
um, and we did a couple of years ago.

01:12:46.080 --> 01:12:47.415
The idea was well,

01:12:47.415 --> 01:12:49.350
what we're going to do is,

01:12:49.350 --> 01:12:52.860
we're initially going to consider mentioned pairs,

01:12:52.860 --> 01:12:57.180
and build some kind of distributed, mention pair representation,

01:12:57.180 --> 01:13:01.815
which is kind of similar to what we were doing previously with the previous models.

01:13:01.815 --> 01:13:07.900
But we're then going to go beyond that and come up with cluster representations.

01:13:07.900 --> 01:13:11.095
And then we can look at cluster pair representations.

01:13:11.095 --> 01:13:16.045
And we would hope that by looking at these cluster representations,

01:13:16.045 --> 01:13:21.760
we'll be able to make better decisions of what to merge or what next to merge.

01:13:21.760 --> 01:13:27.760
Um, I have a few more slides that go through the Clark and Manning algorithm.

01:13:27.760 --> 01:13:30.490
Um, but I also have just a few minutes left.

01:13:30.490 --> 01:13:33.680
And so I think I'll skip the details.

01:13:33.680 --> 01:13:37.120
Um, I think the main thing that's interesting here,

01:13:37.120 --> 01:13:41.740
is the idea of clustering based coreference algorithms,

01:13:41.740 --> 01:13:43.465
and why in principle,

01:13:43.465 --> 01:13:45.490
it should give you extra oomph.

01:13:45.490 --> 01:13:49.135
Um, and that's sort of the main useful thing to get through.

01:13:49.135 --> 01:13:51.280
Because what I want to make sure we have covered in

01:13:51.280 --> 01:13:54.115
the last few minutes that I've said nothing at all about,

01:13:54.115 --> 01:13:58.630
is how do you evaluate coreference resolution and how well does it work?

01:13:58.630 --> 01:14:01.330
So let me skip ahead to that.

01:14:01.330 --> 01:14:07.120
Um, so if you look at coreference resolution papers,

01:14:07.120 --> 01:14:08.680
or something like that,

01:14:08.680 --> 01:14:15.250
um, there are many metrics that people have used to evaluate coreference,

01:14:15.250 --> 01:14:17.680
and they have a long alphabet soup of names.

01:14:17.680 --> 01:14:20.140
So there's MUC, and CEAF, and LEA,

01:14:20.140 --> 01:14:22.510
and B- CUBED, and BLANC and,

01:14:22.510 --> 01:14:24.010
um, things like that.

01:14:24.010 --> 01:14:29.080
Um, so effectively part of it is that if you look in the clustering literature,

01:14:29.080 --> 01:14:32.215
there are lots of ways that people try and evaluate clustering,

01:14:32.215 --> 01:14:36.610
and essentially any of those metrics and some other ones, you can, um,

01:14:36.610 --> 01:14:41.590
port over, um, to, um, coreference evaluation.

01:14:41.590 --> 01:14:45.895
I mean, why it's kind of difficult is the situation you have,

01:14:45.895 --> 01:14:49.900
is that you have a gold standard which picks out certain clusters,

01:14:49.900 --> 01:14:52.885
and the system picks out certain clusters,

01:14:52.885 --> 01:14:58.000
and you get some result like this and you have to decide how good it is.

01:14:58.000 --> 01:15:01.375
So I'm going to show you just quickly one particular algorithm.

01:15:01.375 --> 01:15:04.630
So the B-CUBED algorithm uses

01:15:04.630 --> 01:15:08.725
precision and recall and F-measure like we thought of before.

01:15:08.725 --> 01:15:11.290
So it looks at, uh,

01:15:11.290 --> 01:15:13.870
cluster identified by the system.

01:15:13.870 --> 01:15:19.105
And it says, well this cluster is four-fifths,

01:15:19.105 --> 01:15:20.890
um, gold cluster one,

01:15:20.890 --> 01:15:23.470
so the precision is four-fifths.

01:15:23.470 --> 01:15:28.240
But actually, um, there are six things in gold cluster one.

01:15:28.240 --> 01:15:33.760
So it only has a recall of four-sixth of that cluster.

01:15:33.760 --> 01:15:36.985
And then it similarly does for the other one,

01:15:36.985 --> 01:15:39.445
the same kind of calculation.

01:15:39.445 --> 01:15:43.990
And then it's going to average across the precisions and recalls,

01:15:43.990 --> 01:15:49.045
um, and it's going to come up with an overall, um, B-CUBED score.

01:15:49.045 --> 01:15:54.400
Um, in- if you think about this from an algorithm's perspective,

01:15:54.400 --> 01:15:57.205
this is actually tricky because I sort of said,

01:15:57.205 --> 01:16:00.460
um, okay, this cluster is mainly gold cluster one.

01:16:00.460 --> 01:16:03.730
So use that as its reference,

01:16:03.730 --> 01:16:06.820
but that means you have to do a bipartite graph alignment

01:16:06.820 --> 01:16:09.520
between system clusters, and gold clusters.

01:16:09.520 --> 01:16:12.955
So hidden in- hidden inside this evaluation,

01:16:12.955 --> 01:16:16.210
um, system is actually an NP-complete problem.

01:16:16.210 --> 01:16:19.525
But in practice you can normally do it heuristically well enough,

01:16:19.525 --> 01:16:21.610
that the evaluation method, um,

01:16:21.610 --> 01:16:23.245
runs and works.

01:16:23.245 --> 01:16:25.435
Um, okay.

01:16:25.435 --> 01:16:28.210
And so the kind of thing to notice is that,

01:16:28.210 --> 01:16:29.965
if you under cluster,

01:16:29.965 --> 01:16:32.350
you automatically get great precision,

01:16:32.350 --> 01:16:34.135
but you get bad recall.

01:16:34.135 --> 01:16:35.815
And if you over cluster,

01:16:35.815 --> 01:16:40.405
you get- get great recall because everything that should be in the same cluster is,

01:16:40.405 --> 01:16:42.910
um, but you get terrible precision.

01:16:42.910 --> 01:16:48.175
And so what you want to be doing is balancing those two things.

01:16:48.175 --> 01:16:51.280
Okay. Last two minutes,

01:16:51.280 --> 01:16:53.380
just to give you some idea of performance.

01:16:53.380 --> 01:16:58.285
So these are results from the OntoNotes dataset which is about 3,000 documents.

01:16:58.285 --> 01:17:01.495
Chinese, English, labeled for coreference.

01:17:01.495 --> 01:17:05.980
Um, the scores I'm reporting is actually an average over three metrics.

01:17:05.980 --> 01:17:09.295
One of which is the one I just showed you for B-CUBED,

01:17:09.295 --> 01:17:11.965
um, here are some numbers.

01:17:11.965 --> 01:17:17.245
Um, so Lee et al 2010 was the Stanford system.

01:17:17.245 --> 01:17:21.400
So there- there was this shared task evaluation of coreference systems.

01:17:21.400 --> 01:17:24.265
And we believe that Jerry Hobbs, um,

01:17:24.265 --> 01:17:28.885
was still right, and you could do fine with rule-based coreference.

01:17:28.885 --> 01:17:30.890
And so in 2010,

01:17:30.890 --> 01:17:36.030
we managed to beat all machine learning systems with a rule-based coreference system,

01:17:36.030 --> 01:17:37.725
and we were proud of it.

01:17:37.725 --> 01:17:40.455
Um, and that's its performance right here.

01:17:40.455 --> 01:17:42.240
Um, in subsequent years,

01:17:42.240 --> 01:17:45.150
people did start to do a bit better, um,

01:17:45.150 --> 01:17:50.110
with, um, with, uh, machine learning systems.

01:17:50.110 --> 01:17:51.820
But as you see, not very much,

01:17:51.820 --> 01:17:57.040
right for these 2012 systems that this one's somewhat,

01:17:57.040 --> 01:17:58.930
better this one really wasn't better,

01:17:58.930 --> 01:18:02.335
um, this, um, but making a bit of progress.

01:18:02.335 --> 01:18:07.975
Starting in 2015, there started to be neural systems.

01:18:07.975 --> 01:18:11.200
Um, so Wiseman et al was sort of the first neural system,

01:18:11.200 --> 01:18:14.245
I vaguely mentioned this Clark &amp; Manning system,

01:18:14.245 --> 01:18:16.945
and the numbers are going up into the mid-sixties.

01:18:16.945 --> 01:18:21.355
And this is the Kenton Lee system that has the end-to-end neural coreference,

01:18:21.355 --> 01:18:23.815
and on English is getting about 67.

01:18:23.815 --> 01:18:25.795
So something you'll notice from this,

01:18:25.795 --> 01:18:28.075
is the numbers aren't great.

01:18:28.075 --> 01:18:31.420
So coreference is still far from a solved problem.

01:18:31.420 --> 01:18:33.790
Um, so if you want to have a bit of fun, um,

01:18:33.790 --> 01:18:37.450
you can go out and try coreference systems for yourself.

01:18:37.450 --> 01:18:41.470
Um, there's a Stanford one on the first link or the one from Hugging Face

01:18:41.470 --> 01:18:44.965
is a good modern coreference system as well.

01:18:44.965 --> 01:18:47.740
And if you just try these out with some pieces of text,

01:18:47.740 --> 01:18:50.380
you'll notice they still get lots of things wrong.

01:18:50.380 --> 01:18:52.480
Um, so there's still more work to do,

01:18:52.480 --> 01:18:55.270
because this is just a harder language understanding task,

01:18:55.270 --> 01:18:57.535
[NOISE] which is just kind of like, um,

01:18:57.535 --> 01:19:01.270
Jerry Hobbs and Terry- Terry Winograd earlier observed.

01:19:01.270 --> 01:19:04.675
Okay, um, but I'll stop there for now. Thanks a lot.

01:19:04.675 --> 01:19:09.745
Um, oh yeah, I should have a reminder, invited speaker next Tuesday.

01:19:09.745 --> 01:19:11.575
Um, so I'll be taking,

01:19:11.575 --> 01:19:14.720
um, attendance for invited speakers.

