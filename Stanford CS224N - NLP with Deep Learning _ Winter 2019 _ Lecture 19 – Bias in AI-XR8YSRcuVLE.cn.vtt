WEBVTT
Kind: captions
Language: en

00:00:04.460 --> 00:00:07.800可以。大家好，我们开始吧。00:00:07.800 --> 00:00:10.935嗯，所以克里斯这周要旅行所以他不在这里。00:00:10.935 --> 00:00:13.320但我很高兴今天我们有00:00:13.320 --> 00:00:17.640玛格丽特・米切尔是谷歌人工智能的高级研究科学家。00:00:17.640 --> 00:00:20.435她会告诉我们最新的00:00:20.435 --> 00:00:23.625工作定义、理解和改进00:00:23.625 --> 00:00:27.255人工智能中带有偏见的情况。00:00:27.255 --> 00:00:30.395嗯，玛格丽特有一个在NLP工作和深入学习的背景，00:00:30.395 --> 00:00:33.440所以我真的很想听听她今天要说什么。把它拿走。00:00:33.440 --> 00:00:36.620太好了，谢谢。嗯，你们能听到我说话吗？00:00:36.620 --> 00:00:39.230我不确定这个麦克风是否能准确地听到我的声音，00:00:39.230 --> 00:00:41.300一切都很好？好的，酷。00:00:41.300 --> 00:00:44.285嗯，所以这项工作是，呃，00:00:44.285 --> 00:00:46.250一吨不同的人和00:00:46.250 --> 00:00:48.520我在这里尝试过的合作者。00:00:48.520 --> 00:00:53.330嗯，斯坦福大学的一些学生还有约翰・霍普金斯，谷歌，00:00:53.330 --> 00:00:58.820Facebook和微软都很有代表性，很酷。00:00:58.820 --> 00:01:05.915所以，嗯，对于你们这些以前没看过幻灯片的人来说，00:01:05.915 --> 00:01:08.480你在这里看到什么？大声喊出来。00:01:08.480 --> 00:01:10.130香焦。00:01:10.130 --> 00:01:12.130香焦。好的，还有什么？00:01:12.130 --> 00:01:13.345贴纸。00:01:13.345 --> 00:01:14.570贴纸。还有什么？00:01:14.570 --> 00:01:20.810[噪音]架子。还有什么？00:01:20.810 --> 00:01:21.995一串香蕉。00:01:21.995 --> 00:01:24.540一串香蕉。还有什么？00:01:24.580 --> 00:01:28.025黄熟香蕉。00:01:28.025 --> 00:01:30.500你说熟香蕉，很好。00:01:30.500 --> 00:01:34.730所以你可以在香蕉上贴上标签。00:01:34.730 --> 00:01:37.400你可以开始做，比如，嵌入子句，00:01:37.400 --> 00:01:41.180在商店的架子上贴着几束香蕉，有点疯狂。00:01:41.180 --> 00:01:44.875但我们不喜欢说黄香蕉，对吧？00:01:44.875 --> 00:01:47.160所以有了这样的东西，00:01:47.160 --> 00:01:51.455我们可以说生香蕉，也可以说生香蕉。00:01:51.455 --> 00:01:55.130有了这样的形象，我们可能会说熟香蕉或者，00:01:55.130 --> 00:01:57.340嗯，上面有斑点的香蕉。00:01:57.340 --> 00:02:00.935如果你是我，你可能会说香蕉对香蕉面包有好处。00:02:00.935 --> 00:02:05.240嗯，但如果在现实世界中有这样或那样的图像，00:02:05.240 --> 00:02:07.955我们倾向于不提黄色。00:02:07.955 --> 00:02:12.710这是因为黄色是香蕉的原型。00:02:12.710 --> 00:02:15.545所以原型的想法，呃，00:02:15.545 --> 00:02:18.620源于70年代早期的原型理论，00:02:18.620 --> 00:02:21.795呃，从埃莉诺・罗斯奇和同事的工作中走出来。00:02:21.795 --> 00:02:23.750嗯，就是这个想法00:02:23.750 --> 00:02:28.335一些储存在中心的物体原型概念，00:02:28.335 --> 00:02:31.559嗯，我们在操作时访问，00:02:31.559 --> 00:02:33.065呃，全世界。00:02:33.065 --> 00:02:36.950关于这些原型是否00:02:36.950 --> 00:02:42.320对象的实际示例或类似于在可能的情况下的分布，00:02:42.320 --> 00:02:45.440但总的来说我们确实有一些，00:02:45.440 --> 00:02:49.340感觉到什么是典型的，什么是典型的00:02:49.340 --> 00:02:55.200世界和我们往往会注意到和谈论一些不典型的事情。00:02:55.400 --> 00:02:59.330嗯，这是个谜，我00:02:59.330 --> 00:03:02.710在中学里听到的，那时工作更努力一点，00:03:02.710 --> 00:03:04.895嗯，你们有些人可能以前听过。00:03:04.895 --> 00:03:06.350一个男人和他的儿子在00:03:06.350 --> 00:03:09.875一场可怕的事故被紧急送往医院。00:03:09.875 --> 00:03:12.245医生看着那个男孩，惊叫道，00:03:12.245 --> 00:03:13.775“我不能给这个孩子动手术，00:03:13.775 --> 00:03:17.070他是我儿子，“怎么会这样？[噪音]。00:03:17.070 --> 00:03:19.190两个爸爸？00:03:19.190 --> 00:03:22.905两个爸爸或者他有一个妈妈是医生，对吧。00:03:22.905 --> 00:03:25.920又称女医生，00:03:25.920 --> 00:03:29.090可能会被感染――与医生相比。00:03:29.090 --> 00:03:31.920嗯，在一项研究中他们做到了，00:03:31.920 --> 00:03:33.120呃，当他们第一次，有点，00:03:33.120 --> 00:03:36.450在波士顿大学提出这个谜语，00:03:36.450 --> 00:03:38.375他们发现大多数受试者00:03:38.375 --> 00:03:41.510忽视了医生可能是她的可能性。00:03:41.510 --> 00:03:45.695包括男人，女人和自我描述的女权主义者。00:03:45.695 --> 00:03:46.940重点是，00:03:46.940 --> 00:03:49.100这些，有点，呃，00:03:49.100 --> 00:03:52.880谈论我们所做的事情和假设的方式，00:03:52.880 --> 00:03:58.070不一定是有消极意图的东西，00:03:58.070 --> 00:04:01.670但它说明了我们如何将表示存储在00:04:01.670 --> 00:04:05.600我们的思想以及我们如何在交互时访问这些表示，00:04:05.600 --> 00:04:07.285呃，在这个世界上。00:04:07.285 --> 00:04:11.825所以，这，呃，这会影响我们从文本中学习到什么。00:04:11.825 --> 00:04:15.395所以，嗯，这是从2013年开始的工作，00:04:15.395 --> 00:04:17.300在那里他们看了一眼00:04:17.300 --> 00:04:21.355很可能，如果你只是从原始文本中学习，你会学到什么？00:04:21.355 --> 00:04:24.440嗯，世界上常见的东西是什么？00:04:24.440 --> 00:04:28.070嗯，他们发现在这个装置里00:04:28.070 --> 00:04:32.090像谋杀这样的事情发生的可能性是眨眼的10倍。00:04:32.090 --> 00:04:34.850这是因为人们倾向于00:04:34.850 --> 00:04:38.150更不用说这些典型的不言而喻的事情了。00:04:38.150 --> 00:04:42.500我们一般不会提到眨眼和呼吸之类的事情，00:04:42.500 --> 00:04:47.250但我们确实提到了诸如谋杀之类的非典型事件00:04:47.250 --> 00:04:50.960机器可以从我们在世界上发布的文本中学习到的东西，00:04:50.960 --> 00:04:52.490因为它一直受到00:04:52.490 --> 00:04:57.135这些过滤过程是我们作为人类在交流之前所拥有的。00:04:57.135 --> 00:05:01.690嗯，这个问题特别被称为人类报告偏见。00:05:01.690 --> 00:05:04.010人们写作的频率是多少00:05:04.010 --> 00:05:06.650关于行动、结果或属性，00:05:06.650 --> 00:05:09.470不是真实频率的反射，或00:05:09.470 --> 00:05:13.010财产是一类个人的特征的程度，00:05:13.010 --> 00:05:14.990但更多的是关于我们的实际情况00:05:14.990 --> 00:05:18.205处理世界和我们所认为的是非凡的。00:05:18.205 --> 00:05:22.350所以这会影响系统所能学到的一切。00:05:22.350 --> 00:05:24.620嗯，在典型的机器学习模式中，00:05:24.620 --> 00:05:29.210第一步是收集培训数据并对其进行注释。00:05:29.210 --> 00:05:32.230从那里可以训练一个模型，00:05:32.230 --> 00:05:34.965呃，从那里，呃，00:05:34.965 --> 00:05:38.340可以对媒体进行过滤、排名、聚合，00:05:38.340 --> 00:05:39.900以某种方式产生的，00:05:39.900 --> 00:05:42.985嗯，从那里人们可以看到输出。00:05:42.985 --> 00:05:46.699我们认为这是一条相对简单的管道，00:05:46.699 --> 00:05:49.100嗯，但一开始，呃，00:05:49.100 --> 00:05:51.080甚至在我们收集数据之前，00:05:51.080 --> 00:05:52.895实际上，在数据本身中，00:05:52.895 --> 00:05:55.940是人类各种各样的偏见。00:05:55.940 --> 00:05:58.580像是成见，偏见，00:05:58.580 --> 00:06:03.080像种族主义之类的东西在我们收集数据之前就已经被嵌入了数据中。00:06:03.080 --> 00:06:05.600然后，当我们收集和注释数据时，00:06:05.600 --> 00:06:07.745进一步的偏见被引入。00:06:07.745 --> 00:06:11.815比如抽样误差，确认偏差，嗯，00:06:11.815 --> 00:06:15.050呃，小组内偏见和小组外偏见，我来谈谈这些，00:06:15.050 --> 00:06:16.070嗯，有点。00:06:16.070 --> 00:06:19.625哦，我应该提一下，在我走的时候，请随意提问，00:06:19.625 --> 00:06:21.380嗯，完全可以，00:06:21.380 --> 00:06:23.825有点，互动，呃，贯穿始终。00:06:23.825 --> 00:06:27.290所以这里有一些我认为是的偏见00:06:27.290 --> 00:06:30.320在人工智能和机器学习方面相对重要。00:06:30.320 --> 00:06:32.570你可以进入数百个，00:06:32.570 --> 00:06:34.370嗯，但是我有的，有点，00:06:34.370 --> 00:06:36.750成为最了解在这个空间工作的人，00:06:36.750 --> 00:06:39.680嗯，这些是套装，我会逐一检查一下。00:06:39.680 --> 00:06:42.140嗯，所以我之前谈过报告偏见，00:06:42.140 --> 00:06:45.470也就是说，呃，这会影响我们从文本中学到什么。00:06:45.470 --> 00:06:48.890嗯，另一个例子00:06:48.890 --> 00:06:52.135真正影响我们从文本中学习的是选择偏差。00:06:52.135 --> 00:06:54.835所以，很多时候我们，00:06:54.835 --> 00:06:57.440很多时候，当我们得到数据注释时，我们会用到一些东西00:06:57.440 --> 00:07:00.230就像亚马逊的机械土耳其人，嗯，00:07:00.230 --> 00:07:03.890世界各地的工人分布也不均匀，00:07:03.890 --> 00:07:06.485均匀分布，实际上，00:07:06.485 --> 00:07:09.920主要集中在印度、美国和欧洲。00:07:09.920 --> 00:07:12.065所以这就排除了南美，00:07:12.065 --> 00:07:13.250把非洲排除在外，00:07:13.250 --> 00:07:16.220这遗漏了很多中国，这影响了，00:07:16.220 --> 00:07:20.640当我们对事物进行注释时，我们能够了解这个世界的东西。00:07:20.920 --> 00:07:25.250另一种偏差是组外同质性偏差，00:07:25.250 --> 00:07:29.405这是一种倾向，认为群体成员比群体成员更相似。00:07:29.405 --> 00:07:32.420这会影响人们所能描述的00:07:32.420 --> 00:07:35.575当他们在注释诸如情绪之类的东西时谈论。00:07:35.575 --> 00:07:38.565例如，我们有这两个，比如，00:07:38.565 --> 00:07:42.265左边是可爱的小狗，他们看着这四只猫。00:07:42.265 --> 00:07:44.715嗯，这些都是不同的黑猫，00:07:44.715 --> 00:07:46.200在不同的方面非常不同，00:07:46.200 --> 00:07:50.825但是这两只小狗看着猫，他们看到四只猫基本上是一样的。00:07:50.825 --> 00:07:53.720理解它是如何延伸到00:07:53.720 --> 00:07:56.795人类的认知以及我们如何处理人。00:07:56.795 --> 00:07:59.869嗯，就是这样-这就是我们的感觉，00:07:59.869 --> 00:08:01.915我们所在的团队，00:08:01.915 --> 00:08:03.560与我们互动的人，00:08:03.560 --> 00:08:06.230这些人是细微差别的00:08:06.230 --> 00:08:08.930其他人都没有那么微妙，00:08:08.930 --> 00:08:10.715对他们来说细节更少。00:08:10.715 --> 00:08:14.870这是我们头脑中的一个小把戏，目的是帮助我们处理世界，00:08:14.870 --> 00:08:19.380但它会影响我们如何谈论它，并进一步影响我们如何注释它。00:08:19.930 --> 00:08:24.055嗯，这会导致有偏见的数据表示。00:08:24.055 --> 00:08:27.170因此，您可能有适当数量的数据用于00:08:27.170 --> 00:08:30.710在你的数据中你能想到的每一个可能的人类群体，00:08:30.710 --> 00:08:32.945嗯，但可能有些团体00:08:32.945 --> 00:08:35.090比其他人更不积极。00:08:35.090 --> 00:08:37.190如果我们有时间，我会去，呃，00:08:37.190 --> 00:08:39.970一个很长的例子。00:08:39.970 --> 00:08:43.045嗯，这也会导致有偏见的标签。00:08:43.045 --> 00:08:46.160所以，嗯，这是我们在00:08:46.160 --> 00:08:49.580获取一些关于包容性图像竞争的注释，00:08:49.580 --> 00:08:54.605要求人们对新娘、婚礼和新郎等事物进行注释。00:08:54.605 --> 00:08:57.100我们发现给了三个不同类型的新娘，00:08:57.100 --> 00:08:58.685婚礼和新郎形象，00:08:58.685 --> 00:09:03.465嗯，那些更西方的，欧洲裔美国人，呃，00:09:03.465 --> 00:09:06.985找到了合适的标签，但没有，00:09:06.985 --> 00:09:09.190只是有点普通人，00:09:09.190 --> 00:09:11.235种类，标签，呃，00:09:11.235 --> 00:09:17.960无法真正梳理出这些图像中实际发生的事情。00:09:17.960 --> 00:09:21.160使这个问题复杂化是解释上的偏见。00:09:21.160 --> 00:09:24.145当模型输出，呃，它的决定。00:09:24.145 --> 00:09:27.820所以，嗯，一个问题是确认偏差，00:09:27.820 --> 00:09:30.820这就是寻找、解释、偏爱，00:09:30.820 --> 00:09:34.180以一种确认先前信仰的方式回忆信息。00:09:34.180 --> 00:09:36.520所以很多时候我们，呃，00:09:36.520 --> 00:09:40.120构建端到端系统，并尝试测试我们的假设，00:09:40.120 --> 00:09:42.325我们只是在测试，呃，00:09:42.325 --> 00:09:46.525我们希望成为真实的事物，并以一种能够00:09:46.525 --> 00:09:49.000呃，帮我们确认一下我们想要的是真的。00:09:49.000 --> 00:09:52.120嗯，泛化过度00:09:52.120 --> 00:09:55.765基于过于笼统或不够具体的信息得出的结论。00:09:55.765 --> 00:09:58.165嗯，这是一个经常发生的问题00:09:58.165 --> 00:10:01.555在深度学习模型结果分析中，嗯，00:10:01.555 --> 00:10:03.760假设有，00:10:03.760 --> 00:10:05.470有个将军，呃，00:10:05.470 --> 00:10:08.515结论是，如果真的只是00:10:08.515 --> 00:10:10.615嗯，一个真正扭曲数据的影响。00:10:10.615 --> 00:10:13.900嗯，这也与过度拟合密切相关00:10:13.900 --> 00:10:17.275是一种机器学习版本的过度泛化，00:10:17.275 --> 00:10:20.050这就是你仍然在做预测和结果的地方，00:10:20.050 --> 00:10:23.965但它基于一小部分可能的特性，嗯，00:10:23.965 --> 00:10:28.600所以它实际上并没有为结果捕获正确特性的空间，00:10:28.600 --> 00:10:31.795呃，正确的输出预测。00:10:31.795 --> 00:10:35.320嗯，还有一个相关谬误，00:10:35.320 --> 00:10:37.975这就混淆了因果关系。00:10:37.975 --> 00:10:40.510这在谈论什么的时候又发生了很多00:10:40.510 --> 00:10:41.920机器学习模式是学习和00:10:41.920 --> 00:10:44.575深度学习模式尤其是学习，00:10:44.575 --> 00:10:47.095就因为事情发生在一起，00:10:47.095 --> 00:10:49.240这并不意味着一个导致了另一个，00:10:49.240 --> 00:10:50.770但是，呃，模特们不会告诉你00:10:50.770 --> 00:10:52.900任何东西-深度学习模式直接不会00:10:52.900 --> 00:10:55.150告诉你关于因果关系的任何事情。00:10:55.150 --> 00:10:58.030因此，很容易想到，一些预测的产出00:10:58.030 --> 00:11:01.195基于相关性实际上是因果关系，00:11:01.195 --> 00:11:03.310我也会讲一些例子。00:11:03.310 --> 00:11:07.120还有一个问题是自动化偏差，00:11:07.120 --> 00:11:10.870这确实影响了我们在世界上推出的机器学习模型，00:11:10.870 --> 00:11:15.010然后被司法系统等系统中的人利用。00:11:15.010 --> 00:11:17.215嗯，这就是，嗯，00:11:17.215 --> 00:11:19.750赞成00:11:19.750 --> 00:11:24.535自动预测输出预测的模型，00:11:24.535 --> 00:11:27.880嗯，呃，不同种类的嗯，00:11:27.880 --> 00:11:29.740其他人的建议。00:11:29.740 --> 00:11:33.070嗯，即使面对矛盾的证据，这种情况也会发生。00:11:33.070 --> 00:11:36.085所以，如果系统告诉你，“这个，00:11:36.085 --> 00:11:40.810这是分数，或者这是这个人的风险“，00:11:40.810 --> 00:11:45.970我们更可能认为这是真的，因为它来自一个数学系统，00:11:45.970 --> 00:11:48.850我们自然而然地认为这更客观，00:11:48.850 --> 00:11:50.860一些更为数学化的东西00:11:50.860 --> 00:11:53.440在某种程度上比人类更真实。00:11:53.440 --> 00:11:56.155嗯，这就是自动化偏差。00:11:56.155 --> 00:11:58.915所以，嗯，而不是这种00:11:58.915 --> 00:12:02.215清除我们在机器学习中的直接管道，00:12:02.215 --> 00:12:06.430嗯，数据一开始就有人类偏见，嗯，00:12:06.430 --> 00:12:10.570然后在数据收集、注释和00:12:10.570 --> 00:12:14.290然后在我们训练这些数据时通过系统进一步传播，00:12:14.290 --> 00:12:17.605嗯，当我们开始根据这些数据输出数据时，00:12:17.605 --> 00:12:19.195当人们对这些数据采取行动时。00:12:19.195 --> 00:12:21.385这就形成了一个反馈循环，00:12:21.385 --> 00:12:25.555我们为人们所做的事情，00:12:25.555 --> 00:12:27.520嗯，是的，是的，00:12:27.520 --> 00:12:31.345然后作为输入系统的进一步培训数据，00:12:31.345 --> 00:12:36.640所以你最终会进一步放大这些不同类型的隐含偏见。00:12:36.640 --> 00:12:41.935这就是所谓的偏见网络效应或偏见“洗钱”，我喜欢称之为。00:12:41.935 --> 00:12:47.530因此，信息是人类的数据使人类的偏见永存。00:12:47.530 --> 00:12:51.400当机器学习或深度学习从人类数据中学习时，00:12:51.400 --> 00:12:54.025结果是偏压网络效应。00:12:54.025 --> 00:13:01.210所以，我想避免这样的想法，如果我说偏见，或者有人说偏见等于坏，00:13:01.210 --> 00:13:03.130比这更微妙一点。00:13:03.130 --> 00:13:05.650嗯，所以有很多人00:13:05.650 --> 00:13:08.155当他们谈论偏见时，00:13:08.155 --> 00:13:12.415在某些情况下，即使是同样的偏见也可能是好的，在某些情况下也是坏的，00:13:12.415 --> 00:13:14.590所以统计和ML中的偏差。00:13:14.590 --> 00:13:17.410我们讨论一个估计量的偏差，它是00:13:17.410 --> 00:13:20.980预测和真相，基本真相之间的区别。00:13:20.980 --> 00:13:24.085我们讨论线性回归中的偏倚项。00:13:24.085 --> 00:13:26.649嗯，我们也有认知偏见，00:13:26.649 --> 00:13:28.210我一开始就谈到了，00:13:28.210 --> 00:13:30.220不是所有这些都是负面的，或者，00:13:30.220 --> 00:13:31.675或者必须是，呃，00:13:31.675 --> 00:13:33.400或者必须被视为负面的。00:13:33.400 --> 00:13:36.430所以乐观是另一种偏见，我们可以00:13:36.430 --> 00:13:39.640这会影响我们的世界观和我们处理事情的方式。00:13:39.640 --> 00:13:42.250嗯，甚至是最近的偏见和00:13:42.250 --> 00:13:45.760确认偏见只是我们大脑喜欢的方式，嗯，00:13:45.760 --> 00:13:50.080处理所有不同事物的组合爆炸00:13:50.080 --> 00:13:52.030在这个世界上是真的，把它归结为00:13:52.030 --> 00:13:55.060在现实世界中我们可以用它来操作。00:13:55.060 --> 00:13:58.345嗯，所以算法偏差很大00:13:58.345 --> 00:14:01.645人们的意思是在头条和我们谈论偏见的时候，00:14:01.645 --> 00:14:03.790更重要的是，呃，不公正，00:14:03.790 --> 00:14:07.510不公平或有偏见的对待是00:14:07.510 --> 00:14:09.610自动化决策系统。00:14:09.610 --> 00:14:12.505嗯，这里的重点是，00:14:12.505 --> 00:14:15.460对人的不公正、不公平或有偏见的待遇。00:14:15.460 --> 00:14:19.315所以，现在这个领域的很多工作都集中在试图理解，00:14:19.315 --> 00:14:22.480不公正的算法意味着什么？00:14:22.480 --> 00:14:25.570从算法上看，不公平意味着什么？00:14:25.570 --> 00:14:27.190我们如何处理这个问题，00:14:27.190 --> 00:14:30.490我们如何才能减轻这些问题，以便00:14:30.490 --> 00:14:34.675在不加剧社会分化的前提下，开发对人们有用的技术。00:14:34.675 --> 00:14:41.170嗯，我觉得几年前卫报说得很好。00:14:41.170 --> 00:14:45.295嗯，他们说，“尽管可以说神经网络是自己写程序的，00:14:45.295 --> 00:14:50.125他们这样做是为了实现人类利用为人类目的收集的数据设定的目标。00:14:50.125 --> 00:14:52.420如果数据有偏差，即使是偶然的，00:14:52.420 --> 00:14:54.865电脑会加剧不公正。”00:14:54.865 --> 00:14:58.540而且，这一点确实放大了不公正的想法。00:14:58.540 --> 00:15:01.555嗯，我们来谈谈这意味着什么。00:15:01.555 --> 00:15:05.680所以，深入学习研究的途径之一就是00:15:05.680 --> 00:15:09.415在过去几年中起飞的飞机预示着犯罪行为。00:15:09.415 --> 00:15:14.020嗯，那么，嗯，你们中有多少人熟悉预测性警务？00:15:14.020 --> 00:15:17.995[噪音]好吧，一半的学生。00:15:17.995 --> 00:15:22.345可以。所以，在预测性警务中，算法，嗯，00:15:22.345 --> 00:15:28.675预测可能发生犯罪的地方部署军官。00:15:28.675 --> 00:15:33.520但是模型训练出来的数据00:15:33.520 --> 00:15:38.935根据警察已经去的地方和逮捕的地方。00:15:38.935 --> 00:15:42.520所以，系统只是在学习偏见的模式00:15:42.520 --> 00:15:46.900人类有，他们去哪里，他们试图决定去哪里，呃，00:15:46.900 --> 00:15:48.820为了找到犯罪，嗯，00:15:48.820 --> 00:15:50.425然后反射回来。00:15:50.425 --> 00:15:52.930所以，因为这个系统可以接通00:15:52.930 --> 00:15:56.125人们被逮捕的首要地点，00:15:56.125 --> 00:15:57.940注意，这和…不一样00:15:57.940 --> 00:16:00.490和犯罪地点一样，对吧？00:16:00.490 --> 00:16:02.440这就是逮捕的地方。00:16:02.440 --> 00:16:04.720嗯，这意味着其他地区00:16:04.720 --> 00:16:07.240可能是因为犯罪而被调查，根本不被调查。00:16:07.240 --> 00:16:09.175这使情况恶化。00:16:09.175 --> 00:16:10.795嗯，一些社区，呃，00:16:10.795 --> 00:16:14.080把注意力集中在他们身上，00:16:14.080 --> 00:16:16.810这就增加了对00:16:16.810 --> 00:16:19.735即使是轻微的违法行为，也意味着逮捕。00:16:19.735 --> 00:16:22.060这意味着一个数据反馈循环00:16:22.060 --> 00:16:25.400如果你去那里，你会被逮捕的。00:16:25.470 --> 00:16:33.085嗯，这个领域的另一个相关问题是，嗯，预测性判刑。00:16:33.085 --> 00:16:36.100嗯，有一篇很好的文章出来了00:16:36.100 --> 00:16:39.280几年前从Pro-Propublica讨论过。00:16:39.280 --> 00:16:41.950但是当大多数被告被判入狱后，00:16:41.950 --> 00:16:44.320他们对一份叫做COMPAS的调查问卷做出了回应。00:16:44.320 --> 00:16:47.920嗯，他们的答案被输入这个软件系统00:16:47.920 --> 00:16:51.640生成与累犯风险相对应的分数，00:16:51.640 --> 00:16:53.500这就是呃的风险，00:16:53.500 --> 00:16:55.330呃，又犯了罪。00:16:55.330 --> 00:16:57.970嗯，这些问题是用来收集数据的00:16:57.970 --> 00:17:00.565关于被告的社会经济地位，00:17:00.565 --> 00:17:03.070家庭背景，社区犯罪，00:17:03.070 --> 00:17:05.830就业状况等因素以达到00:17:05.830 --> 00:17:11.785一些预测-个人犯罪或刑事风险的预测。00:17:11.785 --> 00:17:17.470嗯，但最终发生的是它最终集中在关键的偏见问题上00:17:17.470 --> 00:17:19.600人类拥有并传播它00:17:19.600 --> 00:17:23.215回到客观的分数。00:17:23.215 --> 00:17:26.065所以，你更有可能，嗯，00:17:26.065 --> 00:17:28.315被判有罪，嗯，00:17:28.315 --> 00:17:30.055如果你是黑人而不是白人，00:17:30.055 --> 00:17:31.975即使你犯了同样的罪行。00:17:31.975 --> 00:17:34.330系统会发现这一点，00:17:34.330 --> 00:17:36.790并将反映出这一点，即00:17:36.790 --> 00:17:39.580黑人更有可能有累犯一样的累犯，00:17:39.580 --> 00:17:41.020更有可能判A有罪，00:17:41.020 --> 00:17:43.165呃，再次犯罪。00:17:43.165 --> 00:17:49.885嗯，这是一个自动化偏差的例子，倾向于系统的输出，呃，00:17:49.885 --> 00:17:54.085面对过度泛化，反馈循环，00:17:54.085 --> 00:17:55.795以及相关谬误，00:17:55.795 --> 00:18:00.620把一起发生的事情混淆为某种因果关系。00:18:02.520 --> 00:18:06.985还有另一个研究领域，00:18:06.985 --> 00:18:12.010初创公司特别是从人脸图像等方面预测犯罪行为。00:18:12.010 --> 00:18:14.890所以外面有一家公司，呃，叫做FaceOption。00:18:14.890 --> 00:18:18.520他们的基地在以色列，他们声称能够，00:18:18.520 --> 00:18:21.625嗯，使用个人图片，呃，00:18:21.625 --> 00:18:25.150利用计算机视觉和机器学习技术对人进行分析00:18:25.150 --> 00:18:28.855只根据他们的面部形象来展现他们的个性，00:18:28.855 --> 00:18:32.395嗯，认识到像高智商这样的东西，00:18:32.395 --> 00:18:35.575白领罪犯、恋童癖者和恐怖分子。00:18:35.575 --> 00:18:38.350嗯，他们的主要客户是国土安全部，00:18:38.350 --> 00:18:39.550很多其他的，呃，00:18:39.550 --> 00:18:42.985许多其他国家都在处理公共安全问题。00:18:42.985 --> 00:18:45.760他们没有公布任何关于他们方法的细节，00:18:45.760 --> 00:18:47.425他们的培训数据来源，00:18:47.425 --> 00:18:49.090或者他们的定量结果。00:18:49.090 --> 00:18:50.980我们知道，鉴于自动化的偏见，00:18:50.980 --> 00:18:54.535人们会倾向于认为它只是在工作不好的时候才起作用。00:18:54.535 --> 00:18:57.700嗯，但有一份报纸是从网上发出来的00:18:57.700 --> 00:19:01.765一条类似的预测犯罪、犯罪行为的线，00:19:01.765 --> 00:19:05.890或声称根据个人面部图像预测犯罪，00:19:05.890 --> 00:19:08.110而且那个有一些结果，00:19:08.110 --> 00:19:11.350呃，关于我们可以挖掘的数据的更多细节00:19:11.350 --> 00:19:15.100了解这些索赔的来源。00:19:15.100 --> 00:19:19.880嗯，这是一篇发表在2016年底档案馆的文章。00:19:19.880 --> 00:19:26.230嗯，他们说他们用了不到2000张修剪过的面部图片，00:19:26.230 --> 00:19:30.415包括特定地区的通缉嫌疑犯照片，00:19:30.415 --> 00:19:35.035他们声称即使基于这个非常小的训练数据集，00:19:35.035 --> 00:19:37.540他们能够预测，呃，00:19:37.540 --> 00:19:40.240不管有没有人可能是罪犯，00:19:40.240 --> 00:19:42.640超过90%的准确度。00:19:42.640 --> 00:19:45.235嗯，他们在这件事上迷路了，00:19:45.235 --> 00:19:47.020这个想法，呃，00:19:47.020 --> 00:19:49.150读起来很有趣00:19:49.150 --> 00:19:51.640退后一步，意识到正在发生的事情。00:19:51.640 --> 00:19:52.840例如，00:19:52.840 --> 00:19:57.640他们真正令人兴奋的说法是从鼻尖到00:19:57.640 --> 00:19:59.770平均两个嘴角00:19:59.770 --> 00:20:03.640罪犯比非罪犯少19.6%。00:20:03.640 --> 00:20:05.980这就是微笑。[笑声]00:20:05.980 --> 00:20:09.070嗯，还有[笑声]你知道，00:20:09.070 --> 00:20:11.170正是人们想要的那种形象00:20:11.170 --> 00:20:13.780在试图发布通缉犯罪照片时使用，00:20:13.780 --> 00:20:15.655可能不是很开心的照片。00:20:15.655 --> 00:20:18.265但是你在确认偏差中迷失了方向。00:20:18.265 --> 00:20:20.230你在相关性和00:20:20.230 --> 00:20:22.930你最终忽略了这些反馈循环00:20:22.930 --> 00:20:25.945很明显的事情。00:20:25.945 --> 00:20:29.010嗯，这就是选择偏差的一个例子，00:20:29.010 --> 00:20:32.880实验者偏差，确认偏差，相关谬误，00:20:32.880 --> 00:20:36.090和反馈回路一起创造00:20:36.090 --> 00:20:37.950人们认为的深度学习系统00:20:37.950 --> 00:20:40.730很可怕，可以做一些它实际上做不到的事情。00:20:40.730 --> 00:20:44.485嗯，其中一个问题是媒体喜欢它。00:20:44.485 --> 00:20:46.180就像新闻里到处都是一样，00:20:46.180 --> 00:20:49.060类似的事情不断发生。00:20:49.060 --> 00:20:51.175媒体想卖掉这个故事，00:20:51.175 --> 00:20:53.830所以这是我们作为研究人员工作的一部分，00:20:53.830 --> 00:20:55.315做这件事的人，00:20:55.315 --> 00:20:58.615要非常清楚这项技术到底在做什么，00:20:58.615 --> 00:21:00.760嗯，区分一下你00:21:00.760 --> 00:21:03.520可能认为它在做什么和它实际上在做什么。00:21:03.520 --> 00:21:07.930嗯，最近又出现了一个问题，嗯，00:21:07.930 --> 00:21:09.490它声称能够预测00:21:09.490 --> 00:21:13.660内部品质，特别是受到歧视的品质，00:21:13.660 --> 00:21:15.535嗯，失去了机会。00:21:15.535 --> 00:21:18.610因此，特别是，有一项工作声称00:21:18.610 --> 00:21:21.565为了能够预测某人是否是同性恋，00:21:21.565 --> 00:21:23.905只是基于单张脸的图像。00:21:23.905 --> 00:21:28.390嗯，现在，重要的是要知道他们在研究中使用的图像包括00:21:28.390 --> 00:21:33.400那些来自约会网站的图片，人们自称是异性恋或同性恋，00:21:33.400 --> 00:21:37.045确定他们是在寻找异性恋还是同性恋的伴侣，00:21:37.045 --> 00:21:40.015这些成为了培训数据的来源，00:21:40.015 --> 00:21:41.890还是从这个开始，呃。00:21:41.890 --> 00:21:44.470哦！在我继续之前，你们能理解吗？00:21:44.470 --> 00:21:47.500就这样，问题可能是什么？00:21:47.500 --> 00:21:48.640彩虹。00:21:48.640 --> 00:21:54.250[笑声]我不认为有任何关于彩虹的东西，00:21:54.250 --> 00:21:55.390但这真的很不幸。00:21:55.390 --> 00:21:59.980[笑声]。00:21:59.980 --> 00:22:00.280[听不见]00:22:00.280 --> 00:22:03.475正确的。是啊。所以这与自我的表现有更多的关系，00:22:03.475 --> 00:22:07.030例如，当你试图表达社会自我时，00:22:07.030 --> 00:22:08.784在网站上吸引合作伙伴，00:22:08.784 --> 00:22:11.695和你每天的样子没什么关系。00:22:11.695 --> 00:22:14.800嗯，但是他们有点00:22:14.800 --> 00:22:19.660这些数据或他们的研究根本不支持的大结论，00:22:19.660 --> 00:22:24.595嗯，但像是符合产前荷尔蒙的性取向理论。00:22:24.595 --> 00:22:28.630男同性恋者和女同性恋者往往具有性别不典型的面部形态。00:22:28.630 --> 00:22:34.420现在，没有一个作者是产前激素理论专家，你知道。00:22:34.420 --> 00:22:37.120他们的名字里有医生，所以也许这是一回事。00:22:37.120 --> 00:22:39.865嗯，这是斯坦福大学的教授，就像我一样，00:22:39.865 --> 00:22:42.160我在斯坦福大学做过几次这样的演讲00:22:42.160 --> 00:22:44.680有些人喜欢在这件事上进行激烈的斗争。00:22:44.680 --> 00:22:46.570所以我准备好了，如果有人想接我。00:22:46.570 --> 00:22:50.410[笑声]但是，呃，我和我的呃，00:22:50.410 --> 00:22:52.495我的一些同事决定，00:22:52.495 --> 00:22:54.025我们会玩这个，00:22:54.025 --> 00:22:56.755我们发现了一个简单的决策树。00:22:56.755 --> 00:22:59.580嗯，我假设你们知道什么是决策树。00:22:59.580 --> 00:23:01.090所以，好吧。00:23:01.090 --> 00:23:04.270酷。所以根据化妆或戴眼镜，00:23:04.270 --> 00:23:06.790让我们非常接近00:23:06.790 --> 00:23:09.670报纸。这与体内激素无关，00:23:09.670 --> 00:23:11.200这一点都不说，00:23:11.200 --> 00:23:13.795这说明了很多关于身体表现的事情，00:23:13.795 --> 00:23:15.535表面上的东西。00:23:15.535 --> 00:23:17.830嗯，它更多地说明了人们是怎样的00:23:17.830 --> 00:23:20.515表现自己，而不是内部发生的事情。00:23:20.515 --> 00:23:23.530嗯，最近最关键的是00:23:23.530 --> 00:23:26.695被忽视的是深度学习00:23:26.695 --> 00:23:30.940我认为它神奇地超越了表面。00:23:30.940 --> 00:23:34.420但关键是它在地面上工作，而且工作得很好。00:23:34.420 --> 00:23:38.260面对确认偏差和其他类型的偏差因素，00:23:38.260 --> 00:23:41.455很容易就认为发生了其他事情，但事实并非如此。00:23:41.455 --> 00:23:43.720没有严格的检查，呃，00:23:43.720 --> 00:23:46.660例如简单基线，00:23:46.660 --> 00:23:50.635简单的理智检查，这些事情可以被忽略，00:23:50.635 --> 00:23:52.705一点也没注意到。00:23:52.705 --> 00:23:56.620嗯，这就是选择偏差的例子，00:23:56.620 --> 00:24:00.530嗯，实验者的偏见和相关性谬论。00:24:00.780 --> 00:24:03.655可以。所以现在我要和你谈谈，00:24:03.655 --> 00:24:05.680讨论测量算法偏差。00:24:05.680 --> 00:24:10.690所以我只是说了很多关于数据中出现的各种偏见，00:24:10.690 --> 00:24:13.870在收集，在解释的结果。00:24:13.870 --> 00:24:18.265[噪音]让我们来谈谈如何定量测量各种偏差。00:24:18.265 --> 00:24:22.045嗯，所以关键的一点是，呃，00:24:22.045 --> 00:24:25.750出现在一些不同的作品中，并与很多作品很好地联系在一起。00:24:25.750 --> 00:24:29.650公平工作就是这种分门别类的评价思想。00:24:29.650 --> 00:24:31.855所以在分解评估中，00:24:31.855 --> 00:24:35.230在不同的子组之间进行评估，而不是00:24:35.230 --> 00:24:39.280查看您的整体测试数据集的单个分数。00:24:39.280 --> 00:24:41.620嗯，好吧。00:24:41.620 --> 00:24:44.200你们可能熟悉培训测试数据分割。00:24:44.200 --> 00:24:45.505你就像坐在那里的火车，00:24:45.505 --> 00:24:47.320根据你提供的训练数据，00:24:47.320 --> 00:24:51.565你对给定的测试数据进行测试，然后像精确报告一样报告，00:24:51.565 --> 00:24:53.875回忆一下，F-score，诸如此类的事情。00:24:53.875 --> 00:24:57.280嗯，但掩盖的是系统实际上有多好00:24:57.280 --> 00:25:01.315在不同类型的个人和不同的小组中工作。00:25:01.315 --> 00:25:04.660嗯，所以一个简单的处理方法00:25:04.660 --> 00:25:08.320这实际上是对这些不同的子组进行评估。00:25:08.320 --> 00:25:11.650因此，为每种子群预测对创建。00:25:11.650 --> 00:25:13.450嗯，举个例子，00:25:13.450 --> 00:25:15.535你可以看看女性面部检测，00:25:15.535 --> 00:25:18.205男人的面部检测，看看，00:25:18.205 --> 00:25:19.600错误率为，00:25:19.600 --> 00:25:22.375是不同的或是嗯，相似的。00:25:22.375 --> 00:25:27.145嗯，这其中的另一个重要部分是交叉地看待事物，00:25:27.145 --> 00:25:29.530嗯，结合起来，嗯，00:25:29.530 --> 00:25:34.000就像性别和种族一样，看看这些，呃，00:25:34.000 --> 00:25:36.370这类事情的错误率如何00:25:36.370 --> 00:25:39.700改变，以及它们在不同的交叉口有什么不同。00:25:39.700 --> 00:25:42.445嗯，这是金伯利克伦肖的灵感。00:25:42.445 --> 00:25:45.879嗯，她是跨部门研究的先驱，00:25:45.879 --> 00:25:48.175嗯，在批判种族理论中。00:25:48.175 --> 00:25:51.805嗯，她讨论了艾玛・德格拉芬瑞德的故事，00:25:51.805 --> 00:25:55.585他是通用汽车公司的一个女人，嗯，00:25:55.585 --> 00:25:59.770她还声称，公司的招聘做法歧视黑人妇女。00:25:59.770 --> 00:26:01.780嗯，但在她的法庭意见中，00:26:01.780 --> 00:26:04.795法官裁定通用汽车雇佣了00:26:04.795 --> 00:26:10.255许多妇女担任秘书职务，许多黑人担任工厂职务，00:26:10.255 --> 00:26:14.050因此他们不能歧视黑人妇女。00:26:14.050 --> 00:26:16.690他们失败的是看00:26:16.690 --> 00:26:19.270他们两个都明白00:26:19.270 --> 00:26:21.160与任何00:26:21.160 --> 00:26:25.840这两类小组中任何一个单独的经历。00:26:25.840 --> 00:26:29.290嗯，当你开始寻找00:26:29.290 --> 00:26:32.590在深度学习系统中经常发生的错误。00:26:32.590 --> 00:26:34.630嗯，所以我们发现了很多00:26:34.630 --> 00:26:37.360通过不仅查看00:26:37.360 --> 00:26:43.475分解评价，但也在跨部门分解评价。00:26:43.475 --> 00:26:46.645嗯，所以我要详细介绍一下这是如何工作的。00:26:46.645 --> 00:26:49.660这可能是你们大多数人的回顾，00:26:49.660 --> 00:26:52.330但我认为理解这一点很重要，因为它也00:26:52.330 --> 00:26:55.645与我们如何衡量公平以及当我们说喜欢，00:26:55.645 --> 00:26:58.690嗯，算法公平，我们在说什么。00:26:58.690 --> 00:27:02.740所以，嗯，混乱矩阵是一种方式，你们。00:27:02.740 --> 00:27:04.750可以。你们熟悉混乱矩阵吗？00:27:04.750 --> 00:27:06.250[笑声]。我只想知道在哪里。00:27:06.250 --> 00:27:09.085可以。令人惊叹的。酷。所以你熟悉混淆矩阵，对吧。00:27:09.085 --> 00:27:11.425所以你有模型预测和参考。00:27:11.425 --> 00:27:14.470嗯，你可以把这些看成是消极的和积极的，00:27:14.470 --> 00:27:17.110二进制分类00:27:17.110 --> 00:27:19.495这里有一种方法，如果00:27:19.495 --> 00:27:23.200基本事实表明某些事情是真的，模型预测它是真的，00:27:23.200 --> 00:27:24.385这是一个真正的积极因素。00:27:24.385 --> 00:27:25.780如果事实表明00:27:25.780 --> 00:27:27.520是的，是的，是假的，00:27:27.520 --> 00:27:31.045嗯，模型预测它是假的，它是真的负的。00:27:31.045 --> 00:27:33.670嗯，还有错误，那种不同的问题00:27:33.670 --> 00:27:36.400出现是错误的否定和错误的积极。00:27:36.400 --> 00:27:39.670嗯，所以在误报中，嗯，00:27:39.670 --> 00:27:44.290基本事实表明有些事情是消极的，但模型预测它是积极的。00:27:44.290 --> 00:27:47.560嗯，然后是假阴性，反之亦然。00:27:47.560 --> 00:27:49.765嗯，从这些，你知道，00:27:49.765 --> 00:27:51.250呃，基本的，呃，00:27:51.250 --> 00:27:53.290这些基本的错误分解，00:27:53.290 --> 00:27:55.330您可以获得一些不同的指标。00:27:55.330 --> 00:28:01.105嗯，这些指标实际上非常符合许多不同的公平标准。00:28:01.105 --> 00:28:02.965例如，嗯，00:28:02.965 --> 00:28:04.720如果我们看到00:28:04.720 --> 00:28:09.880女性患者与男性患者的结果以及精确性和回忆等问题，00:28:09.880 --> 00:28:12.670这在NLP中比较常见，嗯，00:28:12.670 --> 00:28:16.405如果你在你的小组中有相同的回忆00:28:16.405 --> 00:28:20.875这和机会平等的公平标准是一样的，00:28:20.875 --> 00:28:23.440嗯，我可以通读数学。00:28:23.440 --> 00:28:24.805但我的意思是，这基本上只是，00:28:24.805 --> 00:28:27.475重点是，呃，00:28:27.475 --> 00:28:32.200它说，考虑到某些事情是真实的，在地面上是真实的，00:28:32.200 --> 00:28:35.365模型应该预测这是真的，00:28:35.365 --> 00:28:37.660嗯，在不同的小组中以相同的比率。00:28:37.660 --> 00:28:41.965所以这就相当于在不同的子组中有相同的回忆。00:28:41.965 --> 00:28:45.730同样的，嗯，有相同的精度00:28:45.730 --> 00:28:50.800不同的子群等价于一个称为预测奇偶性的公平准则。00:28:50.800 --> 00:28:55.285当公平被一次又一次的定义，嗯，00:28:55.285 --> 00:28:58.960最初，有些定义00:28:58.960 --> 00:29:02.9801964年《民权法》之后的1966年。00:29:02.980 --> 00:29:05.875嗯，他们被改造了几次，呃，00:29:05.875 --> 00:29:09.895最近在2016年重新投资。00:29:09.895 --> 00:29:12.790嗯，但它们都是00:29:12.790 --> 00:29:16.540这是分组比较和数学比较，00:29:16.540 --> 00:29:20.770度量结果大致相当于我们从混淆矩阵中得到的结果，00:29:20.770 --> 00:29:24.560特别是在分类系统中。00:29:25.980 --> 00:29:29.530那么你使用哪种公平标准呢？00:29:29.530 --> 00:29:31.870你想要什么不同的标准00:29:31.870 --> 00:29:35.020用来观察不同子组之间的差异，00:29:35.020 --> 00:29:37.780这真的取决于权衡。00:29:37.780 --> 00:29:39.925在假阳性和假阴性之间。00:29:39.925 --> 00:29:42.025所以这就是你要处理的问题00:29:42.025 --> 00:29:44.515当你正在思考如何进行总体评估时。00:29:44.515 --> 00:29:46.900嗯，没有一个公平标准，那就是00:29:46.900 --> 00:29:49.960公平的标准和规则，嗯，00:29:49.960 --> 00:29:52.630决定哪一个比另一个好与00:29:52.630 --> 00:29:55.480有点试图决定哪个更好，准确还是召回，对吧？00:29:55.480 --> 00:29:58.630这取决于问题是什么，以及你对测量感兴趣的是什么。00:29:58.630 --> 00:30:03.100嗯，如果是假阳性可能比00:30:03.100 --> 00:30:07.780错误的否定，所以你想优先考虑一些错误的阳性率，00:30:07.780 --> 00:30:10.630啊，跨小组是隐私和图像。00:30:10.630 --> 00:30:15.370所以这里的假阳性是不需要模糊的东西变得模糊。00:30:15.370 --> 00:30:16.780那真是一种无赖。00:30:16.780 --> 00:30:19.540嗯，但一个错误的否定应该是00:30:19.540 --> 00:30:22.405模糊不是模糊，这可能是身份盗窃。00:30:22.405 --> 00:30:24.295这是一个更严重的问题。00:30:24.295 --> 00:30:26.110所以重要的是要优先考虑00:30:26.110 --> 00:30:29.440强调假阴性率的评估指标。00:30:29.440 --> 00:30:32.650嗯，一个假阴性的例子00:30:32.650 --> 00:30:35.335垃圾邮件过滤可能比误报要好。00:30:35.335 --> 00:30:41.635所以一个错误的否定可能是一封未被捕获的垃圾邮件，所以你可以在收件箱中看到它，00:30:41.635 --> 00:30:44.350这通常很烦人，没什么大不了的。00:30:44.350 --> 00:30:47.170嗯，但这里的假阳性邮件会被标记为00:30:47.170 --> 00:30:50.245垃圾邮件，然后从收件箱中删除，00:30:50.245 --> 00:30:52.780你知道，如果它来自朋友或爱人，00:30:52.780 --> 00:30:54.535可能是，也可能是损失，00:30:54.535 --> 00:30:56.620也许有这样的工作机会。00:30:56.620 --> 00:30:58.360好吧。00:30:58.360 --> 00:31:02.560所以，嗯，我只是在讨论人工智能如何无意中导致00:31:02.560 --> 00:31:05.050不公正的结果和一些要做的事情00:31:05.050 --> 00:31:07.045或者这里需要注意的一些事情，00:31:07.045 --> 00:31:11.590是否缺乏对数据、模型中偏差来源的洞察？00:31:11.590 --> 00:31:16.690对收集到的原始数据的反馈循环缺乏洞察力00:31:16.690 --> 00:31:21.519作为人类对数据所做的一个例子，这些数据随后被重新利用，00:31:21.519 --> 00:31:24.475重新使用，采取行动，然后进一步补充。00:31:24.475 --> 00:31:28.060嗯，缺乏仔细的分类评估，00:31:28.060 --> 00:31:29.560看看差距，00:31:29.560 --> 00:31:33.730为了理解这种偏见，不同小组之间的差异，00:31:33.730 --> 00:31:35.605各小组之间的差异。00:31:35.605 --> 00:31:38.949嗯，然后人类在解释和接受方面的偏见，00:31:38.949 --> 00:31:40.525说到结果，00:31:40.525 --> 00:31:45.950然后媒体的循环和人工智能的炒作就更进一步了。00:31:46.080 --> 00:31:50.875嗯，但这取决于我们如何影响人工智能的发展。00:31:50.875 --> 00:31:55.330所以我喜欢从短期来看，00:31:55.330 --> 00:31:57.295中长期目标。00:31:57.295 --> 00:32:00.355所以今天短期来看，00:32:00.355 --> 00:32:05.170我们可能正在研究一个特定的模型，在这个模型中我们试图找到一些局部的最优值，00:32:05.170 --> 00:32:07.705我们有任务，我们有数据，诸如此类。00:32:07.705 --> 00:32:09.880这就是短期目标。00:32:09.880 --> 00:32:14.590嗯，我们可能有一个更长远的目标，就是发表一篇论文，00:32:14.590 --> 00:32:16.990或者，如果你是一个像推出产品这样的行业，00:32:16.990 --> 00:32:18.505不管是什么。00:32:18.505 --> 00:32:23.440嗯，从那里我们可以看到我们的下一个目标是获得奖励，或者，00:32:23.440 --> 00:32:25.870你知道，也许会因为00:32:25.870 --> 00:32:28.600几分钟，就这样，很酷。00:32:28.600 --> 00:32:31.300但是我们有一个长期的目标00:32:31.300 --> 00:32:34.165同时也能朝着这个方向努力。00:32:34.165 --> 00:32:38.110这对环境中的人类来说是一个积极的结果。00:32:38.110 --> 00:32:42.130因此，与其只关注这些地方决策，00:32:42.130 --> 00:32:43.555这些局部最优和这些00:32:43.555 --> 00:32:48.370以纸为基础的解决问题的本地论文，00:32:48.370 --> 00:32:51.400你也可以考虑什么是长期目标。00:32:51.400 --> 00:32:56.739当我追寻人工智能的进化道路时，这会给我带来什么呢？00:32:56.739 --> 00:32:58.555十年来，00:32:58.555 --> 00:33:01.21015年，20年。00:33:01.210 --> 00:33:06.220嗯，你可以通过思考来解决这个问题，00:33:06.220 --> 00:33:10.405现在，我感兴趣的工作如何才能最好地专注于帮助他人？00:33:10.405 --> 00:33:12.235这包括与专家交谈，00:33:12.235 --> 00:33:14.125嗯，就像走出你的泡泡，00:33:14.125 --> 00:33:16.540跨学科演讲00:33:16.540 --> 00:33:19.660我刚刚谈到的认知科学。00:33:19.660 --> 00:33:23.410嗯，让我们谈谈我们能做的事情。00:33:23.410 --> 00:33:25.825所以首先是数据。00:33:25.825 --> 00:33:32.095嗯，很多偏见和公平的问题，00:33:32.095 --> 00:33:36.220啊，在机器学习模式中，真正的数据来源。00:33:36.220 --> 00:33:39.580不幸的是，在机器学习和深度学习中，00:33:39.580 --> 00:33:42.670研究数据真的不被认为是性感的。00:33:42.670 --> 00:33:45.085啊，有一些数据集，啊，00:33:45.085 --> 00:33:47.350人们在外面使用的，00:33:47.350 --> 00:33:48.580这就是人们使用的，00:33:48.580 --> 00:33:50.710没有太多的分析，00:33:50.710 --> 00:33:55.000关于这些数据集在多大程度上捕捉到了关于世界的不同真相，00:33:55.000 --> 00:33:56.740他们可能有多大问题，00:33:56.740 --> 00:34:01.945[噪音]嗯，但这是一个非常广阔的领域，需要很多未来，00:34:01.945 --> 00:34:04.885像Lea一样-需要很多未来的额外工作。00:34:04.885 --> 00:34:08.740嗯，[噪音]所以我们要了解数据倾斜和相关性。00:34:08.740 --> 00:34:10.900如果你知道你的数据有偏差，00:34:10.900 --> 00:34:13.960啊，数据中可能存在问题的相关性，00:34:13.960 --> 00:34:17.305然后你可以开始研究解决这些问题的任何一个模型，00:34:17.305 --> 00:34:20.980或数据扩充方法，以便00:34:20.980 --> 00:34:24.115数据集更好或更具代表性00:34:24.115 --> 00:34:25.990你希望这个世界是怎样的。00:34:25.990 --> 00:34:30.280嗯，放弃单一的训练集测试也很重要00:34:30.280 --> 00:34:34.420从相似的分布方法到深入学习。00:34:34.420 --> 00:34:37.975所以，嗯，当我们做深入学习的项目时，00:34:37.975 --> 00:34:39.610你知道，我们通常都有一套训练设备，00:34:39.610 --> 00:34:43.330测试集，然后这就是我们的基准和优先顺序，00:34:43.330 --> 00:34:46.060但关键是，当你在不同的测试集之间移动时，00:34:46.060 --> 00:34:48.160你会得到完全不同的结果。00:34:48.160 --> 00:34:50.440嗯，所以通过保持00:34:50.440 --> 00:34:55.810这只是一种培训测试数据-培训测试数据集范例，00:34:55.810 --> 00:35:00.265你很可能不会注意到可能存在的问题。00:35:00.265 --> 00:35:02.140一种真正专注于它们的方法，00:35:02.140 --> 00:35:05.155有一套很难的，00:35:05.155 --> 00:35:09.070对于测试用例，你真的想确保模型运行良好。00:35:09.070 --> 00:35:12.055所以这些都是特别有问题的事情。00:35:12.055 --> 00:35:14.905对个人有害的东西，00:35:14.905 --> 00:35:17.545嗯，如果他们要体验输出。00:35:17.545 --> 00:35:21.730嗯，你可以在一个小测试集中收集，然后很容易00:35:21.730 --> 00:35:26.140要在测试集上评估模型的基准改进，00:35:26.140 --> 00:35:28.330当你在你的模型中添加不同种类的东西时，00:35:28.330 --> 00:35:30.025为了看，嗯，00:35:30.025 --> 00:35:32.215不仅仅是你的模型的整体表现，00:35:32.215 --> 00:35:33.940就您的测试数据集而言，00:35:33.940 --> 00:35:36.700但你在这些例子方面做得有多好，00:35:36.700 --> 00:35:38.590你真的很想把它做好。00:35:38.590 --> 00:35:41.950你知道，如果它不能很好地发挥作用，那将是一个问题，00:35:41.950 --> 00:35:43.900任何形式的退化，00:35:43.900 --> 00:35:46.210你可能想优先考虑，嗯，00:35:46.210 --> 00:35:50.815解决上述德格拉盖-退化和整体精度。00:35:50.815 --> 00:35:53.530嗯，和专家交谈也很重要00:35:53.530 --> 00:35:56.335关于可以合并的附加信号。00:35:56.335 --> 00:36:00.490嗯，所以我们拿出了一个工具来帮助解决这个问题，00:36:00.490 --> 00:36:03.220啊，理解被称为面的数据倾斜，00:36:03.220 --> 00:36:04.855嗯，那里正好有。00:36:04.855 --> 00:36:10.075嗯，这是一个非常方便的切片可视化工具，啊，理解，00:36:10.075 --> 00:36:13.330嗯，你知道，不同的小组之间有什么不同00:36:13.330 --> 00:36:16.630以及不同的表示，您可以深入研究更多内容。00:36:16.630 --> 00:36:18.685所以这只是为了帮助人们，啊，00:36:18.685 --> 00:36:21.430了解他们实际使用的数据，00:36:21.430 --> 00:36:23.050哪里可能有，嗯，00:36:23.050 --> 00:36:25.795不需要的联想，或者，或者缺失，00:36:25.795 --> 00:36:26.920缺少功能类型。00:36:26.920 --> 00:36:33.220[噪音]嗯，最近提出的另一种方法，00:36:33.220 --> 00:36:36.565啊，特别是在数据方面，这是数据，00:36:36.565 --> 00:36:38.725数据集方法的数据表。00:36:38.725 --> 00:36:42.040嗯，这就是当你发布一个数据集时，00:36:42.040 --> 00:36:44.770仅仅用like发布数据集是不够的00:36:44.770 --> 00:36:48.880一些漂亮的图，比如说基本的分布信息，00:36:48.880 --> 00:36:52.330你需要谈谈注释员是谁，他们在哪里，00:36:52.330 --> 00:36:54.400注释间协议是什么？00:36:54.400 --> 00:36:56.500他们的背景资料是什么，00:36:56.500 --> 00:36:59.005嗯，数据集的动机。00:36:59.005 --> 00:37:00.550所有这些其他的细节。00:37:00.550 --> 00:37:03.625现在你知道这不仅仅是一个数据集，00:37:03.625 --> 00:37:06.700这是一个具有这些特定偏差的数据集。00:37:06.700 --> 00:37:10.300没有数据集这样的东西在某种程度上是没有偏见的。00:37:10.300 --> 00:37:14.905一个数据集，因为它是作为一个子集从世界收集的，00:37:14.905 --> 00:37:18.415是一个，在某种程度上是一个有偏见的世界。00:37:18.415 --> 00:37:20.440关键是要弄清楚它是什么，00:37:20.440 --> 00:37:22.015它有多偏颇，是什么，00:37:22.015 --> 00:37:23.545各种偏见是什么？00:37:23.545 --> 00:37:25.675啊，这在数据集中很重要。00:37:25.675 --> 00:37:29.410这就是数据集数据表背后的想法之一，00:37:29.410 --> 00:37:32.185公开发布其数据集。00:37:32.185 --> 00:37:35.815好吧。现在让我们切换到机器学习。00:37:35.815 --> 00:37:40.375嗯，我喜欢使用一些技巧。嗯，我来谈谈两个。00:37:40.375 --> 00:37:42.835第一，啊，是减少偏见，00:37:42.835 --> 00:37:45.850这是为了消除有问题的输出信号。00:37:45.850 --> 00:37:48.760嗯，所以去掉，啊，刻板印象，00:37:48.760 --> 00:37:52.390性别歧视，种族主义，试图从模型中消除这些影响。00:37:52.390 --> 00:37:56.530嗯，这有时也称为去偏压或无偏压，00:37:56.530 --> 00:38:00.520但这有点用词不当，因为你通常只是00:38:00.520 --> 00:38:04.690例如，根据一组特定的单词移动偏差，00:38:04.690 --> 00:38:07.795嗯，所以说没有偏见是不对的。00:38:07.795 --> 00:38:10.330嗯，但是你有点减轻了对00:38:10.330 --> 00:38:13.675一些你提供给它的信息。00:38:13.675 --> 00:38:18.910嗯，还有一个包含，它为所需变量添加信号。00:38:18.910 --> 00:38:22.105所以这是减少偏见的另一面。00:38:22.105 --> 00:38:24.610因此，应注意提高模型性能00:38:24.610 --> 00:38:28.075性能最差的子组或数据切片。00:38:28.075 --> 00:38:31.825嗯，那么，啊，为了，00:38:31.825 --> 00:38:33.475呃，地址包含，啊，00:38:33.475 --> 00:38:36.865对表示不足的子组加信号的类型，00:38:36.865 --> 00:38:39.910一种比较有效的方法是多任务学习。00:38:39.910 --> 00:38:43.990嗯，我听说你们学过多任务学习，这很好，00:38:43.990 --> 00:38:46.390嗯，那么我会告诉你一些案例研究。00:38:46.390 --> 00:38:48.235嗯，这是我做的工作，啊，00:38:48.235 --> 00:38:52.390与一个UPENN世界福祉项目合作，啊，00:38:52.390 --> 00:38:54.190直接与临床医生合作，00:38:54.190 --> 00:38:56.530我们的目标是建立一个可以发出警报的系统00:38:56.530 --> 00:38:59.560临床医生，如果有自杀企图迫在眉睫。00:38:59.560 --> 00:39:02.320嗯，他们想了解00:39:02.320 --> 00:39:05.650在培训很少的时候，这种诊断，00:39:05.650 --> 00:39:07.690啊，培训实例可用。00:39:07.690 --> 00:39:11.230这类似于数据集中的少数问题。00:39:11.230 --> 00:39:14.125嗯，[噪音]00:39:14.125 --> 00:39:17.290在这项工作中，00:39:17.290 --> 00:39:19.015我们有两种数据。00:39:19.015 --> 00:39:22.960一个是内部数据，是电子健康记录，嗯，00:39:22.960 --> 00:39:27.190病人或家人提供的。00:39:27.190 --> 00:39:30.070嗯，包括心理健康诊断，00:39:30.070 --> 00:39:32.380呃，自杀未遂或完成，嗯，00:39:32.380 --> 00:39:34.750如果，如果，如果是这样的话，00:39:34.750 --> 00:39:36.175呃，用户的，呃，00:39:36.175 --> 00:39:37.915此人的社交媒体数据。00:39:37.915 --> 00:39:40.690那是我们没有公布的内部数据，00:39:40.690 --> 00:39:43.000但是我们可以和临床医生一起00:39:43.000 --> 00:39:45.685以了解我们的方法是否有效。00:39:45.685 --> 00:39:48.385嗯，外部数据，代理数据，00:39:48.385 --> 00:39:50.845我们可以发表和谈论的东西，00:39:50.845 --> 00:39:52.045基于Twitter。00:39:52.045 --> 00:39:53.910嗯，这是，呃，00:39:53.910 --> 00:39:57.810使用正则表达式来提取，00:39:57.810 --> 00:40:02.315Twitter订阅中的阶段有点像诊断。00:40:02.315 --> 00:40:04.960我被诊断出患有X，00:40:04.960 --> 00:40:06.820或者我试图自杀。00:40:06.820 --> 00:40:08.425这就变成了，00:40:08.425 --> 00:40:12.325代理数据集和相应的社交媒体源，00:40:12.325 --> 00:40:13.735对于那些人，呃，00:40:13.735 --> 00:40:16.270用于实际诊断。00:40:16.270 --> 00:40:22.840嗯，还有最先进的临床医学，呃，00:40:22.840 --> 00:40:24.100在这项工作之前，00:40:24.100 --> 00:40:26.425最近有过，但是，呃，是，00:40:26.425 --> 00:40:30.595这是一种单一任务的逻辑回归-低-低-逻辑回归设置。00:40:30.595 --> 00:40:32.080如果您有一些输入功能，00:40:32.080 --> 00:40:35.185然后你做了一些输出预测，比如真的或者假的。00:40:35.185 --> 00:40:41.260嗯，你可以增加一些层次，并开始使它深入学习，这是更美好的。00:40:41.260 --> 00:40:45.340嗯，你可以有很多任务00:40:45.340 --> 00:40:49.420为临床环境做一系列的逻辑回归工作。00:40:49.420 --> 00:40:51.850或者你可以用多任务学习，00:40:51.850 --> 00:40:55.900它采用了基本的深度学习模式，并在其中添加了大量的头部，00:40:55.900 --> 00:40:58.150嗯，同时联合预测。00:40:58.150 --> 00:41:01.660嗯，这里我们有很多诊断数据。00:41:01.660 --> 00:41:04.420所以，嗯，我们预测像抑郁症这样的事情，00:41:04.420 --> 00:41:07.585焦虑，呃，创伤后应激障碍。00:41:07.585 --> 00:41:10.900嗯，我们还增加了性别，因为这是00:41:10.900 --> 00:41:13.900临床医生告诉我们的事实，呃，00:41:13.900 --> 00:41:16.180与这些情况有些关联，00:41:16.180 --> 00:41:18.970他们实际上是用它自己做决定的，00:41:18.970 --> 00:41:21.535不管有没有人可能，00:41:21.535 --> 00:41:24.010呃，尝试，呃，自杀还是不自杀。00:41:24.010 --> 00:41:27.310嗯，这也用到了共病的概念。00:41:27.310 --> 00:41:32.935因此，多任务学习实际上是一种完美的共病在临床领域。00:41:32.935 --> 00:41:34.870所以共病是，嗯，00:41:34.870 --> 00:41:36.220当你有一个条件时，00:41:36.220 --> 00:41:38.185你更有可能再有一个。00:41:38.185 --> 00:41:39.820嗯，所以那些00:41:39.820 --> 00:41:43.630创伤后应激障碍更容易产生抑郁和焦虑。00:41:43.630 --> 00:41:46.359嗯，抑郁和焦虑往往是病态的，00:41:46.359 --> 00:41:48.695所以拥有一个的人往往拥有另一个。00:41:48.695 --> 00:41:52.320所以这指向事实-这指向可能存在00:41:52.320 --> 00:41:55.680一些在它们之间类似的基本表示，00:41:55.680 --> 00:41:57.990可以在深度学习模式中加以利用，00:41:57.990 --> 00:42:00.885单独的头进一步说明，00:42:00.885 --> 00:42:04.170呃，各种不同的情况。00:42:04.170 --> 00:42:07.960嗯，所以我们发现当我们从00:42:07.960 --> 00:42:12.160逻辑回归到单任务深度学习到多任务深度学习，00:42:12.160 --> 00:42:14.605我们能够取得明显更好的结果。00:42:14.605 --> 00:42:17.725这两个都是真的，在自杀风险案例中，我们有一个，00:42:17.725 --> 00:42:19.510很多数据，还有00:42:19.510 --> 00:42:22.960创伤后应激障碍的病例，我们的数据很少。00:42:22.960 --> 00:42:25.270嗯，这里的行为有点不同。00:42:25.270 --> 00:42:28.660从逻辑回归到00:42:28.660 --> 00:42:30.490嗯，单任务深度学习，00:42:30.490 --> 00:42:32.065当我们有，嗯，00:42:32.065 --> 00:42:33.685很多数据，呃，00:42:33.685 --> 00:42:36.295就像自杀风险一样，嗯，00:42:36.295 --> 00:42:38.230有单一的任务深度学习模式00:42:38.230 --> 00:42:40.690比逻辑回归模型更有效。00:42:40.690 --> 00:42:43.105嗯，但是当我们只有很少的例子时，00:42:43.105 --> 00:42:46.270这就是深度学习模型真正挣扎得更厉害的地方。00:42:46.270 --> 00:42:50.320嗯，所以逻辑回归模型实际上要好得多。00:42:50.320 --> 00:42:54.130但一旦我们开始为不同种类的尸检条件添加头，00:42:54.130 --> 00:42:55.780不同类型的任务，嗯，00:42:55.780 --> 00:42:57.400这与，你知道，00:42:57.400 --> 00:42:59.845不管这个人是否会自杀，嗯，00:42:59.845 --> 00:43:01.210我们能够，呃，00:43:01.210 --> 00:43:03.145再次将准确度提升。00:43:03.145 --> 00:43:05.485嗯，而且，你知道，00:43:05.485 --> 00:43:09.235我们收集到的大约有120个高危人群，00:43:09.235 --> 00:43:12.250如果不是自杀的话00:43:12.250 --> 00:43:15.110注意到有危险。00:43:16.110 --> 00:43:20.050嗯，我们采取的方法之一是00:43:20.050 --> 00:43:24.670将这类技术的发布从伦理层面进行语境化和思考。00:43:24.670 --> 00:43:28.900所以，嗯，在NLP论文中给出例子是很常见的。00:43:28.900 --> 00:43:31.030嗯，但这是我们决定00:43:31.030 --> 00:43:33.475举一些像抑郁的语言的例子，00:43:33.475 --> 00:43:35.860可以用来歧视别人，00:43:35.860 --> 00:43:37.480就像在，你知道，约伯，00:43:37.480 --> 00:43:39.565面试之类的，你知道，00:43:39.565 --> 00:43:42.085那种扶手椅心理学的方法。00:43:42.085 --> 00:43:45.240所以我们决定尽管谈论技术很重要，00:43:45.240 --> 00:43:47.190以及多任务学习在00:43:47.190 --> 00:43:51.840一个临床领域，包括代表性不足的亚组，00:43:51.840 --> 00:43:54.210它必须与有很多00:43:54.210 --> 00:43:57.030谈论抑郁症的风险，00:43:57.030 --> 00:44:00.270还有焦虑，以及如何预测这些事情。00:44:00.270 --> 00:44:03.435嗯，所以我们想在这里采取更平衡的方法，嗯，00:44:03.435 --> 00:44:07.020从那时起，我在所有的论文中都考虑到了伦理问题。00:44:07.020 --> 00:44:10.420嗯，实际上越来越普遍了。00:44:10.790 --> 00:44:15.565嗯，另一种方法，它现在正在改变主意，00:44:15.565 --> 00:44:18.535你想消除一些影响，嗯，00:44:18.535 --> 00:44:20.230以某种方式减轻偏见，00:44:20.230 --> 00:44:22.390是对抗性的多任务学习。00:44:22.390 --> 00:44:24.010所以我刚谈到了多任务学习，00:44:24.010 --> 00:44:26.065我来谈谈对抗性的案子。00:44:26.065 --> 00:44:30.205嗯，在敌对的情况下，你的想法是你有一些头脑。00:44:30.205 --> 00:44:32.470嗯，有人在预测主要任务，00:44:32.470 --> 00:44:35.200另一个预测的是00:44:35.200 --> 00:44:38.290希望影响模型的预测。00:44:38.290 --> 00:44:42.670例如，是否应该基于某个人提升，00:44:42.670 --> 00:44:44.650呃，你知道，他们的绩效评估，00:44:44.650 --> 00:44:46.285像这样的事情。00:44:46.285 --> 00:44:49.555嗯，你不想让他们的性别影响到这一点。00:44:49.555 --> 00:44:53.260理想情况下，性别独立于晋升决定。00:44:53.260 --> 00:44:54.805所以你可以，呃，00:44:54.805 --> 00:44:57.385你可以为这个创建一个模型，00:44:57.385 --> 00:44:59.620呃，说独立，嗯，00:44:59.620 --> 00:45:02.365通过说，呃，00:45:02.365 --> 00:45:05.485我想把升职的损失降到最低，00:45:05.485 --> 00:45:07.885同时最大限度地减少我在性别问题上的损失。00:45:07.885 --> 00:45:10.390所以我们做的只是预测性别，00:45:10.390 --> 00:45:12.250然后对梯度求反。00:45:12.250 --> 00:45:15.010所以消除了信号的影响。00:45:15.010 --> 00:45:17.920嗯，这是另一种敌对的方法。00:45:17.920 --> 00:45:20.950所以你可能已经熟悉了类似生成对抗网络。00:45:20.950 --> 00:45:23.470这就像两个鉴别器，00:45:23.470 --> 00:45:25.435两个不同的任务负责人，呃，00:45:25.435 --> 00:45:28.270当一个人试图完成我们关心的任务时，00:45:28.270 --> 00:45:30.745另一个正在移除信号，呃，00:45:30.745 --> 00:45:32.320我们真的不想，00:45:32.320 --> 00:45:35.890嗯，呃，在我们的下游预测中起作用。00:45:35.890 --> 00:45:37.900嗯，这是一种方式，00:45:37.900 --> 00:45:39.670呃，把这个付诸实践。00:45:39.670 --> 00:45:41.410所以输出的概率，00:45:41.410 --> 00:45:43.030呃，假设00:45:43.030 --> 00:45:46.540基本事实和你敏感的属性，比如性别，嗯，00:45:46.540 --> 00:45:48.835在所有不同的地方都是一样的，呃，00:45:48.835 --> 00:45:52.060所有不同性别的敏感属性或同等属性。00:45:52.060 --> 00:45:56.410嗯，这是监督学习机会均等的一个例子，00:45:56.410 --> 00:45:57.775正在付诸实践。00:45:57.775 --> 00:46:00.220所以这是一个关键的公平性定义。00:46:00.220 --> 00:46:01.750相当于，呃，00:46:01.750 --> 00:46:05.320正如我前面提到的，不同的子组之间的相同回忆。00:46:05.320 --> 00:46:07.495嗯，这是一个模型，实际上，00:46:07.495 --> 00:46:10.270呃，实施它或者帮助你实现它。00:46:10.270 --> 00:46:13.375嗯，你是说分类器的输出决策应该是相同的00:46:13.375 --> 00:46:16.480跨越敏感特征给出了什么，00:46:16.480 --> 00:46:19.070正确的决定应该是什么。00:46:20.190 --> 00:46:23.365好吧，那么我们怎么准时？00:46:23.365 --> 00:46:30.265酷。到目前为止有什么问题吗？我们好吗？00:46:30.265 --> 00:46:35.350好的，酷。所以我现在要做一点案例研究，一个端到端的，呃，00:46:35.350 --> 00:46:37.780谷歌一直在研究的系统，呃，00:46:37.780 --> 00:46:39.325我的同事一直在努力，00:46:39.325 --> 00:46:42.790这是在NLP领域，并处理其中一些偏见问题。00:46:42.790 --> 00:46:46.675嗯，你可以了解更多关于这项工作的信息，嗯，00:46:46.675 --> 00:46:51.745在2018年AIES的论文和2019年的FAT*教程中，00:46:51.745 --> 00:46:56.410嗯，在文本分类中称为测量和减轻无意中的偏差。00:46:56.410 --> 00:47:01.345嗯，这是人工智能对话的结果，它是，00:47:01.345 --> 00:47:03.505这是一种产品，嗯，00:47:03.505 --> 00:47:07.720就好像这是其中的一部分――这叫做谷歌的赌注。00:47:07.720 --> 00:47:10.810这是一个被称为“拼图”的分拆公司00:47:10.810 --> 00:47:14.245专注于尝试在网上打击虐待。00:47:14.245 --> 00:47:16.225嗯，谈话是，呃，00:47:16.225 --> 00:47:20.065团队正试图利用深度学习来改进在线对话。00:47:20.065 --> 00:47:23.320嗯，和很多不同的人合作，00:47:23.320 --> 00:47:25.375嗯，不同的人会这么做。00:47:25.375 --> 00:47:27.805嗯，这是怎么工作的，00:47:27.805 --> 00:47:30.460哦，你也可以在perspectiveapi.com上试试。00:47:30.460 --> 00:47:33.970所以说你是个傻子，呃，00:47:33.970 --> 00:47:41.358它给出了与之相关的毒性评分，如0.91。[噪音]00:47:41.358 --> 00:47:44.140嗯，模型开始有点误会00:47:44.140 --> 00:47:47.305经常攻击具有毒性的身份。00:47:47.305 --> 00:47:50.245所以这是一种假阳性倾向。00:47:50.245 --> 00:47:53.080所以我是一个骄傲的高个子得到了一个模特，00:47:53.080 --> 00:47:55.360嗯，毒性评分为0.18。00:47:55.360 --> 00:47:56.995我很骄傲，呃，00:47:56.995 --> 00:48:00.925同性恋者的毒性模型得分为0.69。00:48:00.925 --> 00:48:06.805这是因为这些-同性恋这个词往往被用在真正有毒的情况下。00:48:06.805 --> 00:48:10.960所以这个模型开始认识到同性恋本身是有毒的。00:48:10.960 --> 00:48:12.730但这不是我们想要的，00:48:12.730 --> 00:48:15.865我们不希望这些预测从模型中出来。00:48:15.865 --> 00:48:22.705嗯，所以，嗯，偏差很大程度上是由数据集不平衡造成的。00:48:22.705 --> 00:48:25.765同样，这是一种数据来了，又戴上了帽子。00:48:25.765 --> 00:48:28.000嗯，经常被攻击，呃，00:48:28.000 --> 00:48:31.180在有毒的评论中，身份确实被夸大了。00:48:31.180 --> 00:48:35.155对LGBTQ身份有很多毒性，嗯，00:48:35.155 --> 00:48:37.240在这样的事情上工作真的很可怕00:48:37.240 --> 00:48:39.985真的（笑声）它真的会影响到你个人。00:48:39.985 --> 00:48:42.790嗯，呃，还有，呃，00:48:42.790 --> 00:48:48.100研究小组采用的方法之一就是添加维基百科的无毒数据。00:48:48.100 --> 00:48:54.025帮助模型理解这些术语可以用于00:48:54.025 --> 00:48:58.040你知道，更积极的背景。00:49:00.720 --> 00:49:03.940测量的挑战之一，呃，00:49:03.940 --> 00:49:06.295系统做得有多好没有00:49:06.295 --> 00:49:11.725一个非常好的控制毒性评估方法。00:49:11.725 --> 00:49:13.750嗯，在现实生活中，00:49:13.750 --> 00:49:18.805任何人都可以猜测某一特定句子的毒性。00:49:18.805 --> 00:49:21.070嗯，如果你真的想控制另一种00:49:21.070 --> 00:49:24.040子群或交叉子群，00:49:24.040 --> 00:49:25.810可能更难得到，呃，00:49:25.810 --> 00:49:28.765一个真正好的数据来正确评估。00:49:28.765 --> 00:49:32.395所以团队最终做的是开发一种综合数据方法。00:49:32.395 --> 00:49:35.185嗯，这有点像偏袒狂libs。00:49:35.185 --> 00:49:37.465嗯，你用模板句子[噪音]，嗯，00:49:37.465 --> 00:49:41.380你用这些来做评估。这就是那种，嗯，00:49:41.380 --> 00:49:45.280除了你的下游目标，你还想使用评估00:49:45.280 --> 00:49:47.650啊，数据集的种类。00:49:47.650 --> 00:49:51.685但这有助于你找到具体的偏见。00:49:51.685 --> 00:49:55.840所以，嗯，一些模板短语，比如我是一个自豪的空白人，00:49:55.840 --> 00:49:58.480然后填写不同的子群身份。00:49:58.480 --> 00:50:01.660你不想发布模型除非你看到00:50:01.660 --> 00:50:04.990这些不同类型的分数，呃，00:50:04.990 --> 00:50:08.860这些不同类型的模板句子00:50:08.860 --> 00:50:10.795合成模板句子，嗯，00:50:10.795 --> 00:50:14.320相对来说是一样的，啊，是的。00:50:14.320 --> 00:50:17.210所有不同的模型都运行。00:50:17.460 --> 00:50:24.995酷。嗯，所以他们在这里做的一些假设是数据集，嗯，呃，00:50:24.995 --> 00:50:28.090没有注释偏见，他们也没有00:50:28.090 --> 00:50:31.525任何因果分析，因为他们只是想特别关注，00:50:31.525 --> 00:50:33.745嗯，关于这个毒性问题。00:50:33.745 --> 00:50:36.880嗯，他们使用CNN，00:50:36.880 --> 00:50:39.610啊，迂回的，是的，你们知道，废话，废话，废话。00:50:39.610 --> 00:50:41.650嗯，带预培训的链子手套。00:50:41.650 --> 00:50:43.240这可能像你的面包和黄油。00:50:43.240 --> 00:50:44.170预培训手套嵌入件。00:50:44.170 --> 00:50:45.940我相信你在Word2vec中已经知道了这一切。00:50:45.940 --> 00:50:48.250很酷，呃，Keras实现了这个。00:50:48.250 --> 00:50:53.470嗯，而且，呃，使用这些数据增强方法，嗯，00:50:53.470 --> 00:50:55.420都是维基百科，呃，00:50:55.420 --> 00:51:00.955一种方法，以及实际收集有关lgbtq身份的积极声明。00:51:00.955 --> 00:51:03.730所以在谷歌有一个叫做“尊重项目”的项目，00:51:03.730 --> 00:51:04.990我们出去的地方，00:51:04.990 --> 00:51:08.890和那些被认为是同性恋的人或者有朋友的人交谈，00:51:08.890 --> 00:51:11.290就像用积极的方式谈论这个，00:51:11.290 --> 00:51:13.120我们将其作为数据添加。00:51:13.120 --> 00:51:17.035嗯，所以我们可以知道这是一个积极的事情。00:51:17.035 --> 00:51:21.385为了测量模型的性能，00:51:21.385 --> 00:51:25.480同样，它也在研究不同小组之间的差异，并试图00:51:25.480 --> 00:51:29.695将子组性能与某种一般分布进行比较。00:51:29.695 --> 00:51:31.930所以这里他们用的是AUC，嗯，00:51:31.930 --> 00:51:34.630其中，AUC本质上是模型将00:51:34.630 --> 00:51:37.975给出一个随机选择的阳性例子，00:51:37.975 --> 00:51:42.070比随机选择的，呃，阴性的例子得分高。00:51:42.070 --> 00:51:44.890所以，嗯，这里你可以看到一些有毒的评论和00:51:44.890 --> 00:51:49.240无毒的评论，例如低AUC。00:51:49.240 --> 00:51:52.225嗯，这里，啊，这是一个00:51:52.225 --> 00:51:53.770具有高AUC的示例，00:51:53.770 --> 00:51:58.000因此，该模型在分离这两种评论方面做得比较好。00:51:58.000 --> 00:52:02.350嗯，他们在这本书中定义了不同的偏见。00:52:02.350 --> 00:52:05.080所以，呃，低亚组性能意味着00:52:05.080 --> 00:52:08.005模型在子组注释上的性能比它差，00:52:08.005 --> 00:52:09.625啊，总的来说。00:52:09.625 --> 00:52:14.150他们引入的度量方法叫做子群AUC。00:52:14.220 --> 00:52:17.350另一个是子组移位。00:52:17.350 --> 00:52:19.960这就是模型系统地评分评论的时候，00:52:19.960 --> 00:52:22.120嗯，从上面的某个子组。00:52:22.120 --> 00:52:24.280嗯，这有点像是在右边。00:52:24.280 --> 00:52:26.620嗯，还有，呃，00:52:26.620 --> 00:52:31.220这个背景正子群负移到左边。00:52:31.620 --> 00:52:36.775是啊。嗯，是的，这就是我说的。00:52:36.775 --> 00:52:38.980它可以走到右边或左边00:52:38.980 --> 00:52:42.740可以定义每个指标的不同度量。00:52:42.780 --> 00:52:46.000酷。嗯，结果是，00:52:46.000 --> 00:52:49.765啊，有点不只是看着，你知道，00:52:49.765 --> 00:52:53.380定性示例、um和一般评估指标，00:52:53.380 --> 00:52:56.470同时也关注为这项工作定义的一些关键指标，00:52:56.470 --> 00:52:58.465这些基于AUC的方法。00:52:58.465 --> 00:53:01.450他们能够看到00:53:01.450 --> 00:53:05.184最初的释放没有解释这些意想不到的偏见，00:53:05.184 --> 00:53:07.510下游排放，呃，确实如此，00:53:07.510 --> 00:53:10.195它包含了这类规范性数据00:53:10.195 --> 00:53:14.690也就是说我们认为模型应该学习的东西。00:53:15.390 --> 00:53:18.250酷。嗯，那么，嗯，00:53:18.250 --> 00:53:20.980在你成长的过程中，最后要记住的是，00:53:20.980 --> 00:53:25.840致力于，呃，创造更深入更好的模型是负责任地发布。00:53:25.840 --> 00:53:28.450嗯，这是我一直在做的一个项目00:53:28.450 --> 00:53:31.510许多不同的人称模型卡为模型报告。00:53:31.510 --> 00:53:36.280这有点像数据集数据表之后的下一步，00:53:36.280 --> 00:53:41.335嗯，其中，嗯，数据集的数据表主要关注有关数据的信息。00:53:41.335 --> 00:53:45.490啊，模型报告的模型卡关注模型的信息。00:53:45.490 --> 00:53:47.935嗯，所以它捕捉到了它所做的，00:53:47.935 --> 00:53:50.005它是如何工作的，为什么重要。00:53:50.005 --> 00:53:55.600嗯，这里的一个关键思想是在跨部门评估中分解。00:53:55.600 --> 00:53:57.055所以这还不够，呃，00:53:57.055 --> 00:54:00.430再推出以人为本的技术，00:54:00.430 --> 00:54:04.105有一些模糊的整体评分。00:54:04.105 --> 00:54:07.855实际上，您需要了解它在不同的子群体中是如何工作的。00:54:07.855 --> 00:54:11.620你必须理解数据告诉你的。00:54:11.620 --> 00:54:14.530嗯，下面是一些示例细节，00:54:14.530 --> 00:54:16.000模型卡应该有，00:54:16.000 --> 00:54:17.410嗯，是谁发明的，00:54:17.410 --> 00:54:18.970预期用途是什么，00:54:18.970 --> 00:54:22.715这样它就不会以不该使用的方式开始使用。00:54:22.715 --> 00:54:25.350嗯，可能是00:54:25.350 --> 00:54:28.125受到模型不均衡性能的影响。00:54:28.125 --> 00:54:31.430嗯，各种不同的身份群体，诸如此类。00:54:31.430 --> 00:54:33.580嗯，指标是，啊，00:54:33.580 --> 00:54:37.150你决定用它来理解模型的公平性，或者00:54:37.150 --> 00:54:42.025模型在不同子群和因子中的不同性能，00:54:42.025 --> 00:54:45.970有关评估数据和培训数据的信息。00:54:45.970 --> 00:54:49.210嗯，还有伦理考虑，嗯，00:54:49.210 --> 00:54:51.010所以你做了些什么？00:54:51.010 --> 00:54:53.800说明或哪些是风险和利益，00:54:53.800 --> 00:54:56.935嗯，那个，呃，和这个模型有关吗？00:54:56.935 --> 00:54:59.455嗯，还有其他注意事项和建议。00:54:59.455 --> 00:55:02.740例如，在对话人工智能案例中，00:55:02.740 --> 00:55:04.270他们正在处理合成数据。00:55:04.270 --> 00:55:08.395所以这就是评估的局限性，需要理解，00:55:08.395 --> 00:55:11.020因为它能告诉你很多关于偏见的事情，00:55:11.020 --> 00:55:13.660但一般情况下不会告诉你很多。00:55:13.660 --> 00:55:19.570[噪音]然后是定量的关键成分，00:55:19.570 --> 00:55:21.730嗯，模型卡的一部分00:55:21.730 --> 00:55:24.640这既包括跨部门评估，也包括分解评估。00:55:24.640 --> 00:55:28.300从这里，你可以得到不同种类的公平定义。00:55:28.300 --> 00:55:30.925越接近亚组间的均等，00:55:30.925 --> 00:55:34.840你越接近数学上公平的东西。00:55:34.840 --> 00:55:39.175可以。希望通过关注这些方法，00:55:39.175 --> 00:55:41.080考虑到这一切，00:55:41.080 --> 00:55:44.080我们可以在00:55:44.080 --> 00:55:47.620我们的模型更像是多样化的表现，00:55:47.620 --> 00:55:49.435嗯，从我们的道德人工智能。00:55:49.435 --> 00:55:50.905可以。就这样。00:55:50.905 --> 00:56:02.540
Thanks. [APPLAUSE]

