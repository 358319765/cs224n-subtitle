WEBVTT
Kind: captions
Language: en

00:00:04.760 --> 00:00:09.570
我们开始吧。所以欢迎来到最后一堂课。

00:00:09.570 --> 00:00:11.475
我希望你们都能活下来

00:00:11.475 --> 00:00:13.830
呃，结束你的项目。

00:00:13.830 --> 00:00:18.540
所以今天我们将听到关于NLP和深度学习的未来。

00:00:18.540 --> 00:00:22.440
呃，所以克里斯还在旅行，今天我们要请凯文·克拉克，

00:00:22.440 --> 00:00:24.825
谁是实验室的博士生，呃，

00:00:24.825 --> 00:00:26.580
在NLP实验室，

00:00:26.580 --> 00:00:29.610
他也是去年班上的助教之一。

00:00:29.610 --> 00:00:31.785
所以他对整个班级都很熟悉。

00:00:31.785 --> 00:00:33.765
嗯，那么，把它拿走，凯文。

00:00:33.765 --> 00:00:37.830
可以。谢谢，艾比。嗯，是的，

00:00:37.830 --> 00:00:40.440
去年成为助教后能回来真是太好了。

00:00:40.440 --> 00:00:45.350
嗯，今天我真的很高兴能谈论深入学习和NLP的未来。

00:00:45.350 --> 00:00:49.090
嗯，很明显，试图预测未来，嗯，

00:00:49.090 --> 00:00:51.800
对于深入学习或在那个空间的任何事情

00:00:51.800 --> 00:00:54.800
很难，因为这个领域变化非常快。

00:00:54.800 --> 00:00:57.080
作为一个参考点，

00:00:57.080 --> 00:01:00.050
让我们看看NLP的深入学习，

00:01:00.050 --> 00:01:02.290
嗯，大概五年前吧。

00:01:02.290 --> 00:01:08.300
事实上，很多想法现在被认为是非常核心的技术，

00:01:08.300 --> 00:01:10.445
嗯，当我们想到深度学习和NLP时，

00:01:10.445 --> 00:01:12.170
嗯，那时候根本不存在。

00:01:12.170 --> 00:01:14.870
嗯，你在这节课上学到的东西，比如seq2seq，

00:01:14.870 --> 00:01:17.180
注意机制，嗯，大规模的，

00:01:17.180 --> 00:01:20.105
阅读理解，呃，甚至框架

00:01:20.105 --> 00:01:23.300
比如TensorFlow或者Pytorch，嗯，不存在。

00:01:23.300 --> 00:01:27.145
我想说的是，

00:01:27.145 --> 00:01:31.205
因此，很难展望未来并说，

00:01:31.205 --> 00:01:33.665
好吧，事情会是怎样的？

00:01:33.665 --> 00:01:38.065
嗯，我想我们能做的是看看，嗯，

00:01:38.065 --> 00:01:41.870
现在确实有点起色的地方，嗯，

00:01:41.870 --> 00:01:43.640
所以在这些区域，嗯，

00:01:43.640 --> 00:01:46.370
最近有很多，很多成功，还有一些，呃，

00:01:46.370 --> 00:01:48.100
从那个项目，那个，

00:01:48.100 --> 00:01:50.900
这些领域在未来可能会很重要。

00:01:50.900 --> 00:01:55.820
嗯，在这次谈话中，我将主要集中在

00:01:55.820 --> 00:01:58.970
wh-关键理念，即杠杆的理念

00:01:58.970 --> 00:02:02.915
培训我们的NLP系统时未标记的示例。

00:02:02.915 --> 00:02:07.490
所以我想谈一下机器翻译的事，嗯，

00:02:07.490 --> 00:02:10.820
提高翻译质量，甚至

00:02:10.820 --> 00:02:14.315
以无人监督的方式进行翻译。

00:02:14.315 --> 00:02:16.170
这意味着你没有，嗯，

00:02:16.170 --> 00:02:19.230
配对句子，呃，和，还有他们的翻译。

00:02:19.230 --> 00:02:23.365
嗯，你只能从单语语料库中学习翻译模型。

00:02:23.365 --> 00:02:27.115
嗯，我要说的第二件事是，呃，

00:02:27.115 --> 00:02:29.330
Openai的GPT-2，嗯，

00:02:29.330 --> 00:02:32.435
总的来说，这一现象实际上在扩大，

00:02:32.435 --> 00:02:34.045
嗯，深度学习模式。

00:02:34.045 --> 00:02:38.330
嗯，我知道你在关于上下文表示的讲座中看到了一点，

00:02:38.330 --> 00:02:40.340
但这一点，但这将更深入一点。

00:02:40.340 --> 00:02:42.335
嗯，我想，嗯，

00:02:42.335 --> 00:02:46.655
全国人民党的这些新进展，

00:02:46.655 --> 00:02:48.600
嗯，相当大，呃，

00:02:48.600 --> 00:02:50.595
影响方面：

00:02:50.595 --> 00:02:53.755
呃，更广泛地说，甚至超越了我们使用的技术，

00:02:53.755 --> 00:02:55.070
尤其是，我的意思是，

00:02:55.070 --> 00:03:00.555
开始越来越多地关注NLP的社会影响，嗯，

00:03:00.555 --> 00:03:03.520
两者都是，嗯，在我们的模型可以做什么和实物方面

00:03:03.520 --> 00:03:06.590
关于人们想要应用这些模型的计划，嗯，

00:03:06.590 --> 00:03:09.755
我认为这确实有一些风险，嗯，

00:03:09.755 --> 00:03:13.160
在安全方面，也在偏见等方面。

00:03:13.160 --> 00:03:16.465
嗯，我还要谈谈未来的研究领域，

00:03:16.465 --> 00:03:19.140
嗯，这些都是研究领域，现在，嗯，

00:03:19.140 --> 00:03:22.060
在过去的一年里

00:03:22.060 --> 00:03:27.180
有希望的领域，我希望它们在未来仍将是重要的。

00:03:27.190 --> 00:03:29.700
好吧，嗯，首先，

00:03:29.700 --> 00:03:33.305
我想问这个问题，为什么深度学习最近如此成功？

00:03:33.305 --> 00:03:35.510
嗯，我喜欢这个漫画，

00:03:35.510 --> 00:03:38.045
这里有一个统计学习者，

00:03:38.045 --> 00:03:41.030
嗯，他们有一些非常复杂的，

00:03:41.030 --> 00:03:44.015
嗯，动机很好，嗯，做的方法，嗯，

00:03:44.015 --> 00:03:45.510
他们关心的任务，

00:03:45.510 --> 00:03:47.460
然后神经网络的人说，

00:03:47.460 --> 00:03:49.110
呃，叠更多层。

00:03:49.110 --> 00:03:52.020
嗯，所以，我想说的是，

00:03:52.020 --> 00:03:56.075
深度学习最近没有成功，因为它更

00:03:56.075 --> 00:04:01.530
理论上是有动机的，或者比以前的技术更复杂。

00:04:01.530 --> 00:04:04.245
事实上，我会说，事实上，很多，嗯，

00:04:04.245 --> 00:04:06.635
旧的统计方法有更多的

00:04:06.635 --> 00:04:10.175
这是一个理论基础，而不是我们在深度学习中的一些技巧。

00:04:10.175 --> 00:04:14.050
嗯，真正让深度学习如此

00:04:14.050 --> 00:04:17.660
近年来成功的是它的扩展能力，对吧。

00:04:17.660 --> 00:04:22.310
所以神经网络，当我们增加数据的大小，

00:04:22.310 --> 00:04:24.265
当我们增加模型的尺寸时，

00:04:24.265 --> 00:04:26.170
他们的精准度大大提高，

00:04:26.170 --> 00:04:28.565
其他方法则不然。

00:04:28.565 --> 00:04:32.210
如果你看看80年代和90年代，

00:04:32.210 --> 00:04:36.190
实际上，在神经网络方面有很多研究正在进行，嗯。

00:04:36.190 --> 00:04:39.130
但它没有，也没有像它那样的大肆宣传

00:04:39.130 --> 00:04:42.205
现在看来，这可能是因为，

00:04:42.205 --> 00:04:45.020
嗯，过去没有，嗯，

00:04:45.020 --> 00:04:47.180
同样的资源在计算机方面，

00:04:47.180 --> 00:04:49.235
在数据方面，嗯，

00:04:49.235 --> 00:04:53.120
直到现在，在我们到达一个拐点之后

00:04:53.120 --> 00:04:55.220
真正利用

00:04:55.220 --> 00:04:57.965
我们的深度学习模式，我们开始看到它变成，

00:04:57.965 --> 00:05:01.520
嗯，一个非常成功的机器学习范例。

00:05:01.520 --> 00:05:04.080
嗯，如果我们看大，呃，

00:05:04.080 --> 00:05:06.075
深入学习成功故事，嗯，

00:05:06.075 --> 00:05:10.200
我想，呃，你能看到这种想法的效果，对吧？

00:05:10.200 --> 00:05:16.490
所以这里有三个可以说是最著名的深度学习的成功，对吧。

00:05:16.490 --> 00:05:18.620
所以有图像识别，以前，

00:05:18.620 --> 00:05:20.870
人们使用的是高度工程化的，嗯，

00:05:20.870 --> 00:05:25.870
分类图像的特征，现在的神经网络比那些方法优越得多。

00:05:25.870 --> 00:05:29.785
嗯，机器翻译确实缩小了，嗯，

00:05:29.785 --> 00:05:33.020
基于短语的系统和人的素质翻译，

00:05:33.020 --> 00:05:35.730
所以这被广泛应用于谷歌翻译等领域

00:05:35.730 --> 00:05:39.115
而且在过去的五年里，质量实际上变得更好了。

00:05:39.115 --> 00:05:43.550
嗯，另一个大肆宣传的例子是玩游戏，所以，嗯，

00:05:43.550 --> 00:05:46.460
有关于阿塔里游戏的工作，还有阿尔法戈，

00:05:46.460 --> 00:05:50.395
呃，最近有阿尔法斯塔和Openai五号。

00:05:50.395 --> 00:05:53.599
嗯，如果你看下面三个案例

00:05:53.599 --> 00:05:57.200
这些成功确实是大量的数据，对吧。

00:05:57.200 --> 00:05:58.550
对于ImageNet，嗯，

00:05:58.550 --> 00:06:00.020
对于图像识别，嗯，

00:06:00.020 --> 00:06:03.035
有IMAGENET数据集，它有1400万个图像，

00:06:03.035 --> 00:06:06.320
嗯，机器翻译数据集通常有数百万个例子。

00:06:06.320 --> 00:06:09.275
嗯，玩游戏你可以

00:06:09.275 --> 00:06:12.470
生成尽可能多的培训数据，

00:06:12.470 --> 00:06:14.690
嗯，只要运行你的代理，

00:06:14.690 --> 00:06:16.040
嗯，在比赛中，

00:06:16.040 --> 00:06:18.660
嗯，一遍又一遍。

00:06:19.120 --> 00:06:21.360
嗯，如果我们，

00:06:21.360 --> 00:06:23.590
如果我们看NLP，嗯，

00:06:23.590 --> 00:06:27.740
对于很多任务来说，这个故事有点不同，嗯，对吧。

00:06:27.740 --> 00:06:32.030
所以，如果你看一些非常核心的流行任务，

00:06:32.030 --> 00:06:35.060
比如说，英语阅读理解，嗯，

00:06:35.060 --> 00:06:39.710
像Squad这样的数据集大约有100000个例子

00:06:39.710 --> 00:06:44.810
这远远低于数百万或数千万个例子，

00:06:44.810 --> 00:06:47.105
嗯，这些以前的，

00:06:47.105 --> 00:06:50.285
嗯，成功已经从中受益。

00:06:50.285 --> 00:06:54.210
嗯，那当然只是英语，对吧。

00:06:54.210 --> 00:06:55.770
嗯，有，嗯，

00:06:55.770 --> 00:06:59.570
成千上万种其他语言，我想这就是

00:06:59.570 --> 00:07:03.770
当前存在的NLP数据问题。

00:07:03.770 --> 00:07:06.455
嗯，绝大多数数据都是英文的，嗯，

00:07:06.455 --> 00:07:10.070
当世界人口的实际比例低于10%时，

00:07:10.070 --> 00:07:12.190
嗯，把英语作为他们的第一语言。

00:07:12.190 --> 00:07:17.565
嗯，所以这些小数据集的问题只有当你看，

00:07:17.565 --> 00:07:21.465
嗯，各种各样的语言，嗯，它们都存在。

00:07:21.465 --> 00:07:23.955
嗯，那么，我们该怎么做，

00:07:23.955 --> 00:07:25.800
呃，当我们受到这些数据的限制时，

00:07:25.800 --> 00:07:30.560
但我们想利用深度学习的规模，训练我们能训练的最大的模型。

00:07:30.560 --> 00:07:32.510
嗯，流行的解决方案，嗯，

00:07:32.510 --> 00:07:36.230
尤其是最近的成功是使用未标记的数据，嗯，

00:07:36.230 --> 00:07:37.805
因为与标签数据不同，

00:07:37.805 --> 00:07:40.840
未标记的数据很容易为语言获取。

00:07:40.840 --> 00:07:42.120
嗯，你可以上网，

00:07:42.120 --> 00:07:44.685
你可以去看书，你可以得到很多文本，嗯，

00:07:44.685 --> 00:07:49.370
而标记数据通常至少需要众包示例。

00:07:49.370 --> 00:07:54.730
嗯，在某些情况下，你甚至需要一个像语言学这样的专家，

00:07:54.730 --> 00:07:57.820
嗯，到，来注释数据。

00:07:59.510 --> 00:08:03.890
好吧，那么，嗯，第一部分的谈话将要用到

00:08:03.890 --> 00:08:08.195
利用未标记数据改进NLP模型的想法，

00:08:08.195 --> 00:08:11.070
嗯，完成机器翻译的任务。

00:08:11.990 --> 00:08:15.170
嗯，我们来谈谈机器翻译数据。

00:08:15.170 --> 00:08:20.520
嗯，确实存在相当大的机器翻译数据集。

00:08:20.520 --> 00:08:23.165
嗯，这些数据集不存在是因为

00:08:23.165 --> 00:08:26.870
NLP的研究人员为了训练他们的模型，对文本进行了注释，对吧。

00:08:26.870 --> 00:08:29.750
它们的存在是因为，呃，在不同的环境中，

00:08:29.750 --> 00:08:33.195
翻译是因为它很有用，例如，

00:08:33.195 --> 00:08:35.070
欧洲议会议事录，

00:08:35.070 --> 00:08:37.019
嗯，联合国会议记录，

00:08:37.019 --> 00:08:41.320
嗯，一些新闻网站，他们把文章翻译成多种语言。

00:08:41.320 --> 00:08:46.610
嗯，实际上，我们用来训练模型的机器翻译数据通常是

00:08:46.610 --> 00:08:52.745
更多需要翻译的现有案例的副产品，而不是，

00:08:52.745 --> 00:08:57.500
嗯，这是我们在世界上看到的那种文本的完整样本。

00:08:57.500 --> 00:08:58.910
嗯，这意味着第一，

00:08:58.910 --> 00:09:00.680
它在领域上是相当有限的，对吧。

00:09:00.680 --> 00:09:03.580
所以很难找到翻译的tweets，

00:09:03.580 --> 00:09:05.410
嗯，除非你正好为Twitter工作。

00:09:05.410 --> 00:09:08.145
嗯，除此之外，嗯，

00:09:08.145 --> 00:09:12.230
在所涵盖的语言方面有局限性，对吧。

00:09:12.230 --> 00:09:14.750
一些语言，比如欧洲语言，

00:09:14.750 --> 00:09:16.500
有很多翻译数据，嗯，

00:09:16.500 --> 00:09:19.180
对于其他语言来说，这要少得多。

00:09:19.180 --> 00:09:22.040
嗯，所以在我们想处理的这些环境中

00:09:22.040 --> 00:09:25.220
一个不同的领域或者我们想使用低资源语言的地方，

00:09:25.220 --> 00:09:27.995
嗯，我们受到标记数据的限制，嗯，

00:09:27.995 --> 00:09:30.985
但是我们可以很容易地找到未标记的数据。

00:09:30.985 --> 00:09:33.620
嗯，这实际上是一个很好解决的问题，嗯，

00:09:33.620 --> 00:09:37.010
也许不是100%，但我们可以很准确地观察

00:09:37.010 --> 00:09:41.195
一些文本，决定它所使用的语言，并训练分类器来实现这一点。

00:09:41.195 --> 00:09:43.610
嗯，这意味着很容易找到

00:09:43.610 --> 00:09:46.100
你所关心的任何语言的数据，因为你可以继续

00:09:46.100 --> 00:09:48.440
在网络上搜索数据

00:09:48.440 --> 00:09:52.650
并获得大量的单语数据。

00:09:55.240 --> 00:10:00.775
好吧，嗯，我现在要进入第一种方法，

00:10:00.775 --> 00:10:03.095
嗯，我要谈谈使用

00:10:03.095 --> 00:10:06.365
未标记数据以改进机器翻译模型。

00:10:06.365 --> 00:10:09.410
这项技术叫做预训练

00:10:09.410 --> 00:10:12.790
真的让人想起一些想法，比如，嗯，埃尔莫。

00:10:12.790 --> 00:10:16.580
嗯，我们的想法是通过语言建模进行预先培训。

00:10:16.580 --> 00:10:18.350
如果我们有，嗯，

00:10:18.350 --> 00:10:21.350
我们有两种语言想翻译，

00:10:21.350 --> 00:10:22.535
嗯，从一端到另一端，

00:10:22.535 --> 00:10:27.480
我们将为这两种语言收集大型数据集，然后我们可以训练，

00:10:27.480 --> 00:10:29.040
嗯，两种语言模式，

00:10:29.040 --> 00:10:33.365
每个数据上都有一个，然后，嗯，

00:10:33.365 --> 00:10:34.490
我们可以用这些，呃，

00:10:34.490 --> 00:10:38.450
预先训练的语言模型作为机器翻译系统的初始化。

00:10:38.450 --> 00:10:41.720
嗯，所以编码器将被初始化为

00:10:41.720 --> 00:10:45.485
在源端语言上训练的语言模型的权重，嗯，

00:10:45.485 --> 00:10:49.830
解码器将被初始化为目标大小语言，呃，

00:10:49.830 --> 00:10:51.225
这会，嗯，

00:10:51.225 --> 00:10:55.490
提高你的模型的性能，因为在这个预培训期间，

00:10:55.490 --> 00:10:59.750
我们希望我们的语言模型能够学习有用的信息，比如，

00:10:59.750 --> 00:11:02.460
单词的意思，或者，呃，呃，

00:11:02.460 --> 00:11:05.250
语言的结构，嗯，

00:11:05.250 --> 00:11:09.020
他们正在处理，嗯，这个可以，呃，

00:11:09.020 --> 00:11:12.410
帮助机器翻译模型，

00:11:12.410 --> 00:11:15.020
嗯，当我们调整好的时候。

00:11:15.020 --> 00:11:17.464
嗯，让我停下来问一下有没有问题，

00:11:17.464 --> 00:11:18.620
总的来说，感觉，

00:11:18.620 --> 00:11:24.870
在整个演讲过程中，请随意提问。可以。

00:11:25.920 --> 00:11:33.385
所以，这里有一个情节展示了这种预训练技术的一些结果。

00:11:33.385 --> 00:11:36.040
嗯，这是英语到德语的翻译。

00:11:36.040 --> 00:11:39.805
呃，x轴是多少训练数据，

00:11:39.805 --> 00:11:41.920
在无监督的培训数据中，嗯，

00:11:41.920 --> 00:11:43.075
你提供这些模型，

00:11:43.075 --> 00:11:45.355
当然，它们也有大量的

00:11:45.355 --> 00:11:48.940
此培训前步骤的单语数据。

00:11:48.940 --> 00:11:51.970
你可以看到这个很好用，对吧？

00:11:51.970 --> 00:11:54.445
所以你有两个蓝点，嗯，

00:11:54.445 --> 00:11:57.670
提高性能，这就是蓝线以上的红线，

00:11:57.670 --> 00:12:00.175
嗯，做这种训练前技巧的时候。

00:12:00.175 --> 00:12:01.689
不足为奇，

00:12:01.689 --> 00:12:06.740
当标记的数据量很小时，此增益尤其大。

00:12:10.350 --> 00:12:14.080
嗯，有个问题，

00:12:14.080 --> 00:12:17.260
呃，我想谈的是培训前，也就是说，

00:12:17.260 --> 00:12:18.850
在预训中，你有

00:12:18.850 --> 00:12:20.890
这两种不同的语言模式

00:12:20.890 --> 00:12:23.035
两人之间的任何互动，

00:12:23.035 --> 00:12:25.780
当你在未标记的语料库上运行它们时。

00:12:25.780 --> 00:12:28.435
嗯，这是一个简单的技巧，嗯，

00:12:28.435 --> 00:12:32.485
试图解决这个问题，这叫做自我训练。

00:12:32.485 --> 00:12:37.090
嗯，这个想法来自我们的单语语料库，

00:12:37.090 --> 00:12:40.210
所以在这个例子中，“我去过比利时”，这是一个英语句子。

00:12:40.210 --> 00:12:45.400
嗯，这句话我们没有人工翻译，

00:12:45.400 --> 00:12:48.925
但我们能做的是运行我们的机器翻译模型，

00:12:48.925 --> 00:12:52.750
我们会得到目标语言的翻译。

00:12:52.750 --> 00:12:56.320
嗯，既然这是机器学习模型的结果，那就不完美了，

00:12:56.320 --> 00:13:00.160
但是我们可以希望我们的模型仍然可以从这种模式中学习。

00:13:00.160 --> 00:13:03.580
有噪音标签的例子，对吗？

00:13:03.580 --> 00:13:05.275
所以我们，我们治疗，嗯，

00:13:05.275 --> 00:13:08.230
我们原来的单语句子和它的机器

00:13:08.230 --> 00:13:12.490
翻译就像是人类提供的翻译，

00:13:12.490 --> 00:13:17.030
嗯，在这个例子中训练我们的机器学习模型。

00:13:19.800 --> 00:13:24.190
嗯，我觉得这看起来很奇怪，实际上

00:13:24.190 --> 00:13:27.970
当你第一次看到它是因为它看起来是圆形的，对吗？

00:13:27.970 --> 00:13:31.315
所以如果你看这个，呃，呃，

00:13:31.315 --> 00:13:33.850
模型训练的翻译

00:13:33.850 --> 00:13:38.095
生产实际上正是它已经开始生产的，

00:13:38.095 --> 00:13:43.420
对，因为，嗯，这个翻译首先来自我们的模型。

00:13:43.420 --> 00:13:45.700
嗯，实际上在实践中，

00:13:45.700 --> 00:13:49.480
由于这个问题，这不是一种广泛使用的技术，

00:13:49.480 --> 00:13:53.365
嗯，但它激发了另一种称为“反向翻译”的技术。

00:13:53.365 --> 00:13:56.740
这种技术非常流行，嗯，

00:13:56.740 --> 00:13:59.950
解决这个问题的方法，嗯，

00:13:59.950 --> 00:14:04.240
这在使用未标记的数据进行翻译方面取得了很大的成功。

00:14:04.240 --> 00:14:06.940
所以这是方法，而不仅仅是

00:14:06.940 --> 00:14:10.855
拥有从源语言到目标语言的翻译系统，

00:14:10.855 --> 00:14:13.210
嗯，我们还要训练一个

00:14:13.210 --> 00:14:16.375
从目标语言到源语言。

00:14:16.375 --> 00:14:18.670
在这种情况下，如果，

00:14:18.670 --> 00:14:21.340
如果一天结束的时候我们想要一个法式到英式的模特，嗯，

00:14:21.340 --> 00:14:24.910
我们首先要训练一个从英语到法语的模式。

00:14:24.910 --> 00:14:27.880
然后我们可以做一些类似于自我标记的事情。

00:14:27.880 --> 00:14:30.205
所以我们选一个英语句子。

00:14:30.205 --> 00:14:33.370
我们运行我们的英语到法语模式和翻译。

00:14:33.370 --> 00:14:35.950
与我们以前所做的不同之处在于

00:14:35.950 --> 00:14:38.500
我们实际上要切换源端和目标端。

00:14:38.500 --> 00:14:42.640
所以在这个例子中，法语句子是源序列。

00:14:42.640 --> 00:14:45.985
呃，目标序列是，嗯，

00:14:45.985 --> 00:14:50.740
我们最初的英语句子来自单语语料库。

00:14:50.740 --> 00:14:52.165
现在我们正在训练语言，

00:14:52.165 --> 00:14:54.040
机器翻译系统

00:14:54.040 --> 00:14:57.265
另一个方向是法语到英语。

00:14:57.265 --> 00:15:00.445
嗯，那么，为什么我们认为这会更好呢？

00:15:00.445 --> 00:15:02.320
嗯，第一，嗯，

00:15:02.320 --> 00:15:05.230
训练不再有这种循环

00:15:05.230 --> 00:15:10.210
因为正在训练的模型是完全不同模型的输出。

00:15:10.210 --> 00:15:14.845
嗯，另一件我认为非常重要的事情是，

00:15:14.845 --> 00:15:18.970
嗯，翻译，模型被训练来制作。

00:15:18.970 --> 00:15:21.520
所以解码器实际上正在学习的东西

00:15:21.520 --> 00:15:24.430
生成从不坏的翻译，对吗？

00:15:24.430 --> 00:15:26.574
所以如果你看这个例子，

00:15:26.574 --> 00:15:29.545
法语到英语模式的目标序列，

00:15:29.545 --> 00:15:31.165
我去过比利时，嗯，

00:15:31.165 --> 00:15:34.645
最初来自单语语料库。

00:15:34.645 --> 00:15:37.420
嗯，所以我认为凭直觉这是有道理的

00:15:37.420 --> 00:15:40.435
如果我们想培养一个好的翻译模式，

00:15:40.435 --> 00:15:44.620
嗯，把它暴露在嘈杂的输入信号中可能没关系。

00:15:44.620 --> 00:15:47.515
所以我们把它暴露在一个英语和法语系统的输出中，

00:15:47.515 --> 00:15:48.730
它可能并不完美。

00:15:48.730 --> 00:15:52.330
嗯，但我们不想做的是，暴露在

00:15:52.330 --> 00:15:54.850
目标序列差，因为

00:15:54.850 --> 00:15:58.370
不会有效地学习如何用这种语言生成。

00:15:58.560 --> 00:16:04.300
在我得到结果之前，有没有关于后译的问题？嗯，当然。

00:16:04.300 --> 00:16:08.980
[背景]

00:16:08.980 --> 00:16:11.500
所以这是假设我们有大量的

00:16:11.500 --> 00:16:16.700
未标记的数据，我们希望使用它来帮助我们的翻译模型。

00:16:17.330 --> 00:16:19.875
这有道理吗？

00:16:19.875 --> 00:16:23.340
嗯，也许你可以澄清这个问题。

00:16:23.340 --> 00:16:29.160
[背景]

00:16:29.160 --> 00:16:32.830
是的，没错。所以我们有大量的英语语料库，包括句子，

00:16:32.830 --> 00:16:36.190
“我去过比利时，”我们不知道翻译，但我们还是想去。

00:16:36.190 --> 00:16:39.630
使用此数据。是的，另一个问题。

00:16:39.630 --> 00:16:45.280
[背景]

00:16:45.280 --> 00:16:47.110
是的，所以这是一个很好的问题，你是如何做到的？

00:16:47.110 --> 00:16:52.300
避免这两种模式，比如说爆炸和产生垃圾？

00:16:52.300 --> 00:16:54.400
然后他们就在互相喂垃圾。

00:16:54.400 --> 00:16:57.820
答案是这里也有一定数量的标记数据。

00:16:57.820 --> 00:17:00.820
所以在未标记的数据上，您可以这样做，但在标记的数据上，

00:17:00.820 --> 00:17:02.110
你做标准训练，

00:17:02.110 --> 00:17:04.795
这样你就避免了，你，

00:17:04.795 --> 00:17:07.900
你要确保你的模型保持在轨道上，因为它们仍然需要适应

00:17:07.900 --> 00:17:12.175
标记的数据。是的，另一个问题。

00:17:12.175 --> 00:17:15.475
你如何安排这两种模式的培训？

00:17:15.475 --> 00:17:17.500
是的，这是个好问题。

00:17:17.500 --> 00:17:21.580
我认为这基本上就像一个超参数，你可以调整。

00:17:21.580 --> 00:17:25.720
所以我认为一个很常见的事情是首先，

00:17:25.720 --> 00:17:28.270
仅在标记数据上训练两个模型。

00:17:28.270 --> 00:17:32.965
然后贴标签，嗯，然后再做反向翻译

00:17:32.965 --> 00:17:37.480
在一个大的语料库上，一次又一次重复这个过程。

00:17:37.480 --> 00:17:40.165
所以每次迭代，你都要训练标签数据，

00:17:40.165 --> 00:17:43.510
标记一些未标记的数据，现在您可以使用更多的数据。

00:17:43.510 --> 00:17:46.270
但是我认为有很多种安排是有效的

00:17:46.270 --> 00:17:50.380
在这里。可以。另一个问题。

00:17:50.380 --> 00:18:06.100
我对评估很好奇，考虑到如果你有一个非常好的法语-英语模式，你可以尝试查找，或者竞争如果你有一个好的法语-英语模式，你可以尝试查找原始来源，看看它是否匹配。

00:18:06.100 --> 00:18:07.435
是的，我不是，我不太确定。

00:18:07.435 --> 00:18:10.135
你是建议像英语到法语再到英语，看看是否？

00:18:10.135 --> 00:18:11.635
我明白了，是的，是的，

00:18:11.635 --> 00:18:12.775
这真是个有趣的主意。

00:18:12.775 --> 00:18:15.775
实际上，我们要谈谈这类，

00:18:15.775 --> 00:18:17.290
这叫做循环一致性，

00:18:17.290 --> 00:18:20.000
这个想法在稍后的谈话中。

00:18:20.970 --> 00:18:23.770
好吧，我继续看结果。

00:18:23.770 --> 00:18:28.120
所以，这里是使用未标记数据来改进翻译的方法。

00:18:28.120 --> 00:18:29.890
效果如何？

00:18:29.890 --> 00:18:33.220
嗯，答案是这些改进至少对我来说是这样，他们

00:18:33.220 --> 00:18:36.490
出奇地非常好，对吧？

00:18:36.490 --> 00:18:39.445
所以，嗯，这是英语到德语的翻译。

00:18:39.445 --> 00:18:44.515
这是Facebook的一些研究成果，因此他们使用了500万个贴有标签的句子对。

00:18:44.515 --> 00:18:52.040
但他们也使用了230个单语句子，所以没有翻译的句子。

00:18:52.290 --> 00:18:56.425
你可以看到，与以前的技术相比，

00:18:56.425 --> 00:18:59.755
他们提高了6个布鲁分数，嗯，

00:18:59.755 --> 00:19:03.010
如果你把它与以前的研究和机器翻译相比较

00:19:03.010 --> 00:19:04.180
真的是个大收获，对吧？

00:19:04.180 --> 00:19:08.020
所以，即使是像变压器的发明，大多数人都会

00:19:08.020 --> 00:19:13.165
考虑到NLP是一项非常重要的研究进展，

00:19:13.165 --> 00:19:16.825
这比之前的工作提高了2.5个百分点。

00:19:16.825 --> 00:19:22.330
在这里，只要使用更多的数据，就不用做任何花哨的模型设计，

00:19:22.330 --> 00:19:25.400
嗯，实际上我们得到了更大的改进。

00:19:29.130 --> 00:19:34.390
可以。一个有趣的问题，

00:19:34.390 --> 00:19:38.125
嗯，假设我们只有单语语料库。

00:19:38.125 --> 00:19:41.155
所以我们没有任何人工翻译的句子。

00:19:41.155 --> 00:19:43.390
我们只有两种语言的句子。

00:19:43.390 --> 00:19:47.080
嗯，所以你可以想象的情况是，

00:19:47.080 --> 00:19:48.985
嗯，一个外星人下来了，

00:19:48.985 --> 00:19:50.740
嗯，开始和你说话，这是一个

00:19:50.740 --> 00:19:53.965
奇怪的外星语言，嗯，它能说很多，

00:19:53.965 --> 00:19:58.120
你最终能把它的意思翻译成英语吗？

00:19:58.120 --> 00:20:01.670
嗯，只要有大量的数据？

00:20:03.300 --> 00:20:06.205
嗯，所以我先从，嗯，

00:20:06.205 --> 00:20:11.935
当你只有未标记的句子时，翻译比完整的任务要简单。

00:20:11.935 --> 00:20:15.220
嗯，不是逐句翻译，

00:20:15.220 --> 00:20:18.640
让我们从只关心逐字翻译开始。

00:20:18.640 --> 00:20:21.490
所以这里的目标是用一种语言给出一个单词，

00:20:21.490 --> 00:20:25.330
找到它的翻译，但不使用任何标记的数据。

00:20:25.330 --> 00:20:27.100
嗯，还有方法，

00:20:27.100 --> 00:20:29.440
我们试图解决的方法

00:20:29.440 --> 00:20:33.460
这个任务叫做跨语言嵌入。

00:20:33.460 --> 00:20:35.830
嗯，所以目标是学习，呃，

00:20:35.830 --> 00:20:39.265
两种语言的单词矢量，

00:20:39.265 --> 00:20:41.935
我们希望向量这个词

00:20:41.935 --> 00:20:45.550
你已经学过的关于矢量词的所有好的性质，嗯，

00:20:45.550 --> 00:20:49.149
但我们也需要特定语言的词汇载体，

00:20:49.149 --> 00:20:52.860
嗯，接近它的翻译矢量。

00:20:52.860 --> 00:20:57.090
嗯，所以我不确定它是否在这个图中可见，但这个图显示了

00:20:57.090 --> 00:21:02.475
大量的英语和德语单词，你可以看到，

00:21:02.475 --> 00:21:07.795
每个英语单词都有对应的德语单词，

00:21:07.795 --> 00:21:10.330
嗯，在它的嵌入空间附近。

00:21:10.330 --> 00:21:15.010
所以，如果我们学习这样的嵌入，那么进行逐字翻译就相当容易了。

00:21:15.010 --> 00:21:16.705
嗯，我们只选一个英文单词，

00:21:16.705 --> 00:21:18.550
我们找到最近的，呃，

00:21:18.550 --> 00:21:22.075
这个联合嵌入空间中的德语单词

00:21:22.075 --> 00:21:26.030
这将给我们一个英语单词的翻译。

00:21:28.470 --> 00:21:32.185
嗯，我们的关键方法

00:21:32.185 --> 00:21:35.500
假设我们要用它来解决这个问题，

00:21:35.500 --> 00:21:40.870
嗯，这-即使你运行两次word2vec，你会得到非常不同的嵌入。

00:21:40.870 --> 00:21:46.930
嗯，嵌入空间的结构有很多规律性，

00:21:46.930 --> 00:21:49.675
我们可以利用这个规律，嗯，

00:21:49.675 --> 00:21:51.700
为了帮助找出时间，

00:21:51.700 --> 00:21:54.370
嗯，嵌入空间之间的对齐。

00:21:54.370 --> 00:21:56.830
所以在这里要更具体一些。

00:21:56.830 --> 00:21:59.560
这是两组单词嵌入的图片。

00:21:59.560 --> 00:22:00.820
所以红色的，我们有，嗯，

00:22:00.820 --> 00:22:02.655
英语单词，in，uh，

00:22:02.655 --> 00:22:04.565
蓝色我们有意大利语单词，

00:22:04.565 --> 00:22:09.280
虽然，嗯，向量空间现在看起来非常不同，

00:22:09.280 --> 00:22:12.400
嗯，你可以看到它们有一个非常相似的结构，对吧？

00:22:12.400 --> 00:22:16.735
所以你可以想象距离和

00:22:16.735 --> 00:22:19.345
呃，猫和猫在，嗯，

00:22:19.345 --> 00:22:22.570
英语嵌入空间应该与距离非常相似

00:22:22.570 --> 00:22:27.880
在意大利的加托和费利诺之间。

00:22:27.880 --> 00:22:34.310
嗯，这种方法激发了学习这些跨语言嵌入的算法。

00:22:35.400 --> 00:22:38.440
嗯，这就是我的想法。

00:22:38.440 --> 00:22:40.960
我们要做的是学习

00:22:40.960 --> 00:22:44.080
我们可以变换的旋转，

00:22:44.080 --> 00:22:46.660
嗯，我们的英文嵌入集，所以

00:22:46.660 --> 00:22:50.515
它们与我们的意大利刺绣相匹配。

00:22:50.515 --> 00:22:52.780
从数学上来说，这意味着我们要学习

00:22:52.780 --> 00:22:55.660
一个矩阵，如果我们取它的话，

00:22:55.660 --> 00:23:00.355
呃，英语中cat的矢量这个词，我们用w乘以。

00:23:00.355 --> 00:23:06.205
最后我们用西班牙语或意大利语表示加图，

00:23:06.205 --> 00:23:09.550
嗯，这里的一个细节是，

00:23:09.550 --> 00:23:12.580
我们将把w约束为正交的。

00:23:12.580 --> 00:23:15.070
从几何角度来说，这意味着

00:23:15.070 --> 00:23:17.980
只做一个旋转，

00:23:17.980 --> 00:23:19.945
向量，以x表示。

00:23:19.945 --> 00:23:24.320
它不会做其他更奇怪的转变。

00:23:24.870 --> 00:23:29.305
所以这是我们的目标是学习这个。

00:23:29.305 --> 00:23:31.000
接下来我要说的是，

00:23:31.000 --> 00:23:36.985
说到我们是怎么学会这个的，嗯，

00:23:36.985 --> 00:23:41.665
实际上有很多学习w矩阵的技巧，

00:23:41.665 --> 00:23:44.740
嗯，但是，嗯，这是

00:23:44.740 --> 00:23:48.310
我认为相当聪明的人被称为对抗性训练。

00:23:48.310 --> 00:23:50.635
嗯，它的工作原理如下：

00:23:50.635 --> 00:23:53.770
除了尝试学习这个w矩阵，

00:23:53.770 --> 00:23:57.670
我们还将尝试学习一个模型，呃，

00:23:57.670 --> 00:23:58.915
被称为鉴别器，

00:23:58.915 --> 00:24:02.800
它将要做的是，取一个向量，它将试图预测，

00:24:02.800 --> 00:24:05.080
是这个向量，嗯，

00:24:05.080 --> 00:24:08.830
一个英语单词嵌入还是一个意大利语单词嵌入？

00:24:08.830 --> 00:24:11.425
换句话说，如果你想一想，

00:24:11.425 --> 00:24:14.920
图表，我们要求鉴别器做的是，

00:24:14.920 --> 00:24:17.680
它给出了其中一个点，它试图预测

00:24:17.680 --> 00:24:21.055
基本上是一个红点，原来是一个英文单词，还是一个蓝点？

00:24:21.055 --> 00:24:24.010
如果我们没有w矩阵，这是

00:24:24.010 --> 00:24:27.190
对于鉴别器来说是一项非常简单的任务，因为，

00:24:27.190 --> 00:24:32.425
嗯，英语和意大利语的单词嵌入是分开的。

00:24:32.425 --> 00:24:36.130
但是，如果我们学习w矩阵

00:24:36.130 --> 00:24:39.955
它成功地将所有这些嵌入物排列在一起，

00:24:39.955 --> 00:24:43.270
那么我们的鉴别器就永远不会做得好，对吧。

00:24:43.270 --> 00:24:46.210
我们可以想象它永远不会比50%更好，

00:24:46.210 --> 00:24:48.835
因为给定了一个向量来表示猫，

00:24:48.835 --> 00:24:51.190
不知道是猫的向量

00:24:51.190 --> 00:24:54.130
由w转换，还是它实际上是gatto的向量？

00:24:54.130 --> 00:24:58.885
嗯，因为在这种情况下，这两个向量是对齐的，所以它们是在彼此之上的。

00:24:58.885 --> 00:25:03.715
嗯，所以，嗯，在训练期间，你首先，

00:25:03.715 --> 00:25:06.790
你交替训练鉴别器一点

00:25:06.790 --> 00:25:09.640
意味着确保尽可能的好

00:25:09.640 --> 00:25:13.120
区分英语和意大利语单词，然后你

00:25:13.120 --> 00:25:16.930
训练w，训练w的目标是，

00:25:16.930 --> 00:25:20.050
呃，基本上尽量混淆鉴别器。

00:25:20.050 --> 00:25:23.215
嗯，所以你想有一种情况，

00:25:23.215 --> 00:25:26.170
你不能用这种机器学习模式，

00:25:26.170 --> 00:25:29.290
弄清楚一个词是否真的嵌入了，嗯，

00:25:29.290 --> 00:25:33.625
是，嗯，最初是英语还是意大利语的矢量词。

00:25:33.625 --> 00:25:36.085
嗯，所以在一天结束的时候，

00:25:36.085 --> 00:25:39.410
你有一些向量是相互对齐的。

00:25:39.420 --> 00:25:43.460
嗯，关于这种方法有什么问题吗？

00:25:47.220 --> 00:25:50.650
可以。嗯，他-有一个链接指向一份更详细的文件。

00:25:50.650 --> 00:25:53.275
实际上还有很多其他的技巧你可以做，

00:25:53.275 --> 00:25:55.850
嗯，但这是一个关键的想法。

00:25:58.440 --> 00:26:04.810
嗯，好吧。所以这是逐字逐句的无监督翻译。

00:26:04.810 --> 00:26:08.930
嗯，我们如何进行全句对句翻译？

00:26:09.150 --> 00:26:11.725
嗯，所以我们要用，嗯，

00:26:11.725 --> 00:26:13.750
一种标准的seq2seq模型，

00:26:13.750 --> 00:26:16.660
嗯，甚至没有注意机制。

00:26:16.660 --> 00:26:19.900
嗯，标准的seq2seq有一个变化

00:26:19.900 --> 00:26:23.050
这里的模特就是这样，嗯，

00:26:23.050 --> 00:26:25.780
我们将使用相同的编码器和解码器，

00:26:25.780 --> 00:26:30.160
呃，不管输入和输出语言是什么。

00:26:30.160 --> 00:26:31.930
所以你可以看到，嗯，

00:26:31.930 --> 00:26:33.340
在这个例子中，嗯，

00:26:33.340 --> 00:26:35.815
我们可以给编码器一个英语句子，

00:26:35.815 --> 00:26:40.360
我们也可以给它一个法语句子，它会有这些跨语言的嵌入。

00:26:40.360 --> 00:26:43.255
所以它会有英文单词的向量表示

00:26:43.255 --> 00:26:47.140
和法语单词，这意味着它可以处理任何类型的输入。

00:26:47.140 --> 00:26:49.375
嗯，对于解码器，

00:26:49.375 --> 00:26:52.930
我们需要给它一些关于应该用什么语言生成的信息。

00:26:52.930 --> 00:26:54.955
它将生成法语还是英语？

00:26:54.955 --> 00:26:58.660
嗯，那么做的方式是，呃，

00:26:58.660 --> 00:27:01.915
喂入一个特殊的令牌，这里是fr

00:27:01.915 --> 00:27:05.590
在brack括号中表示法语，表示模型，

00:27:05.590 --> 00:27:07.975
好吧，你现在应该用法语生成。

00:27:07.975 --> 00:27:11.380
嗯，在这个数字里只有法语，

00:27:11.380 --> 00:27:13.975
但是你也可以想象喂养这个模型，呃，

00:27:13.975 --> 00:27:17.635
括号中的英语，然后告诉它生成英语。

00:27:17.635 --> 00:27:21.670
你能看到的一件事就是你可以用这种模型来生成，

00:27:21.670 --> 00:27:23.155
一定要从英语到法语。

00:27:23.155 --> 00:27:25.450
你也可以使用这个模型作为自动编码器，对吧。

00:27:25.450 --> 00:27:27.295
所以，在底部，嗯，

00:27:27.295 --> 00:27:31.510
它将一个法语句子作为输入，并将其生成为

00:27:31.510 --> 00:27:37.580
这里的输出意味着只是复制原始的输入序列。

00:27:38.850 --> 00:27:43.104
嗯，所以只需要对标准的seq2seq做一个小小的改动。

00:27:43.104 --> 00:27:46.765
下面是我们将如何训练seq2seq模型。

00:27:46.765 --> 00:27:50.170
嗯，有两个培训目标，嗯，

00:27:50.170 --> 00:27:51.940
我来解释一下他们为什么，呃，

00:27:51.940 --> 00:27:55.060
在这个模型中，只需几张幻灯片。

00:27:55.060 --> 00:27:57.025
现在，让我们说一下它们是什么。

00:27:57.025 --> 00:27:59.110
第一个是，嗯，

00:27:59.110 --> 00:28:01.165
称为去噪自动编码器。

00:28:01.165 --> 00:28:06.430
嗯，我们要训练我们的模型，在这种情况下，我们要做的就是用一个，呃，句子。

00:28:06.430 --> 00:28:08.140
所以，嗯，在这里

00:28:08.140 --> 00:28:10.795
一个英语句子，但也可以是一个法语句子。

00:28:10.795 --> 00:28:14.170
嗯，我们要把这些词拼凑一下，

00:28:14.170 --> 00:28:16.885
然后我们要让模特

00:28:16.885 --> 00:28:20.560
消除噪音，换言之，这句话的意思是

00:28:20.560 --> 00:28:25.345
重新生成句子在被置乱之前的实际内容。

00:28:25.345 --> 00:28:31.740
也许这是一个有用的培训目标的原因是，

00:28:31.740 --> 00:28:35.505
呃，因为我们有一个编码器解码器，没有引起注意，

00:28:35.505 --> 00:28:41.780
编码器正在将源语句的整体转换为单个向量，

00:28:41.780 --> 00:28:47.110
自动编码器所做的是确保向量包含有关

00:28:47.110 --> 00:28:52.390
使我们能够恢复原判的判决，

00:28:52.390 --> 00:28:56.180
嗯，来自编码器产生的矢量。

00:28:57.960 --> 00:29:00.805
嗯，这就是目标1。

00:29:00.805 --> 00:29:05.005
培训目标2是现在我们要做一个翻译，

00:29:05.005 --> 00:29:07.479
嗯，但是，嗯，和以前一样，

00:29:07.479 --> 00:29:09.775
我们将使用这个反向翻译的想法。

00:29:09.775 --> 00:29:12.970
所以记住，我们只有没有标记的句子，

00:29:12.970 --> 00:29:16.015
我们没有任何人工翻译，

00:29:16.015 --> 00:29:19.750
但是我们仍然可以做的是，

00:29:19.750 --> 00:29:22.000
嗯，我们说一个英语句子，或者说一个法语句子，

00:29:22.000 --> 00:29:24.505
如果是法语句子，我们可以把它翻译成英语，嗯，

00:29:24.505 --> 00:29:28.120
在当前状态下使用我们的模型，

00:29:28.120 --> 00:29:32.605
然后我们可以要求那个模型从英语中翻译或者翻译-是的，

00:29:32.605 --> 00:29:34.690
把英语译回法语。

00:29:34.690 --> 00:29:37.105
嗯，你能想象的是，在这种环境下，

00:29:37.105 --> 00:29:39.640
输入序列会有点混乱

00:29:39.640 --> 00:29:42.820
因为它是我们不完善的机器学习模型的输出。

00:29:42.820 --> 00:29:47.050
所以这里输入的顺序是“我是学生”，嗯，一个词被删除了，

00:29:47.050 --> 00:29:51.820
但是，嗯，我们现在要训练它，即使有这种糟糕的输入，

00:29:51.820 --> 00:29:55.330
复制原稿，嗯，

00:29:55.330 --> 00:29:58.270
法语句子，嗯，来自我们的，

00:29:58.270 --> 00:30:01.270
嗯，单语语料库，嗯，法语文本。

00:30:01.270 --> 00:30:07.400
[噪音]嗯，让我-让我在这里停下来问问题。

00:30:08.910 --> 00:30:13.840
当然。

00:30:13.840 --> 00:30:16.000
[噪音][听不见]如果，嗯，你为什么

00:30:16.000 --> 00:30:20.305
这个正交性约束让你的单词嵌入，

00:30:20.305 --> 00:30:22.900
是为了避免过度安装吗？

00:30:22.900 --> 00:30:29.800
你试过把它脱下来吗？你知道，看看[听不见]

00:30:29.800 --> 00:30:31.060
是啊。这是个好问题。

00:30:31.060 --> 00:30:35.305
嗯，这可以追溯到早期有单词翻译的时候。

00:30:35.305 --> 00:30:39.325
为什么我们要约束w矩阵是正交的？

00:30:39.325 --> 00:30:43.030
嗯，基本上是这样的。这是为了避免过拟合，尤其是，

00:30:43.030 --> 00:30:46.060
它假设我们的嵌入空间是

00:30:46.060 --> 00:30:50.005
类似的，实际上只有一个旋转可以区分，

00:30:50.005 --> 00:30:53.500
嗯，我们的英语单词向量和意大利语单词向量。

00:30:53.500 --> 00:30:57.460
嗯，我想有，嗯，

00:30:57.460 --> 00:31:01.360
有一些结果不包括正交性约束，

00:31:01.360 --> 00:31:04.480
我认为如果不把它放在里面的话，会对表演造成轻微的伤害。

00:31:04.480 --> 00:31:09.130
[噪音]好的。

00:31:09.130 --> 00:31:11.155
嗯，那么-继续说，

00:31:11.155 --> 00:31:13.765
嗯，无监督的机器翻译，

00:31:13.765 --> 00:31:17.290
嗯，我-我给了一个训练方法。

00:31:17.290 --> 00:31:20.395
我没有很好地解释为什么它会起作用，所以-所以，

00:31:20.395 --> 00:31:24.790
嗯，这是对这个想法的一些直觉。

00:31:24.790 --> 00:31:27.730
嗯，记住，嗯，

00:31:27.730 --> 00:31:29.665
我们要初始化

00:31:29.665 --> 00:31:33.264
我们的机器翻译模型有这些跨语言嵌入，

00:31:33.264 --> 00:31:37.015
这意味着英语和法语单词看起来应该差不多。

00:31:37.015 --> 00:31:42.565
嗯，我们也在使用共享的，嗯，编码器。

00:31:42.565 --> 00:31:44.860
嗯，这意味着如果你考虑一下，

00:31:44.860 --> 00:31:46.645
嗯，在顶部，我们只有，

00:31:46.645 --> 00:31:51.760
一个自动编码的目标，我们当然可以相信我们的模型可以学习到这一点。

00:31:51.760 --> 00:31:54.250
嗯，这是一项非常简单的任务。

00:31:54.250 --> 00:31:59.395
嗯，现在假设我们给模型一个法语句子作为输入。

00:31:59.395 --> 00:32:01.555
嗯，因为，呃，

00:32:01.555 --> 00:32:03.850
嵌入看起来很相似，

00:32:03.850 --> 00:32:06.190
既然编码器是一样的，嗯，

00:32:06.190 --> 00:32:09.760
很可能模型的表示

00:32:09.760 --> 00:32:11.950
这个法语句子应该是

00:32:11.950 --> 00:32:15.520
类似于英语句子的表达。

00:32:15.520 --> 00:32:19.870
当这个表示被传递到解码器时，

00:32:19.870 --> 00:32:24.980
我们希望能得到和以前一样的产量。

00:32:25.200 --> 00:32:28.495
嗯，嗯，所以这里有点像一个起点。

00:32:28.495 --> 00:32:30.865
我们-我们希望我们的模型，嗯，

00:32:30.865 --> 00:32:33.430
已经具备一定的翻译能力。

00:32:33.430 --> 00:32:37.840
[噪音]嗯，另一种思考方式是

00:32:37.840 --> 00:32:42.355
我们真正希望我们的模型能够编码一个句子，

00:32:42.355 --> 00:32:44.335
使代表，

00:32:44.335 --> 00:32:47.410
嗯，是一种通用的中间语。

00:32:47.410 --> 00:32:49.885
一个宇宙，嗯，呃，

00:32:49.885 --> 00:32:53.680
对那个句子的普遍表达

00:32:53.680 --> 00:32:56.245
呃，这不是语言的特殊性。

00:32:56.245 --> 00:32:59.785
所以-这里有一张图片，试图得到这个。

00:32:59.785 --> 00:33:03.160
所以我们的自动编码器，嗯，还有我们的，嗯，

00:33:03.160 --> 00:33:05.290
在我们后面的翻译示例中，

00:33:05.290 --> 00:33:07.210
嗯，这里，目标序列是一样的。

00:33:07.210 --> 00:33:10.090
[噪音]嗯，那本质上是指

00:33:10.090 --> 00:33:14.200
英语句子和法语句子的载体，

00:33:14.200 --> 00:33:17.410
嗯，要接受相同的训练吗，嗯，对吗？

00:33:17.410 --> 00:33:19.645
因为如果他们不同，我们的，呃，

00:33:19.645 --> 00:33:21.520
解码器将产生不同的，

00:33:21.520 --> 00:33:25.040
呃，这两个例子的输出。

00:33:25.040 --> 00:33:29.640
嗯，这里-这只是另一种直觉，就是我们的模型

00:33:29.640 --> 00:33:31.290
在这里学习是一种

00:33:31.290 --> 00:33:33.870
在矢量中编码一个句子的信息，

00:33:33.870 --> 00:33:37.100
嗯，但在某种程度上，这是语言不可知论。

00:33:37.100 --> 00:33:39.460
嗯，还有什么问题吗？

00:33:39.460 --> 00:33:42.740
嗯，无人监督的机器翻译？

00:33:44.220 --> 00:33:50.350
可以。嗯，继续这个方法的结果，嗯，

00:33:50.350 --> 00:33:53.020
这里，水平线是，

00:33:53.020 --> 00:33:56.860
嗯，一个无监督机器翻译模型的结果。

00:33:56.860 --> 00:34:00.775
嗯，上面的行是用于受监控机器翻译模型的，

00:34:00.775 --> 00:34:03.900
嗯，随着我们提供越来越多的数据。

00:34:03.900 --> 00:34:06.300
正确的？不出所料，嗯，

00:34:06.300 --> 00:34:09.405
考虑到大量的监控数据，嗯，

00:34:09.405 --> 00:34:11.790
监控机器翻译模型

00:34:11.790 --> 00:34:15.725
比无监督的机器翻译模型工作得更好。

00:34:15.725 --> 00:34:19.285
嗯，但是，嗯，无监督机器翻译模型，

00:34:19.285 --> 00:34:21.310
实际上还是很不错的。

00:34:21.310 --> 00:34:26.995
嗯，如果你看到大约10000到100000个训练例子，

00:34:26.995 --> 00:34:30.565
嗯，它实际上比有监督的翻译效果好或更好，

00:34:30.565 --> 00:34:33.580
我认为这是一个非常有希望的结果，

00:34:33.580 --> 00:34:36.640
呃，因为如果你想到，嗯，

00:34:36.640 --> 00:34:39.550
低资源设置，没有太多标记的示例，嗯，

00:34:39.550 --> 00:34:42.280
你能表现得这么好，突然变得非常好，

00:34:42.280 --> 00:34:46.550
嗯，甚至不需要使用训练设备。

00:34:48.690 --> 00:34:51.745
嗯，另一件有趣的事情是，

00:34:51.745 --> 00:34:55.195
一个无监督的机器翻译模型是属性转移。

00:34:55.195 --> 00:34:58.855
嗯，所以基本上，你可以，嗯，拿，呃，

00:34:58.855 --> 00:35:00.520
文本集合，

00:35:00.520 --> 00:35:03.190
呃，根据你想要的属性来划分。

00:35:03.190 --> 00:35:04.900
例如，你可以在Twitter上，

00:35:04.900 --> 00:35:08.650
查看hashtags来决定哪些tweet是烦人的，哪些tweet是放松的，

00:35:08.650 --> 00:35:11.080
然后你可以把这两个语料库当作

00:35:11.080 --> 00:35:13.614
文字就像是两种不同的语言，

00:35:13.614 --> 00:35:16.510
你可以训练一个无监督的机器翻译模型，

00:35:16.510 --> 00:35:19.165
呃，从一个转换到另一个。

00:35:19.165 --> 00:35:22.495
嗯，你可以看到这些例子，嗯，

00:35:22.495 --> 00:35:26.650
这个模型实际上很好地将句子的变化降到最低，

00:35:26.650 --> 00:35:29.680
保留了很多句子的原始语义，

00:35:29.680 --> 00:35:33.620
嗯，这样目标属性就改变了。

00:35:36.540 --> 00:35:41.290
嗯，我还想对这个想法泼点冷水。

00:35:41.290 --> 00:35:44.410
所以我认为这真的很令人兴奋而且几乎是

00:35:44.410 --> 00:35:47.650
令人吃惊的是，您可以在没有标记数据的情况下进行此翻译。

00:35:47.650 --> 00:35:49.600
嗯，当然，对。

00:35:49.600 --> 00:35:54.520
真的很难想象有人给我一大堆意大利语书然后说，“好吧。

00:35:54.520 --> 00:35:56.410
我们是意大利人，“嗯，没有，你知道，

00:35:56.410 --> 00:35:59.755
教你如何具体翻译。

00:35:59.755 --> 00:36:03.955
嗯，但是，嗯，即使这些方法显示出希望，

00:36:03.955 --> 00:36:08.095
嗯，他们大多对那些关系密切的语言表现出了希望。

00:36:08.095 --> 00:36:09.775
所以以前的结果，

00:36:09.775 --> 00:36:11.065
这些都是，嗯，

00:36:11.065 --> 00:36:13.750
英语到法语或英语到德语的组合，

00:36:13.750 --> 00:36:16.270
嗯，等等，这些语言非常相似。

00:36:16.270 --> 00:36:18.280
[噪音]嗯，如果你看，呃，

00:36:18.280 --> 00:36:20.320
一对不同的语言，比如说英语和土耳其语，

00:36:20.320 --> 00:36:24.685
这两种语言的语言学是完全不同的，呃，

00:36:24.685 --> 00:36:27.610
这些方法在某种程度上仍然有效，嗯，

00:36:27.610 --> 00:36:30.910
所以他们得到了五个布鲁分数，比如，

00:36:30.910 --> 00:36:33.190
但它们的效果不太好，

00:36:33.190 --> 00:36:35.890
嗯，就像他们在其他地方一样，对吧？

00:36:35.890 --> 00:36:40.240
因此，纯粹的监督学习还有很大的差距。嗯，对吧？

00:36:40.240 --> 00:36:41.350
所以我们可能不是，你知道，

00:36:41.350 --> 00:36:45.040
在外星人可能坠落的这个阶段，没问题，

00:36:45.040 --> 00:36:48.220
让我们使用我们的无监督机器翻译系统，嗯，

00:36:48.220 --> 00:36:52.399
但我仍然认为这是非常令人兴奋的进展。嗯，是的。有问题吗？

00:36:52.399 --> 00:36:55.270
嗯，你说的是

00:36:55.270 --> 00:36:58.630
一种语言可能需要它来叠加更糟的内容，对吗？

00:36:58.630 --> 00:37:01.510
因为我最初的想法是如果你举个例子，

00:37:01.510 --> 00:37:04.810
就像拉丁语，没有一个词来表示，

00:37:04.810 --> 00:37:11.440
现代的汽车分类，我认为会做得更差。但是如果-但是，呃，基本上，

00:37:11.440 --> 00:37:15.280
我要问的是，你认为英语地图更适合拉丁语吗？

00:37:15.280 --> 00:37:20.380
因为他们两个都有关系，更糟的是土耳其语，还是相反？

00:37:20.380 --> 00:37:25.645
嗯，我希望英语能更好地映射到拉丁语。

00:37:25.645 --> 00:37:28.930
我认为问题的一部分是，

00:37:28.930 --> 00:37:33.460
我认为翻译的困难并不在字面上。

00:37:33.460 --> 00:37:35.410
所以我的意思是这当然是一个词存在的问题

00:37:35.410 --> 00:37:37.495
一种语言不存在于另一种语言中，

00:37:37.495 --> 00:37:38.740
嗯，但我想事实上，

00:37:38.740 --> 00:37:43.195
语言之间更实质性的差异在于相似语法的层次，

00:37:43.195 --> 00:37:45.820
嗯，嗯，或者你知道，语义学，对吧？

00:37:45.820 --> 00:37:47.410
如何表达想法。

00:37:47.410 --> 00:37:53.515
嗯，所以-我想我-我希望意大利语-拉丁语有，你知道，

00:37:53.515 --> 00:37:56.020
与英语的语法相对相似，

00:37:56.020 --> 00:37:57.580
嗯，和土耳其语相比，

00:37:57.580 --> 00:37:59.860
我想那可能是更大的障碍

00:37:59.860 --> 00:38:03.260
对于无监督的机器翻译模型。

00:38:07.190 --> 00:38:10.260
嗯，我会很快进入

00:38:10.260 --> 00:38:14.910
这是最近的一篇研究论文，主要是以伯特为例，

00:38:14.910 --> 00:38:17.265
你知道的，嗯，对吗？

00:38:17.265 --> 00:38:20.190
对.可以。使之成为跨语言的。

00:38:20.190 --> 00:38:23.730
嗯，那么，嗯，这是伯特的常客，对吧？

00:38:23.730 --> 00:38:26.295
我们有一系列的英语句子。

00:38:26.295 --> 00:38:28.215
我们要屏蔽掉一些单词。

00:38:28.215 --> 00:38:31.500
我们要问伯特，哪一个是我们的变压器模型，嗯，

00:38:31.500 --> 00:38:36.675
基本上填补空白，预测掉的单词是什么。

00:38:36.675 --> 00:38:42.990
嗯，实际上谷歌已经做了一件事，那就是训练多语言伯特。

00:38:42.990 --> 00:38:46.835
所以他们所做的基本上是串联，嗯，

00:38:46.835 --> 00:38:51.560
一大堆不同语言的语料库，然后训练一个模型。

00:38:51.560 --> 00:38:54.785
使用这个蒙面的lm目标，嗯，

00:38:54.785 --> 00:38:56.315
在所有的文本上。

00:38:56.315 --> 00:38:58.300
这是一个公开发布的模型。

00:38:58.300 --> 00:39:03.495
嗯，最近这种新的扩展，呃，

00:39:03.495 --> 00:39:06.300
Facebook提出的建议是将

00:39:06.300 --> 00:39:10.965
这掩盖了我的培训目标，嗯，翻译。

00:39:10.965 --> 00:39:17.130
所以在这种情况下，他们有时会给这个模型A，

00:39:17.130 --> 00:39:21.060
一个英语序列和一个法语序列。

00:39:21.060 --> 00:39:24.300
嗯，把一些话说出来，就像以前一样，

00:39:24.300 --> 00:39:26.130
让模特来填。

00:39:26.130 --> 00:39:28.635
这里的动机是，嗯，

00:39:28.635 --> 00:39:31.080
这将更好地导致模型

00:39:31.080 --> 00:39:33.525
了解这两种语言之间的关系。

00:39:33.525 --> 00:39:37.950
因为如果你想找一个被删掉的英文单词，

00:39:37.950 --> 00:39:40.500
嗯，如果你有翻译，最好的办法是看

00:39:40.500 --> 00:39:43.005
在法国那边，试着找到那个词。

00:39:43.005 --> 00:39:45.075
希望那个也没被扔下。

00:39:45.075 --> 00:39:48.525
然后你可以UM，更容易填空。

00:39:48.525 --> 00:39:52.575
呃，这实际上导致了，

00:39:52.575 --> 00:39:55.860
无监督机器翻译的实质性改进。

00:39:55.860 --> 00:39:59.670
就像Bert在NLP中用于其他任务一样，

00:39:59.670 --> 00:40:02.010
他们基本上采用跨语言伯特。

00:40:02.010 --> 00:40:03.930
它们将其用作

00:40:03.930 --> 00:40:07.410
一个无监督的机器翻译系统，他们得到，你知道，

00:40:07.410 --> 00:40:10.425
在10个布鲁点上获得了巨大的收益嗯，

00:40:10.425 --> 00:40:12.690
使得

00:40:12.690 --> 00:40:16.485
无监督的机器翻译和当前监督的技术状态，

00:40:16.485 --> 00:40:18.420
嗯，要小得多。

00:40:18.420 --> 00:40:23.190
嗯，所以这是一个很新的想法，但我认为它也显示了承诺

00:40:23.190 --> 00:40:28.320
通过使用未标记的数据真正提高翻译质量。

00:40:28.320 --> 00:40:30.945
嗯，虽然我想是的，但我想在这件事上，伯特

00:40:30.945 --> 00:40:33.930
他们也在使用标记的翻译数据。

00:40:33.930 --> 00:40:37.270
有问题吗？

00:40:37.820 --> 00:40:46.350
可以。嗯，这就是我要说的关于使用未标记的数据进行翻译的全部内容。

00:40:46.350 --> 00:40:48.750
下一部分是关于，嗯，

00:40:48.750 --> 00:40:54.720
如果我们真的扩大这些无监督的语言模型会发生什么。

00:40:54.720 --> 00:40:59.865
嗯，特别是我要讲的GPT-2是OpenAI的一个新模型。

00:40:59.865 --> 00:41:02.265
这实际上是一个巨大的语言模型

00:41:02.265 --> 00:41:05.685
我认为它有一些有趣的含义。

00:41:05.685 --> 00:41:15.060
首先，这里是一些不同的NLP模型的大小，

00:41:15.060 --> 00:41:18.165
嗯，你知道，也许几年前，

00:41:18.165 --> 00:41:19.230
标准的那种

00:41:19.230 --> 00:41:24.135
LSTM中型模型的参数约为1000万。

00:41:24.135 --> 00:41:30.660
其中10-其中一个参数只是一个权重，比如在神经网络中，

00:41:30.660 --> 00:41:33.090
埃尔莫和呃，GPT。

00:41:33.090 --> 00:41:35.520
所以他们之前的原始Openai文件

00:41:35.520 --> 00:41:38.820
这个GPT-2比那个大10倍。

00:41:38.820 --> 00:41:43.120
嗯，GPT-2大约是另一个数量级。

00:41:44.120 --> 00:41:48.825
嗯，这里有一个有趣的比较点是，

00:41:48.825 --> 00:41:51.735
GPT-2是15亿个参数，

00:41:51.735 --> 00:41:55.635
事实上，它的参数比蜜蜂大脑中的突触还要多。

00:41:55.635 --> 00:41:58.440
嗯，听起来不错，对吧？

00:41:58.440 --> 00:42:01.350
你知道蜜蜂不是最聪明的

00:42:01.350 --> 00:42:05.325
但它们仍然可以四处飞，找到花蜜或其他什么。

00:42:05.325 --> 00:42:08.760
嗯，但是是的。当然，这不是一个苹果对苹果的比较，对吧？

00:42:08.760 --> 00:42:11.970
所以神经网络中的突触和重量是完全不同的。

00:42:11.970 --> 00:42:14.490
但我认为这是一个有趣的里程碑

00:42:14.490 --> 00:42:16.815
就车型尺寸来说，嗯，

00:42:16.815 --> 00:42:18.150
这已经超越了。

00:42:18.150 --> 00:42:26.835
[噪音]嗯，这里要指出的一点是，

00:42:26.835 --> 00:42:32.130
这种不断扩大的深度学习实际上是一种普遍趋势，呃，

00:42:32.130 --> 00:42:34.845
在所有的机器学习中，超越了NLP。

00:42:34.845 --> 00:42:41.760
所以这个图显示了x轴上的时间，y轴是对数刻度的。

00:42:41.760 --> 00:42:45.255
用于训练此模型的petaflops数量。

00:42:45.255 --> 00:42:50.010
嗯，这意味着至少目前的趋势是

00:42:50.010 --> 00:42:53.130
计算能力指数增长

00:42:53.130 --> 00:42:55.735
我们在扔我们的机器学习模型。

00:42:55.735 --> 00:42:57.920
我想有点不清楚，你知道，

00:42:57.920 --> 00:43:00.695
指数增长会继续吗，但当然，嗯，

00:43:00.695 --> 00:43:03.560
我们的模型规模迅速增长。

00:43:03.560 --> 00:43:06.200
它会带来一些非常惊人的结果，对吧？

00:43:06.200 --> 00:43:09.445
所以这不是语言的结果，而是视觉的结果。

00:43:09.445 --> 00:43:13.155
嗯，这是一个生成性的对抗性网络

00:43:13.155 --> 00:43:16.920
这是在大量数据的基础上进行的培训，而且是在非常大的范围内进行的培训。

00:43:16.920 --> 00:43:22.710
所以说它是一个介于埃尔莫和伯特之间的大模型。

00:43:22.710 --> 00:43:27.510
嗯，这些照片实际上是模特的作品。

00:43:27.510 --> 00:43:28.740
所以这些不是真照片。

00:43:28.740 --> 00:43:31.515
这些都是模型在稀薄空气中产生的幻觉。

00:43:31.515 --> 00:43:34.770
至少在我看来，这些照片基本上是真实的。

00:43:34.770 --> 00:43:38.010
还有一个网站，嗯，看它很有趣。

00:43:38.010 --> 00:43:39.915
如果你不感兴趣-如果你感兴趣，

00:43:39.915 --> 00:43:42.195
此人不在texist.com上。

00:43:42.195 --> 00:43:43.950
所以如果你去那里，你会看到

00:43:43.950 --> 00:43:47.430
一张很有说服力的照片，但不是真的照片。

00:43:47.430 --> 00:43:51.400
它又像是由甘产生的幻觉。

00:43:51.440 --> 00:43:55.725
我们也看到了用于图像识别的巨大模型。

00:43:55.725 --> 00:43:58.110
所以这是谷歌最近的工作，他们在那里训练

00:43:58.110 --> 00:44:02.010
一个有50亿参数的图像网络模型。

00:44:02.010 --> 00:44:06.450
所以这比伯特大，但不如GPT-2大。

00:44:06.450 --> 00:44:09.420
嗯，这张图显示

00:44:09.420 --> 00:44:14.760
在X轴上记录参数的比例数量，然后在ImageNet上记录精度

00:44:14.760 --> 00:44:20.520
在Y轴上，更大的模型表现得更好，这不足为奇。

00:44:20.520 --> 00:44:24.000
事实上这里有一个相当一致的趋势，呃，

00:44:24.000 --> 00:44:28.240
精度随着对数、模型尺寸的增大而增大。

00:44:31.010 --> 00:44:35.100
嗯，我想更详细一点，怎么样

00:44:35.100 --> 00:44:39.060
可能我们可以在如此大的程度上扩大模型和培训模型。

00:44:39.060 --> 00:44:41.190
一个答案就是更好的硬件。

00:44:41.190 --> 00:44:42.675
尤其是，嗯，

00:44:42.675 --> 00:44:44.160
越来越多的人，呃，

00:44:44.160 --> 00:44:48.165
专门为深度学习开发硬件的公司数量。

00:44:48.165 --> 00:44:50.520
所以这些更受约束

00:44:50.520 --> 00:44:53.190
他们可以比GPU做的操作，

00:44:53.190 --> 00:44:55.950
嗯，但他们做这些手术的速度更快。

00:44:55.950 --> 00:44:59.610
所以谷歌的张量处理单元就是一个例子。

00:44:59.610 --> 00:45:03.180
实际上还有很多其他公司在研究这个想法。

00:45:03.180 --> 00:45:06.930
嗯，扩大模型的另一种方法是利用

00:45:06.930 --> 00:45:11.835
并行性，有两种类型的并行性，我想简单地讨论一下。

00:45:11.835 --> 00:45:13.980
一个是数据并行性。

00:45:13.980 --> 00:45:16.785
在这种情况下，你们每个人，

00:45:16.785 --> 00:45:19.380
假设GPU，将有一个模型的副本。

00:45:19.380 --> 00:45:21.480
你基本上是分开的

00:45:21.480 --> 00:45:25.350
你在这些不同型号上训练的小批量。

00:45:25.350 --> 00:45:27.165
所以如果你有，我们假设，

00:45:27.165 --> 00:45:30.945
16 gpu，每批32个。

00:45:30.945 --> 00:45:35.670
你可以把这16个，呃，呃，

00:45:35.670 --> 00:45:42.540
如果你在这16个GPU上做一个后支撑，你最终得到的实际批量大小是512。

00:45:42.540 --> 00:45:44.700
所以这可以让你更快地训练模型。

00:45:44.700 --> 00:45:50.340
另一种日益重要的并行性是模型并行性。

00:45:50.340 --> 00:45:54.510
嗯，所以最终模特们变得这么大以至于他们

00:45:54.510 --> 00:45:59.070
甚至不能适应一个GPU，他们甚至不能做一个批量大小的一个。

00:45:59.070 --> 00:46:00.660
嗯，在这种情况下，

00:46:00.660 --> 00:46:02.985
你实际上需要把模型分割开来

00:46:02.985 --> 00:46:06.075
多台计算机-多个计算单元。

00:46:06.075 --> 00:46:10.485
嗯，这就是模特们所做的，

00:46:10.485 --> 00:46:12.720
比如说GPT-2。

00:46:12.720 --> 00:46:15.540
有一些新的框架，比如Mesh TensorFlow，嗯，

00:46:15.540 --> 00:46:21.430
这基本上是为了使这种模型并行性更容易。

00:46:23.990 --> 00:46:27.390
嗯，好吧。所以在GPT-2上，嗯，

00:46:27.390 --> 00:46:31.560
我知道你已经在语境中看到了这一点，呃，

00:46:31.560 --> 00:46:36.540
嗯，嵌入，嗯，演讲，但我会在这里更深入地讲。

00:46:36.540 --> 00:46:41.265
[噪音]所以本质上，它是一个非常大的变形金刚语言模型。

00:46:41.265 --> 00:46:45.165
嗯，所以这里没有什么真正意义上的小说

00:46:45.165 --> 00:46:49.305
新的训练算法，或者就um而言，

00:46:49.305 --> 00:46:51.645
损失函数之类的。

00:46:51.645 --> 00:46:53.340
嗯，让它与众不同的是

00:46:53.340 --> 00:46:56.070
之前的工作是它真的非常大。

00:46:56.070 --> 00:46:59.970
嗯，它的培训内容也相应地相当多。

00:46:59.970 --> 00:47:04.800
所以它的容量是40千兆字节，大约是以前的10倍。

00:47:04.800 --> 00:47:07.215
语言模型已经过训练。

00:47:07.215 --> 00:47:11.070
嗯，当你有这么大的数据集时，

00:47:11.070 --> 00:47:14.325
嗯，获得这么多文本的唯一方法就是上网。

00:47:14.325 --> 00:47:18.840
嗯，所以Openai在开发时投入了很多精力

00:47:18.840 --> 00:47:23.570
这个网络是为了确保文本的高质量。

00:47:23.570 --> 00:47:26.180
嗯，他们以一种有趣的方式做到了。

00:47:26.180 --> 00:47:28.970
他们在Reddit网站上看到人们

00:47:28.970 --> 00:47:30.140
可以在链接上投票。

00:47:30.140 --> 00:47:31.640
然后他们说如果

00:47:31.640 --> 00:47:35.090
一个链接有很多选票，那么它可能是一个不错的链接。

00:47:35.090 --> 00:47:36.830
可能有呃，你知道，

00:47:36.830 --> 00:47:39.750
有合理的文字供模特学习。

00:47:40.610 --> 00:47:43.080
嗯，好吧，如果有的话

00:47:43.080 --> 00:47:45.600
这种超大型的语言模式

00:47:45.600 --> 00:47:49.515
GPT-2关于你能用它做什么的问题，

00:47:49.515 --> 00:47:53.415
嗯，很明显，如果你有一个语言模型，你可以用它来做语言建模。

00:47:53.415 --> 00:47:56.790
但是有一件有趣的事是你

00:47:56.790 --> 00:48:00.525
可以在ER上运行此语言模型，

00:48:00.525 --> 00:48:03.435
现有基准，嗯，

00:48:03.435 --> 00:48:05.250
对于语言建模，嗯，

00:48:05.250 --> 00:48:08.520
即使在这些基准上，它也会产生最新的困惑。

00:48:08.520 --> 00:48:11.700
尽管它从未看到这些基准的培训数据，对吗？

00:48:11.700 --> 00:48:16.770
所以，通常情况下，如果你想说评估你的语言模型在宾州树库。

00:48:16.770 --> 00:48:21.510
你先是在宾夕法尼亚州的Treebank上训练，然后再评估一下这个保留设置。

00:48:21.510 --> 00:48:23.790
呃，在这种情况下，呃，

00:48:23.790 --> 00:48:28.515
一个GPT-2仅仅因为看到了如此多的文本和如此大的模型，

00:48:28.515 --> 00:48:31.095
比其他人都好，

00:48:31.095 --> 00:48:34.540
即使没有看到这些数据，先前的方法也能奏效。

00:48:34.580 --> 00:48:39.430
嗯，在一堆不同的语言建模基准上。

00:48:40.800 --> 00:48:46.315
嗯，但是还有很多其他有趣的实验

00:48:46.315 --> 00:48:51.700
用这种语言建模，这些都是基于零镜头学习。

00:48:51.700 --> 00:48:57.250
所以零镜头学习只是意味着尝试去做一个任务而不去训练它。

00:48:57.250 --> 00:49:00.445
而且，呃，你可以用语言模型来做这个

00:49:00.445 --> 00:49:03.460
是通过设计一个提示

00:49:03.460 --> 00:49:06.880
语言模型，然后让它从那里生成

00:49:06.880 --> 00:49:11.065
希望它能产生一些与您试图解决的任务相关的东西。

00:49:11.065 --> 00:49:13.225
例如，对于阅读理解，

00:49:13.225 --> 00:49:16.090
你能做的就是把上下文段落，

00:49:16.090 --> 00:49:20.080
把问题连起来然后加上

00:49:20.080 --> 00:49:21.430
结肠是一种方式，

00:49:21.430 --> 00:49:22.705
我想，告诉模特，

00:49:22.705 --> 00:49:25.210
“好吧，你应该回答这个问题。”

00:49:25.210 --> 00:49:27.790
然后让它生成文本，

00:49:27.790 --> 00:49:30.940
也许它会产生一些实际的答案，

00:49:30.940 --> 00:49:32.365
嗯，问题是，

00:49:32.365 --> 00:49:34.060
关注环境。

00:49:34.060 --> 00:49:37.390
[噪音]嗯，同样地，为了总结，

00:49:37.390 --> 00:49:41.740
然后您可以得到本文tl；dr，也许模型将生成摘要。

00:49:41.740 --> 00:49:43.795
嗯，你甚至可以做翻译，

00:49:43.795 --> 00:49:45.655
你给模特的地方，

00:49:45.655 --> 00:49:49.720
嗯，一些前-一份已知的英法翻译清单，所以你，有点，

00:49:49.720 --> 00:49:53.770
最好告诉它应该做翻译，然后你给

00:49:53.770 --> 00:49:58.120
它的源序列等于空白，只运行它，

00:49:58.120 --> 00:49:59.920
嗯，也许会产生，

00:49:59.920 --> 00:50:02.690
嗯，目标语言中的序列。

00:50:03.300 --> 00:50:06.895
嗯，好吧。所以结果是这样的。

00:50:06.895 --> 00:50:09.100
嗯，所有这些，

00:50:09.100 --> 00:50:11.545
呃，X轴是，

00:50:11.545 --> 00:50:16.210
是对数比例模型尺寸，Y轴是精确的，嗯，

00:50:16.210 --> 00:50:18.715
虚线基本上对应，

00:50:18.715 --> 00:50:22.090
嗯，这些任务的现有工作。

00:50:22.090 --> 00:50:26.290
嗯，所以在这些任务中，嗯，

00:50:26.290 --> 00:50:31.765
GPT-2远远低于现有系统，

00:50:31.765 --> 00:50:33.625
嗯，但当然有很大的区别，对吧？

00:50:33.625 --> 00:50:37.195
现有系统经过专门培训，

00:50:37.195 --> 00:50:39.775
嗯，不管他们在做什么工作，

00:50:39.775 --> 00:50:42.520
其中gpt-2是um，

00:50:42.520 --> 00:50:46.540
只有接受过语言建模培训，并且在学习语言建模时，

00:50:46.540 --> 00:50:48.865
这有点像是在处理其他任务。

00:50:48.865 --> 00:50:50.785
嗯，没错。例如，嗯，

00:50:50.785 --> 00:50:54.385
它有，呃，从英语到法语的机器翻译，嗯，

00:50:54.385 --> 00:50:56.875
不如，呃，

00:50:56.875 --> 00:51:00.400
标准的无监督机器翻译就是那些，

00:51:00.400 --> 00:51:02.920
虚线，嗯，但它仍然，

00:51:02.920 --> 00:51:04.300
它仍然很好。

00:51:04.300 --> 00:51:06.370
还有一点，

00:51:06.370 --> 00:51:07.810
有趣的是趋势线，对吧，

00:51:07.810 --> 00:51:09.520
几乎所有这些任务。

00:51:09.520 --> 00:51:11.530
嗯，表演开始了，

00:51:11.530 --> 00:51:13.600
随着模型尺寸的增加，效果会更好。

00:51:13.600 --> 00:51:18.535
[噪音]嗯，我觉得特别有趣，

00:51:18.535 --> 00:51:21.580
呃，其中一个任务是机器翻译，对吧？

00:51:21.580 --> 00:51:23.290
所以问题是，它是如何做到的

00:51:23.290 --> 00:51:26.440
机器翻译当我们把它当作一堆

00:51:26.440 --> 00:51:28.540
网页和那些网页几乎都在

00:51:28.540 --> 00:51:31.810
英语，但不知怎的，它神奇地变了起来，

00:51:31.810 --> 00:51:33.340
一点机器翻译，对吧。

00:51:33.340 --> 00:51:35.395
所以这不是一个很好的模型，但它仍然可以，

00:51:35.395 --> 00:51:38.260
嗯，你知道，在某些情况下做一件体面的工作。

00:51:38.260 --> 00:51:40.510
嗯，答案是，

00:51:40.510 --> 00:51:43.810
如果你看看这个庞大的英语语料库，

00:51:43.810 --> 00:51:47.050
偶尔，呃，在语料库内，

00:51:47.050 --> 00:51:48.880
你看到翻译的例子了吧？

00:51:48.880 --> 00:51:50.290
你看，嗯，

00:51:50.290 --> 00:51:52.810
法语成语及其翻译或

00:51:52.810 --> 00:51:56.035
引自法语的人，然后用英语翻译。

00:51:56.035 --> 00:51:57.400
而且，嗯，有点，

00:51:57.400 --> 00:52:00.700
令人惊讶的是，我认为这个大模型，嗯，

00:52:00.700 --> 00:52:05.380
看到这些例子，它实际上开始学习如何生成法语，

00:52:05.380 --> 00:52:07.030
嗯，尽管那不是真的，

00:52:07.030 --> 00:52:09.980
某种程度上，是培训的一部分。

00:52:11.970 --> 00:52:14.560
嗯，另一个有趣的，嗯，

00:52:14.560 --> 00:52:18.700
更深入一点的研究是它回答问题的能力。

00:52:18.700 --> 00:52:24.040
所以，一个简单的回答问题的基线可以得到1%的准确率，

00:52:24.040 --> 00:52:27.295
GPT-2的精确度仅为4%。

00:52:27.295 --> 00:52:28.840
所以这不是，就像，你知道，

00:52:28.840 --> 00:52:32.440
超级神奇的解决了问题回答，嗯，但是，嗯，

00:52:32.440 --> 00:52:34.420
这仍然很有趣，

00:52:34.420 --> 00:52:37.435
如果你看答案模型最有信心，

00:52:37.435 --> 00:52:39.010
你可以看到它有点

00:52:39.010 --> 00:52:41.320
已经了解了一些关于世界的事实，对吧。

00:52:41.320 --> 00:52:45.550
据了解，查尔斯·达尔文写了物种起源。

00:52:45.550 --> 00:52:50.740
嗯，通常在NLP的历史上，如果你想得到，有点，

00:52:50.740 --> 00:52:52.765
将世界知识融入到一个NLP系统中，

00:52:52.765 --> 00:52:55.435
你需要一个大的事实数据库。

00:52:55.435 --> 00:52:57.340
即使这仍然是，

00:52:57.340 --> 00:52:59.500
有点，很早就开始了，嗯，

00:52:59.500 --> 00:53:04.000
4%的准确率和，呃，你知道，

00:53:04.000 --> 00:53:05.875
70%左右，呃，

00:53:05.875 --> 00:53:09.550
最先进的开放领域问答系统可以做到，

00:53:09.550 --> 00:53:12.010
嗯，它，它，嗯，

00:53:12.010 --> 00:53:14.200
它仍然可以，呃，

00:53:14.200 --> 00:53:17.740
仅仅通过阅读大量的文本来获取一些世界知识，嗯，没有，

00:53:17.740 --> 00:53:21.895
有点，明确地将这些知识放入模型中。

00:53:21.895 --> 00:53:26.810
嗯，到目前为止GPT-2还有什么问题吗？

00:53:28.050 --> 00:53:33.865
可以。所以一个有趣的问题是，

00:53:33.865 --> 00:53:36.505
如果我们的模型变得更大会发生什么？

00:53:36.505 --> 00:53:38.305
嗯，我已经完成了，嗯，

00:53:38.305 --> 00:53:42.565
在PowerPoint中画一些线条，看看它们在哪里相遇是非常科学的事情。

00:53:42.565 --> 00:53:44.655
嗯，你可以看到，嗯，

00:53:44.655 --> 00:53:48.429
如果趋势保持在1万亿个参数左右，

00:53:48.429 --> 00:53:52.390
嗯，我们要达到人的阅读理解水平。

00:53:52.390 --> 00:53:55.480
嗯，如果这是真的，那真的会让人吃惊。

00:53:55.480 --> 00:54:00.505
我真的希望1万亿参数模型能在

00:54:00.505 --> 00:54:02.155
我不知道，十年左右，

00:54:02.155 --> 00:54:04.240
嗯，但当然，

00:54:04.240 --> 00:54:05.665
是的，趋势还不清楚。

00:54:05.665 --> 00:54:07.630
例如，如果你看总结，

00:54:07.630 --> 00:54:09.040
好像表演已经开始了，

00:54:09.040 --> 00:54:11.005
呃，呃，结束了。

00:54:11.005 --> 00:54:15.760
嗯，所以我认为这将是一件非常有趣的事情

00:54:15.760 --> 00:54:17.980
展望NLP的未来，嗯，

00:54:17.980 --> 00:54:20.710
是比例的变化，

00:54:20.710 --> 00:54:23.570
嗯，接近NLP的方式。

00:54:24.120 --> 00:54:29.755
关于gpt-2的另一个有趣的事情是它的反应

00:54:29.755 --> 00:54:32.125
媒体和其他研究人员。

00:54:32.125 --> 00:54:35.455
嗯，真正的原因是

00:54:35.455 --> 00:54:39.295
关于这一点，很多争议都来自于Openai的声明。

00:54:39.295 --> 00:54:43.000
他们说，“我们不会发布我们的全语言模型，

00:54:43.000 --> 00:54:44.590
嗯，因为太危险了，

00:54:44.590 --> 00:54:46.015
你知道，我们的语言模式太好了。

00:54:46.015 --> 00:54:51.115
嗯，所以媒体真的很喜欢这个，

00:54:51.115 --> 00:54:52.330
你知道，这么说，

00:54:52.330 --> 00:54:55.135
嗯，机器学习会破坏互联网。

00:54:55.135 --> 00:55:00.580
嗯，我们的研究人员也有一些非常有趣的反应，对吧。

00:55:00.580 --> 00:55:02.020
嗯，有一些，

00:55:02.020 --> 00:55:04.195
有点，舌尖对这里的反应，对吧。

00:55:04.195 --> 00:55:05.755
你知道，我是在mnist上训练这个模特的。

00:55:05.755 --> 00:55:07.915
释放它对我来说太危险了吗？

00:55:07.915 --> 00:55:11.530
嗯，同样的，我们也做了非常好的工作

00:55:11.530 --> 00:55:15.715
但我们不能释放它太危险了，所以你只能相信我们。

00:55:15.715 --> 00:55:18.970
看看更多，有点，有道理，嗯，

00:55:18.970 --> 00:55:20.665
关于这个问题的辩论，

00:55:20.665 --> 00:55:22.885
你仍然可以看到文章，

00:55:22.885 --> 00:55:24.610
嗯，争论双方。

00:55:24.610 --> 00:55:26.469
这是两篇AR文章，

00:55:26.469 --> 00:55:29.545
从梯度来看，

00:55:29.545 --> 00:55:31.690
机器学习时事通讯，嗯，

00:55:31.690 --> 00:55:35.875
他们在争论这个问题的完全相反的方面，

00:55:35.875 --> 00:55:38.510
嗯，是不是应该放出来。

00:55:40.770 --> 00:55:47.120
所以我想我可以简单地回顾一下一些赞成或反对的论点。

00:55:47.130 --> 00:55:50.185
关于这件事有很多争论，我不想

00:55:50.185 --> 00:55:53.480
深入讨论一个有争议的问题，

00:55:54.150 --> 00:55:56.710
嗯，但这里有一长串，

00:55:56.710 --> 00:55:58.570
有点，人们说过的，对吧。

00:55:58.570 --> 00:56:01.450
所以，嗯，这就是为什么你应该释放。

00:56:01.450 --> 00:56:03.280
一个抱怨是，

00:56:03.280 --> 00:56:05.065
这个模型真的很特别吗？

00:56:05.065 --> 00:56:06.595
这里没有什么新鲜事。

00:56:06.595 --> 00:56:09.640
比以前的型号大10倍，嗯，

00:56:09.640 --> 00:56:11.860
还有一些观点认为，

00:56:11.860 --> 00:56:14.500
嗯，即使这个还没有发布，你知道，

00:56:14.500 --> 00:56:17.185
五年后，每个人都能训练出这样好的模特，嗯，

00:56:17.185 --> 00:56:22.270
实际上，如果你看图像识别或者看图像和语音数据，

00:56:22.270 --> 00:56:25.780
已经有可能合成高度令人信服的，

00:56:25.780 --> 00:56:28.405
嗯，假象和假话。

00:56:28.405 --> 00:56:34.750
所以有点，是什么让这个东西不同于其他的，嗯，系统。

00:56:34.750 --> 00:56:36.310
说到其他系统，是吗？

00:56:36.310 --> 00:56:38.335
photoshop已经存在很长时间了，

00:56:38.335 --> 00:56:41.950
所以我们已经可以令人信服地伪造图像了，嗯，

00:56:41.950 --> 00:56:44.140
人们刚刚学会了调整和学习

00:56:44.140 --> 00:56:46.645
你不应该总是相信图像中的东西，

00:56:46.645 --> 00:56:47.995
嗯，因为可能是，

00:56:47.995 --> 00:56:50.065
嗯，在某种程度上改变了。

00:56:50.065 --> 00:56:52.450
嗯，另一方面，你可以说，

00:56:52.450 --> 00:56:55.780
“好吧，呃，photoshop存在，但是，嗯，你不能，有点，

00:56:55.780 --> 00:57:00.130
扩大photoshop的规模，开始以这种方式大量生产假内容

00:57:00.130 --> 00:57:04.660
“关于模特，”他们指出，嗯，假新闻的危险，嗯，

00:57:04.660 --> 00:57:08.950
虚假评论，嗯，一般来说，只是铺天盖地，这基本上意味着，

00:57:08.950 --> 00:57:15.370
嗯，创建假用户内容来支持你希望其他人持有的视图。

00:57:15.370 --> 00:57:18.870
嗯，这实际上是已经做过的事情，

00:57:18.870 --> 00:57:21.660
嗯，相当广泛的国家公司和政府。

00:57:21.660 --> 00:57:23.475
有很多证据证明这一点，嗯，

00:57:23.475 --> 00:57:25.500
但他们当然会雇佣员工

00:57:25.500 --> 00:57:27.795
把这些评论都写在新闻文章上，比如说

00:57:27.795 --> 00:57:30.390
我们不想让他们的工作更轻松

00:57:30.390 --> 00:57:33.620
通过生产一台可能做到这一点的机器。

00:57:33.620 --> 00:57:37.330
所以，嗯，我不想站在这里，

00:57:37.330 --> 00:57:39.565
嗯，关于这个还有很多争论。

00:57:39.565 --> 00:57:41.110
我想，你知道，

00:57:41.110 --> 00:57:43.300
主要的，主要的外卖是，

00:57:43.300 --> 00:57:46.959
作为一个关于机器学习和NLP的人的社区，

00:57:46.959 --> 00:57:48.910
对这件事不太了解，对吧？

00:57:48.910 --> 00:57:51.355
我们有点惊讶，嗯，

00:57:51.355 --> 00:57:56.095
Openai的，嗯，这里的决定，嗯，呃，

00:57:56.095 --> 00:57:57.760
也就是说，你知道，

00:57:57.760 --> 00:58:01.120
确实有一些人想知道需要做什么

00:58:01.120 --> 00:58:05.515
完全有责任公开发布。

00:58:05.515 --> 00:58:09.430
我们应该研究什么样的研究问题等等。

00:58:09.430 --> 00:58:11.530
[噪音]是的。

00:58:11.530 --> 00:58:13.795
关于这个有什么问题吗？

00:58:13.795 --> 00:58:16.450
这种反应还是一般的辩论？

00:58:16.450 --> 00:58:20.930
[噪音]好的。

00:58:22.140 --> 00:58:27.610
嗯，我认为这场辩论的结果是，嗯，

00:58:27.610 --> 00:58:29.310
问题是，嗯，

00:58:29.310 --> 00:58:32.580
真的，ML人应该是制造这些东西的人，

00:58:32.580 --> 00:58:38.085
决策还是需要更多跨学科的科学，我们看，嗯，

00:58:38.085 --> 00:58:40.425
计算机安全专家，

00:58:40.425 --> 00:58:42.705
嗯，来自社会科学的人，

00:58:42.705 --> 00:58:46.185
嗯，你知道，那些道德专家，

00:58:46.185 --> 00:58:48.365
嗯，看看这些决定。

00:58:48.365 --> 00:58:54.595
嗯，对。所以GPT-2绝对是一个例子，突然间它看起来像，

00:58:54.595 --> 00:58:58.420
嗯，我们的NLP技术有很多缺陷，对吧。

00:58:58.420 --> 00:59:02.005
它们可能会被恶意使用或造成损害。

00:59:02.005 --> 00:59:05.725
我认为这种趋势只会增加，嗯，

00:59:05.725 --> 00:59:07.165
如果你看，有点，

00:59:07.165 --> 00:59:10.540
人们正在研究的NLP领域，

00:59:10.540 --> 00:59:16.510
越来越多的人致力于NLP的高风险应用，

00:59:16.510 --> 00:59:19.570
嗯，那些经常非常大，嗯，

00:59:19.570 --> 00:59:25.280
后果，尤其是从偏见和公平的角度考虑。

00:59:25.980 --> 00:59:32.420
嗯，那么，让我们来看几个例子，嗯-

00:59:32.690 --> 00:59:35.955
嗯，一个-一些，一些地区，

00:59:35.955 --> 00:59:37.875
发生这种情况的地方是人们所看到的，

00:59:37.875 --> 00:59:40.050
呃，全国人民党来看看司法裁决。

00:59:40.050 --> 00:59:41.895
例如，如果这个人，

00:59:41.895 --> 00:59:43.305
呃，保释还是不保释？

00:59:43.305 --> 00:59:45.210
嗯，对于招聘决定，是吗？

00:59:45.210 --> 00:59:46.680
所以你看别人的简历，

00:59:46.680 --> 00:59:48.000
你在上面运行NLP，

00:59:48.000 --> 00:59:50.775
然后你会自动做出决定，

00:59:50.775 --> 00:59:53.130
嗯，嘘-我们要不要把这份简历扔掉？

00:59:53.130 --> 00:59:56.850
所以做一些，类似的，筛选，嗯，分级测试。

00:59:56.850 --> 00:59:58.650
嗯，如果你接受GRE，嗯，

00:59:58.650 --> 01:00:00.825
你的，你的考试将由一台机器评分。

01:00:00.825 --> 01:00:03.090
嗯，一个人也会看，嗯，

01:00:03.090 --> 01:00:05.295
但是，嗯，你知道的，

01:00:05.295 --> 01:00:09.090
有时是你生命中非常重要的一部分，嗯，当它，

01:00:09.090 --> 01:00:11.085
当测试结果是，嗯，inf-你知道，

01:00:11.085 --> 01:00:14.490
影响你，嗯，进入学校，比如说。

01:00:14.490 --> 01:00:17.265
嗯，所以我认为有-有一些，

01:00:17.265 --> 01:00:20.790
在这种情况下使用机器学习的一些好方面。

01:00:20.790 --> 01:00:24.120
一个是我们可以很快地评估，

01:00:24.120 --> 01:00:26.985
一个机器学习系统和搜索。

01:00:26.985 --> 01:00:28.680
有什么偏见吗？

01:00:28.680 --> 01:00:31.350
只需在一堆数据上运行它并查看它的功能，

01:00:31.350 --> 01:00:34.350
更重要的是，

01:00:34.350 --> 01:00:35.640
嗯，我们可以解决这个问题，

01:00:35.640 --> 01:00:37.080
如果出现问题，对吗？

01:00:37.080 --> 01:00:42.240
所以，嗯，修复一个屏幕恢复的机器学习系统可能更容易，

01:00:42.240 --> 01:00:44.730
你知道，要解决的问题比解决的问题更重要，

01:00:44.730 --> 01:00:48.300
5000个有点性别歧视的高管，对吧？

01:00:48.300 --> 01:00:49.725
所以，这样，

01:00:49.725 --> 01:00:51.180
嗯，有一种，

01:00:51.180 --> 01:00:57.840
在这些高风险的决策中使用机器学习的积极角度。

01:00:57.840 --> 01:01:00.015
嗯，另一方面，嗯，

01:01:00.015 --> 01:01:02.220
大家都知道，

01:01:02.220 --> 01:01:04.770
我知道你有一个关于偏见和公平的讲座，

01:01:04.770 --> 01:01:07.770
机器学习经常反映出数据集中的偏差，

01:01:07.770 --> 01:01:11.025
嗯，它甚至可以放大数据集中的偏差。

01:01:11.025 --> 01:01:12.660
嗯，有点担心，

01:01:12.660 --> 01:01:15.315
有偏算法的反馈回路

01:01:15.315 --> 01:01:18.360
实际上会导致产生更多有偏见的数据，

01:01:18.360 --> 01:01:23.050
嗯，在这种情况下，这些问题只会加剧并恶化。

01:01:23.150 --> 01:01:28.950
嗯，所以对于所有的，呃，高影响力的决定，

01:01:28.950 --> 01:01:30.990
嗯，我，我在幻灯片上列出了，

01:01:30.990 --> 01:01:34.320
有一些例子说明事情出了差错，对吧？

01:01:34.320 --> 01:01:36.690
所以亚马逊有一些人工智能，

01:01:36.690 --> 01:01:39.975
嗯，作为一个招聘工具，结果是性别歧视。

01:01:39.975 --> 01:01:42.255
嗯，嗯，有一些，有点，

01:01:42.255 --> 01:01:44.550
早期使用人工智能的飞行员，嗯，

01:01:44.550 --> 01:01:46.680
在司法系统中，他们也有，

01:01:46.680 --> 01:01:49.710
嗯，在某些情况下，结果很糟糕。

01:01:49.710 --> 01:01:52.920
嗯，如果你看自动的，

01:01:52.920 --> 01:01:54.855
自动论文评分，嗯，

01:01:54.855 --> 01:01:56.430
不是很好，

01:01:56.430 --> 01:01:57.720
你知道，NLP系统，对吧？

01:01:57.720 --> 01:01:59.730
这是一个例子，嗯，

01:01:59.730 --> 01:02:02.355
一篇文章的摘录，嗯，

01:02:02.355 --> 01:02:06.240
GRE测试使用的自动评分系统给出，

01:02:06.240 --> 01:02:08.040
得分很高，嗯，

01:02:08.040 --> 01:02:10.230
但实际上，它只是，某种程度上，一个固体的，

01:02:10.230 --> 01:02:12.420
嗯，花言巧语，那是

01:02:12.420 --> 01:02:16.060
足以让模型相信这是一篇伟大的论文。

01:02:17.240 --> 01:02:19.410
最后一个，嗯，

01:02:19.410 --> 01:02:21.555
我想谈谈的地方，哪里，嗯，

01:02:21.555 --> 01:02:23.550
你可以看到确实有一些风险和

01:02:23.550 --> 01:02:26.655
使用NLP技术的一些陷阱是聊天机器人。

01:02:26.655 --> 01:02:31.560
嗯，所以我认为聊天机器人确实有一个非常有益的一面。

01:02:31.560 --> 01:02:33.930
嗯，Woebot就是一个例子，

01:02:33.930 --> 01:02:37.545
这家公司有这个聊天机器人，如果你没有，你可以和它聊天，

01:02:37.545 --> 01:02:39.480
嗯，感觉太好了，会努力的，

01:02:39.480 --> 01:02:41.565
嗯，我不知道，让你振作起来。

01:02:41.565 --> 01:02:43.830
嗯，所以，所以，你知道，

01:02:43.830 --> 01:02:46.770
可能是一种非常好的技术，可以帮助人们，

01:02:46.770 --> 01:02:49.380
嗯，但另一方面，有很大的风险。

01:02:49.380 --> 01:02:53.520
所以，微软研究院的一个例子就是在tweets上训练了聊天机器人。

01:02:53.520 --> 01:02:56.850
它很快就开始说种族主义的话，不得不被拉出来。

01:02:56.850 --> 01:02:59.625
嗯，所以我认为所有这些都突显了，嗯，

01:02:59.625 --> 01:03:02.505
随着NLP越来越有效，

01:03:02.505 --> 01:03:05.835
人们看到了在，嗯，

01:03:05.835 --> 01:03:09.300
越来越高的风险决策，尽管，

01:03:09.300 --> 01:03:11.775
你知道，有一些不错的-有一些吸引力，

01:03:11.775 --> 01:03:14.310
嗯，还有很多风险。

01:03:14.310 --> 01:03:17.310
嗯，还有什么问题吗，呃，

01:03:17.310 --> 01:03:20.620
NLP的这种社会影响？

01:03:21.650 --> 01:03:29.250
可以。嗯，这节课的最后一部分是看未来的研究，对吗？

01:03:29.250 --> 01:03:30.465
尤其是，嗯，

01:03:30.465 --> 01:03:33.510
我认为目前很多研究趋势是，

01:03:33.510 --> 01:03:35.760
对伯特的反应，嗯，对吧？

01:03:35.760 --> 01:03:40.080
所以，问题是伯特解决了什么，我们下一步要做什么？

01:03:40.080 --> 01:03:44.295
嗯，这是胶水基准测试的结果。

01:03:44.295 --> 01:03:47.070
嗯，那是，嗯，一份，

01:03:47.070 --> 01:03:50.280
10项自然语言理解任务。

01:03:50.280 --> 01:03:54.420
嗯，这10项任务的平均分是多少。

01:03:54.420 --> 01:03:57.810
嗯，左边，嗯，两个-两个是，

01:03:57.810 --> 01:04:00.720
对不起，对了-两个最合适的型号是，

01:04:00.720 --> 01:04:03.330
呃，呃，S-不，呃，

01:04:03.330 --> 01:04:06.480
只是监督培训过的机器学习系统，对吗？

01:04:06.480 --> 01:04:08.355
我们有一袋向量，嗯，

01:04:08.355 --> 01:04:10.920
相反，我们使用我们奇特的神经网络架构

01:04:10.920 --> 01:04:13.650
of BiLSTM + Attention and we get about five points.

01:04:13.650 --> 01:04:15.600
嗯，但是伯特的收获，

01:04:15.600 --> 01:04:17.520
呃，真的比这差小，对吧？

01:04:17.520 --> 01:04:19.890
所以，伯特提高了，呃，

01:04:19.890 --> 01:04:24.120
17分，最后我们的比分非常接近，

01:04:24.120 --> 01:04:26.925
嗯，这些任务的人的表现。

01:04:26.925 --> 01:04:29.820
嗯，那么一个，有点，

01:04:29.820 --> 01:04:32.220
人们想知道的是，

01:04:32.220 --> 01:04:35.115
这就是建筑工程的死亡吗？

01:04:35.115 --> 01:04:39.225
嗯，所以我敢肯定你们所有参与过默认最终项目的人，嗯，

01:04:39.225 --> 01:04:42.570
看到了一大堆不同的花哨图片，

01:04:42.570 --> 01:04:44.490
呃，解决小组的架构。

01:04:44.490 --> 01:04:46.710
嗯，有很多文件。

01:04:46.710 --> 01:04:48.390
他们都提出了一些，

01:04:48.390 --> 01:04:50.895
呃，注意力机制之类的。

01:04:50.895 --> 01:04:53.880
嗯，还有，嗯，是的。

01:04:53.880 --> 01:04:55.170
和伯特在一起，有点，

01:04:55.170 --> 01:04:56.970
嗯，你不需要这么做，对吧？

01:04:56.970 --> 01:04:59.190
你只要训练一个变压器，给它足够的数据，

01:04:59.190 --> 01:05:01.020
事实上你在球队里表现出色，

01:05:01.020 --> 01:05:03.885
你知道，也许，嗯，这些，呃，

01:05:03.885 --> 01:05:07.800
架构增强不一定是，嗯，

01:05:07.800 --> 01:05:10.590
推动进步的关键因素，

01:05:10.590 --> 01:05:13.720
嗯，改进这些任务的结果。

01:05:14.150 --> 01:05:16.740
嗯，对。所以，呃，

01:05:16.740 --> 01:05:18.630
如果你以研究者的视角来看待这个问题，

01:05:18.630 --> 01:05:20.610
你可以认为研究人员会说，“好吧，

01:05:20.610 --> 01:05:23.520
我可以花六个月的时间为

01:05:23.520 --> 01:05:27.930
如果我做得好，也许我会把成绩提高1分，嗯，F1分。”

01:05:27.930 --> 01:05:30.030
嗯，但是对于伯特来说，

01:05:30.030 --> 01:05:32.160
把他们的模型增加3倍，

01:05:32.160 --> 01:05:33.240
这就是两者的区别，

01:05:33.240 --> 01:05:36.090
它们就像一个基本尺寸的模型和一个大模型，

01:05:36.090 --> 01:05:39.585
嗯，把结果提高了5个F1点。

01:05:39.585 --> 01:05:42.150
嗯，所以它确实表明我们需要，某种程度上，

01:05:42.150 --> 01:05:46.635
重新排定优先次序，嗯，我们会追求哪种研究途径，

01:05:46.635 --> 01:05:49.500
因为这个建筑工程没有提供，

01:05:49.500 --> 01:05:52.605
时间投资收益的方式，

01:05:52.605 --> 01:05:54.765
嗯，利用未标记的数据是。

01:05:54.765 --> 01:05:57.735
嗯，那么现在，如果你看看球队排行榜，嗯，

01:05:57.735 --> 01:06:02.350
我认为至少前20名都是伯特加上一些东西。

01:06:04.190 --> 01:06:07.725
嗯，还有一个问题，呃，

01:06:07.725 --> 01:06:09.540
我想伯特已经长大了，

01:06:09.540 --> 01:06:11.400
嗯，我们需要更艰巨的任务，对吧？

01:06:11.400 --> 01:06:13.560
伯特几乎解决了球队的问题，

01:06:13.560 --> 01:06:15.060
如果你用，呃，

01:06:15.060 --> 01:06:16.860
接近人类的表现。

01:06:16.860 --> 01:06:19.230
嗯，所以有，嗯，

01:06:19.230 --> 01:06:22.635
新数据集的增长，呃，

01:06:22.635 --> 01:06:25.020
更具挑战性，有几种方法，

01:06:25.020 --> 01:06:26.370
嗯，它们可能更具挑战性。

01:06:26.370 --> 01:06:28.140
一个是，嗯，

01:06:28.140 --> 01:06:30.240
对较长的文件进行阅读理解，

01:06:30.240 --> 01:06:32.625
或者跨多个文档执行。

01:06:32.625 --> 01:06:35.280
嗯，有一个区域在看C-Uh，

01:06:35.280 --> 01:06:38.850
提出更难的问题，需要多跳推理。

01:06:38.850 --> 01:06:41.550
嗯，所以这基本上是测量-意味着你必须串

01:06:41.550 --> 01:06:45.180
来自不同地方的多个支持性事实，

01:06:45.180 --> 01:06:47.670
嗯，为了得到正确的答案。

01:06:47.670 --> 01:06:49.350
嗯，还有另一个地区，

01:06:49.350 --> 01:06:51.870
将问题回答置于对话中。

01:06:51.870 --> 01:06:54.330
嗯，还有一种，

01:06:54.330 --> 01:06:58.260
阅读理解数据集的构造细节，

01:06:58.260 --> 01:07:00.600
这确实影响了，

01:07:00.600 --> 01:07:02.835
嗯，任务的难度。

01:07:02.835 --> 01:07:04.110
这就是，嗯，

01:07:04.110 --> 01:07:06.495
当你创建这些数据集时，

01:07:06.495 --> 01:07:09.420
是写文章问题的人，

01:07:09.420 --> 01:07:11.535
他们能看到那条通道吗？

01:07:11.535 --> 01:07:14.070
嗯，所以，当然，更容易出现

01:07:14.070 --> 01:07:16.110
当你看到这段话的时候，

01:07:16.110 --> 01:07:18.870
如果你在看不到文章的情况下提出一个问题，

01:07:18.870 --> 01:07:21.810
你甚至可能没有一个可以回答的问题。

01:07:21.810 --> 01:07:23.730
嗯，但是看问题

01:07:23.730 --> 01:07:26.460
这段话首先是不现实的，对吧？

01:07:26.460 --> 01:07:28.845
所以，呃，如果我问一个问题，你知道，

01:07:28.845 --> 01:07:30.585
我通常不会

01:07:30.585 --> 01:07:33.870
坐在我面前回答那个问题的段落。

01:07:33.870 --> 01:07:35.670
嗯，除此之外，

01:07:35.670 --> 01:07:37.560
它确实鼓励简单的问题，对吗？

01:07:37.560 --> 01:07:39.840
所以，如果你是一个机械土耳其人，

01:07:39.840 --> 01:07:42.869
你可以写尽可能多的问题，

01:07:42.869 --> 01:07:44.790
然后你看到一篇文章说，

01:07:44.790 --> 01:07:46.350
嗯，我不知道，你知道，

01:07:46.350 --> 01:07:50.040
亚伯拉罕·林肯是美国第16任总统，

01:07:50.040 --> 01:07:51.600
嗯，你要写什么？

01:07:51.600 --> 01:07:53.100
作为你的问题，你要写，

01:07:53.100 --> 01:07:55.365
他是美国第16任总统。

01:07:55.365 --> 01:07:58.035
你不会写一些更有趣、更难回答的东西。

01:07:58.035 --> 01:08:01.890
嗯，所以这是众包数据集改变的一种方式，嗯，

01:08:01.890 --> 01:08:04.170
人们现在确定问题是，

01:08:04.170 --> 01:08:07.410
有点独立于上下文。

01:08:07.410 --> 01:08:09.375
嗯，所以我要简单地，呃，

01:08:09.375 --> 01:08:11.610
检查这一行中的几个新数据集。

01:08:11.610 --> 01:08:15.150
所以有一个叫做quac，它代表上下文中的问答。

01:08:15.150 --> 01:08:16.815
嗯，在这个数据集中，

01:08:16.815 --> 01:08:18.690
有一个老师和一个学生，

01:08:18.690 --> 01:08:21.390
嗯，老师看到一篇维基百科文章。

01:08:21.390 --> 01:08:24.195
这个学生想了解维基百科的这篇文章，

01:08:24.195 --> 01:08:28.005
目标是训练一个充当教师的机器学习模型。

01:08:28.005 --> 01:08:30.000
嗯，所以你可以想象未来，这个，

01:08:30.000 --> 01:08:32.190
某种程度上，技术对，

01:08:32.190 --> 01:08:34.320
呃，嗯，教育，有点，

01:08:34.320 --> 01:08:37.035
增加了一些自动化。

01:08:37.035 --> 01:08:42.495
嗯，呃，有一件事让这项任务变得困难，

01:08:42.495 --> 01:08:46.545
嗯，问题取决于整个谈话的历史。

01:08:46.545 --> 01:08:48.225
嗯，例如，呃，

01:08:48.225 --> 01:08:50.790
如果你看左边，呃，

01:08:50.790 --> 01:08:54.810
例如，嗯，对话，

01:08:54.810 --> 01:08:57.315
第三个问题是他是明星吗？

01:08:57.315 --> 01:09:02.070
嗯，很明显你不能回答这个问题，除非你在对话中回顾一下，

01:09:02.070 --> 01:09:04.095
认识到这个问题，

01:09:04.095 --> 01:09:06.180
嗯，谈话是愚蠢的鸭子。

01:09:06.180 --> 01:09:09.060
嗯，还有，有点，

01:09:09.060 --> 01:09:11.040
因为这个数据集更具挑战性，

01:09:11.040 --> 01:09:14.340
你可以看到，人类的表现有一个更大的差距，对吧？

01:09:14.340 --> 01:09:17.610
所以如果你用一些扩展训练伯特，你会…

01:09:17.610 --> 01:09:22.185
结果仍然比人类的表现差15个F1点。

01:09:22.185 --> 01:09:28.935
这是另一个数据集，叫做Hotpotqa。

01:09:28.935 --> 01:09:30.510
嗯，是，呃，

01:09:30.510 --> 01:09:32.760
设计用于多跳推理。

01:09:32.760 --> 01:09:35.610
嗯，本质上，为了回答一个问题，

01:09:35.610 --> 01:09:37.875
你必须查看多个文档，

01:09:37.875 --> 01:09:40.350
你必须从这些文件中找出不同的事实，

01:09:40.350 --> 01:09:41.925
做一些推断，

01:09:41.925 --> 01:09:44.655
嗯，为了得到正确的答案。

01:09:44.655 --> 01:09:48.645
嗯，所以我想，你知道，这是一项非常艰巨的任务。

01:09:48.645 --> 01:09:54.040
再说一次，嗯，人的表现之间有很大的差距。

01:09:54.590 --> 01:09:57.390
嗯，有什么问题吗，呃，

01:09:57.390 --> 01:10:01.720
新的数据集，嗯，对NLP来说更困难的chi-任务？

01:10:01.900 --> 01:10:07.035
可以。嗯，我会的，

01:10:07.035 --> 01:10:09.360
一种快速的火焰，穿过，嗯，

01:10:09.360 --> 01:10:12.210
在本次谈话的最后几分钟还有几个方面。

01:10:12.210 --> 01:10:16.335
嗯，所以我认为多任务学习真的越来越重要了。

01:10:16.335 --> 01:10:18.390
嗯，当然，嗯，

01:10:18.390 --> 01:10:20.190
你已经讲了一整堂课了，对吧？

01:10:20.190 --> 01:10:21.750
所以我不会花太多时间在上面。

01:10:21.750 --> 01:10:24.330
嗯，但也许有一个，呃，

01:10:24.330 --> 01:10:28.920
有趣的是，如果你看看这个胶水基准测试的性能，

01:10:28.920 --> 01:10:31.320
所以这是自然语言理解的基准，

01:10:31.320 --> 01:10:34.920
嗯，所有的顶级组合结果，嗯，

01:10:34.920 --> 01:10:37.980
是-那现在实际上超过了伯特在

01:10:37.980 --> 01:10:42.390
绩效是——以多任务的方式训练伯特。

01:10:42.390 --> 01:10:47.370
嗯，我觉得另一个有趣的，呃，

01:10:47.370 --> 01:10:52.020
多任务学习的动机是，如果你在训练伯特，你会

01:10:52.020 --> 01:10:54.480
非常大的型号和一种制造方法

01:10:54.480 --> 01:10:58.690
更有效地使用这个模型是训练它同时做许多事情。

01:11:00.950 --> 01:11:04.920
另一个绝对重要的领域，嗯，

01:11:04.920 --> 01:11:09.090
我认为未来处理低资源环境很重要。

01:11:09.090 --> 01:11:10.890
嗯，这里我用的是非常广泛的，

01:11:10.890 --> 01:11:13.020
呃，资源的定义，对吧。

01:11:13.020 --> 01:11:15.435
这可能意味着计算能力，嗯，你知道，

01:11:15.435 --> 01:11:18.990
伯特很棒，但运行它也需要大量的计算。

01:11:18.990 --> 01:11:20.310
所以说这是不现实的，

01:11:20.310 --> 01:11:22.545
嗯，如果你在建，我们假设一部手机，呃，

01:11:22.545 --> 01:11:27.510
一个移动设备的应用程序，你可以运行一个伯特大小的模型。

01:11:27.510 --> 01:11:31.845
嗯，正如我之前在谈话中提到的，嗯，你知道的，

01:11:31.845 --> 01:11:36.225
低资源语言是一个我认为很漂亮的领域，嗯，

01:11:36.225 --> 01:11:39.120
目前在NLP研究中的代表不足，

01:11:39.120 --> 01:11:41.460
因为大多数数据集都是英文的，嗯，

01:11:41.460 --> 01:11:42.570
但我认为，是的，

01:11:42.570 --> 01:11:44.130
真的，你知道，

01:11:44.130 --> 01:11:49.245
很多人为了从NLP技术中获益，

01:11:49.245 --> 01:11:52.200
我们需要有能在很多

01:11:52.200 --> 01:11:56.055
不同的语言，尤其是那些没有太多训练数据的语言。

01:11:56.055 --> 01:12:00.870
而且，嗯，说到低-低数量的培训数据，我认为一般来说，

01:12:00.870 --> 01:12:04.065
呃，A-一个有趣的研究领域，

01:12:04.065 --> 01:12:05.550
嗯，在机器学习中。

01:12:05.550 --> 01:12:07.305
事实上，人们是，嗯，

01:12:07.305 --> 01:12:09.315
在这方面也做了很多工作。

01:12:09.315 --> 01:12:11.460
嗯，所以一个术语通常是，呃，

01:12:11.460 --> 01:12:14.025
常用的一个术语是“少量学习”。

01:12:14.025 --> 01:12:16.410
嗯，这基本上意味着能够

01:12:16.410 --> 01:12:18.720
训练一个只看到

01:12:18.720 --> 01:12:20.730
我们来举五到十个例子。

01:12:20.730 --> 01:12:23.370
嗯，有一个动机，嗯，

01:12:23.370 --> 01:12:29.445
我认为我们现有的机器学习系统是如何学习的，

01:12:29.445 --> 01:12:31.875
人类是如何学习的，嗯，

01:12:31.875 --> 01:12:35.550
人类可以很快地从五个左右的例子中归纳出来。

01:12:35.550 --> 01:12:37.185
如果你在训练神经网络，

01:12:37.185 --> 01:12:38.580
你通常需要，你知道，

01:12:38.580 --> 01:12:41.610
成千上万的例子，甚至数万个，

01:12:41.610 --> 01:12:45.060
数以万计的例子来获得有用的东西。

01:12:45.060 --> 01:12:49.650
嗯，所以我也认为这是未来一个非常重要的领域。

01:12:49.650 --> 01:12:53.730
嗯，最后一个我想进去的地方，嗯，

01:12:53.730 --> 01:12:57.600
更深入的一点是解释和理解模型。

01:12:57.600 --> 01:13:00.570
嗯，所以，这真的有两个方面。

01:13:00.570 --> 01:13:04.095
一个是如果我有一个机器学习模型，它会做出预测，

01:13:04.095 --> 01:13:06.450
我想，呃，

01:13:06.450 --> 01:13:08.790
知道它为什么做出这样的预测吗？

01:13:08.790 --> 01:13:11.385
所以有了一些理由，有了一些解释，

01:13:11.385 --> 01:13:15.180
嗯，这在像医疗保健这样的领域尤其重要，对吗？

01:13:15.180 --> 01:13:17.910
所以如果你是个医生，你在做决定，嗯，

01:13:17.910 --> 01:13:21.090
你的机器学习模式可能还不够好，

01:13:21.090 --> 01:13:22.470
“患者患有X病。”

01:13:22.470 --> 01:13:23.805
你真的想说，

01:13:23.805 --> 01:13:26.070
“由于这些原因，患者患有X病。”

01:13:26.070 --> 01:13:28.589
嗯，因为你作为一名医生可以复查，

01:13:28.589 --> 01:13:30.540
并尝试验证，

01:13:30.540 --> 01:13:33.165
呃，机器，嗯，我想，

01:13:33.165 --> 01:13:35.610
嗯，想出来那个诊断。

01:13:35.610 --> 01:13:38.640
嗯，另一个解释领域

01:13:38.640 --> 01:13:41.370
理解模型更像是一个科学问题，对吗？

01:13:41.370 --> 01:13:43.860
我们知道伯特这样的人工作得很好吗？

01:13:43.860 --> 01:13:45.960
嗯，我们想知道他们为什么工作得很好？

01:13:45.960 --> 01:13:48.195
他们模拟语言的哪些方面？

01:13:48.195 --> 01:13:49.995
嗯，他们没有做什么模型？

01:13:49.995 --> 01:13:52.020
嗯，这可能会导致，嗯，

01:13:52.020 --> 01:13:55.695
改进的想法，嗯，那些-那些模型。

01:13:55.695 --> 01:13:59.580
嗯，那么，嗯，这是一个，呃，

01:13:59.580 --> 01:14:04.935
几张关于评估主要方法的幻灯片-回答科学问题。

01:14:04.935 --> 01:14:06.975
机器学习模型学习什么？

01:14:06.975 --> 01:14:10.530
嗯，你要做的是你有一个模型，所以我们假设它是伯特。

01:14:10.530 --> 01:14:13.440
它需要输入一系列单词，嗯，

01:14:13.440 --> 01:14:16.470
它产生一系列向量作为输出，嗯，

01:14:16.470 --> 01:14:18.570
我们想问一下，它知道吗，例如，

01:14:18.570 --> 01:14:19.680
言语的一部分？

01:14:19.680 --> 01:14:22.455
所以，它在向量表示中是这样的，

01:14:22.455 --> 01:14:24.630
它捕获了一些关于语法的信息吗？

01:14:24.630 --> 01:14:29.850
嗯，问这个问题的一个简单方法是在Bert上训练另一个分类器，

01:14:29.850 --> 01:14:31.965
嗯，这是训练的，

01:14:31.965 --> 01:14:34.395
嗯，我们来说说语音标记的一部分。

01:14:34.395 --> 01:14:36.825
嗯，但我们只有，嗯，

01:14:36.825 --> 01:14:39.945
回到诊断分类器本身。

01:14:39.945 --> 01:14:43.680
换句话说，我们是在处理伯特的输出，嗯，

01:14:43.680 --> 01:14:46.185
作为固定输入的向量序列，

01:14:46.185 --> 01:14:48.600
我们正在探索这些向量，

01:14:48.600 --> 01:14:50.505
嗯，它们含有吗，嗯，

01:14:50.505 --> 01:14:52.440
关于演讲的一部分的信息

01:14:52.440 --> 01:14:56.445
上面的第二个诊断分类器可以解码，

01:14:56.445 --> 01:14:59.050
嗯，要得到正确的标签吗？

01:14:59.120 --> 01:15:03.690
嗯，所以，嗯，这是相当多的关注点。

01:15:03.690 --> 01:15:06.540
嗯，一个问题是，

01:15:06.540 --> 01:15:09.915
如果你的诊断分类器太复杂，

01:15:09.915 --> 01:15:13.200
它只需解决分类——任务本身，

01:15:13.200 --> 01:15:15.210
基本上可以忽略，

01:15:15.210 --> 01:15:17.565
伯特所作的任何陈述。

01:15:17.565 --> 01:15:20.040
嗯，所以-所以现在的标准是使用

01:15:20.040 --> 01:15:23.205
在Bert上有一个SoftMax层，

01:15:23.205 --> 01:15:25.185
嗯，做这些决定。

01:15:25.185 --> 01:15:29.100
嗯，有一大堆工作要做

01:15:29.100 --> 01:15:32.895
从本质上评价这些模型的语言知识。

01:15:32.895 --> 01:15:34.785
嗯，你可以做部分语音标记，

01:15:34.785 --> 01:15:37.080
你可以做更多的语义任务，比如，

01:15:37.080 --> 01:15:39.285
嗯，关系提取，嗯，

01:15:39.285 --> 01:15:41.265
或者-或者类似共同参考的东西。

01:15:41.265 --> 01:15:44.280
嗯，这是一个相当活跃的工作领域。

01:15:44.280 --> 01:15:47.055
嗯，这是，呃，只有一个，呃，

01:15:47.055 --> 01:15:51.195
图中显示了这种方法的一些结果。

01:15:51.195 --> 01:15:53.865
所以我们要做的是增加

01:15:53.865 --> 01:15:56.955
诊断分类器到不同层的bert，

01:15:56.955 --> 01:16:02.620
我们看到哪些层的bert对于特定的任务更有用。

01:16:02.620 --> 01:16:07.025
嗯，而且，嗯，某种有趣的事情从中产生，那就是，嗯，

01:16:07.025 --> 01:16:10.310
伯特的不同层次似乎是对应的，嗯，

01:16:10.310 --> 01:16:12.890
很好的理解，

01:16:12.890 --> 01:16:15.395
嗯，不同层次的语言学。

01:16:15.395 --> 01:16:19.110
嗯，所以，呃，依赖性分析，这是一项语法任务，

01:16:19.110 --> 01:16:20.940
嗯，呃，你知道，这算是一种，

01:16:20.940 --> 01:16:23.430
理解句子的中级任务。

01:16:23.430 --> 01:16:28.125
嗯，伯特的中层，所以从6层到8层之类的，

01:16:28.125 --> 01:16:30.480
是最擅长依赖分析的。

01:16:30.480 --> 01:16:34.095
嗯，如果你有一个非常语义化的任务，比如情感分析，

01:16:34.095 --> 01:16:35.880
嗯，你想学点什么，呃，

01:16:35.880 --> 01:16:38.325
整个句子的语义属性，嗯，

01:16:38.325 --> 01:16:41.490
那么伯特的最后一层似乎就是

01:16:41.490 --> 01:16:45.700
编码关于这个，呃，现象的大部分信息。

01:16:46.310 --> 01:16:48.690
嗯，好吧。

01:16:48.690 --> 01:16:50.835
这几乎就是谈话的内容了，嗯，

01:16:50.835 --> 01:16:54.600
我只有一张幻灯片，呃，嗯，

01:16:54.600 --> 01:16:57.870
NLP不是在学术研究的背景下，

01:16:57.870 --> 01:17:00.735
我已经说过很多了，但是在工业界，NLP，

01:17:00.735 --> 01:17:03.075
实际上，那里的进展很快。

01:17:03.075 --> 01:17:06.315
我想指出两个我认为

01:17:06.315 --> 01:17:10.650
特别是对使用NLP技术的极大兴趣。

01:17:10.650 --> 01:17:12.240
嗯，一个是对话，

01:17:12.240 --> 01:17:14.010
嗯，像聊天机器人之类的东西，对吧？

01:17:14.010 --> 01:17:17.580
亚历克萨奖，他们在那里投资了很多钱，

01:17:17.580 --> 01:17:21.105
嗯，让小组找出如何改进聊天对话。

01:17:21.105 --> 01:17:25.230
嗯，我也认为客户服务的潜力很大，对吧？

01:17:25.230 --> 01:17:28.170
所以改进基本上自动化的系统，嗯，

01:17:28.170 --> 01:17:29.580
你知道，给你订个航班，

01:17:29.580 --> 01:17:32.385
或者帮助您取消订阅或类似的操作。

01:17:32.385 --> 01:17:35.460
嗯，同样，在医疗保健方面也有很多潜力。

01:17:35.460 --> 01:17:39.180
嗯，一种是了解某人的记录，

01:17:39.180 --> 01:17:42.060
嗯，生病了，帮助他们-帮助诊断。

01:17:42.060 --> 01:17:43.935
嗯，我想还有一个，嗯，

01:17:43.935 --> 01:17:46.215
同样重要的是，

01:17:46.215 --> 01:17:49.020
分析生物医学论文。

01:17:49.020 --> 01:17:54.285
嗯，那么，嗯，正在写的生物医学论文的数量真是太疯狂了，

01:17:54.285 --> 01:17:56.100
嗯，它比数字大得多

01:17:56.100 --> 01:17:57.960
正在撰写的计算机科学论文。

01:17:57.960 --> 01:18:01.530
[噪音]嗯，如果你是医生，

01:18:01.530 --> 01:18:03.150
或者如果你是研究人员，嗯，

01:18:03.150 --> 01:18:06.360
在医学上，你可能想查找一些非常具体的东西，对吗？

01:18:06.360 --> 01:18:07.620
你可能想知道什么是

01:18:07.620 --> 01:18:11.370
这种特殊药物对这种特殊基因的影响，

01:18:11.370 --> 01:18:13.140
或者一个有这种特殊基因的细胞。

01:18:13.140 --> 01:18:16.710
嗯，现在找不到好方法，嗯，

01:18:16.710 --> 01:18:20.175
数十万份文件来寻找是否有人有，呃，

01:18:20.175 --> 01:18:23.085
做了这个实验并取得了结果，

01:18:23.085 --> 01:18:25.095
嗯，事情的特殊组合。

01:18:25.095 --> 01:18:28.590
嗯，自动阅读所有的生物医学文献，

01:18:28.590 --> 01:18:30.850
嗯，可能有很多价值。

01:18:31.100 --> 01:18:33.960
好吧，嗯，最后，嗯，

01:18:33.960 --> 01:18:38.280
在过去的五年里，由于在全国人民计划中的深入学习，进步很快。

01:18:38.280 --> 01:18:42.780
去年，我们看到了另一种

01:18:42.780 --> 01:18:45.300
我们的系统能力大幅提高，

01:18:45.300 --> 01:18:47.610
感谢，呃，使用未标记的数据。

01:18:47.610 --> 01:18:49.095
这就是伯特这样的方法。

01:18:49.095 --> 01:18:54.210
嗯，还有，嗯，我认为另一件重要的事情是，

01:18:54.210 --> 01:18:58.170
NLP系统开始处于一个可以产生巨大社会影响的地方。

01:18:58.170 --> 01:19:04.845
嗯，这使得一些诸如偏见和安全性的问题非常重要。嗯，谢谢。

01:19:04.845 --> 01:19:06.690
呃，祝你完成所有项目好运。

01:19:06.690 --> 01:19:14.800
[APPLAUSE].

