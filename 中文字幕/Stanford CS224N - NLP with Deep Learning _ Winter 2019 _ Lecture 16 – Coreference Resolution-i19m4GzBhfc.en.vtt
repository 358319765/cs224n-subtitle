WEBVTT
Kind: captions
Language: en

00:00:04.790 --> 00:00:09.660
大家好，该开始了。

00:00:09.660 --> 00:00:18.755
可以。嗯，所以，今天我们要讨论的是一个主题，嗯，

00:00:18.755 --> 00:00:23.745
共指消解，我马上解释这是什么，

00:00:23.745 --> 00:00:27.060
但是在开始之前

00:00:27.060 --> 00:00:29.565
嗯，公告上说了几句。

00:00:29.565 --> 00:00:35.770
嗯，所以助教们都在忙着做家庭作业，五个年级的作业都已经完成了。

00:00:35.770 --> 00:00:39.170
所以我们希望我们能把这些给你，嗯，

00:00:39.170 --> 00:00:41.600
明天，以防万一你急于知道

00:00:41.600 --> 00:00:44.750
在你做出最后决定之前。

00:00:44.750 --> 00:00:48.290
然后，你应该记住的另一件事

00:00:48.290 --> 00:00:52.580
最后一个项目的里程碑是这个星期二吗？

00:00:52.580 --> 00:00:55.780
现在，我承认即使在我看来，

00:00:55.780 --> 00:00:58.925
“伙计，伙计，这个里程碑来得真快。”

00:00:58.925 --> 00:01:01.680
我意识到，你可能会感觉加倍。

00:01:01.680 --> 00:01:06.530
所以你知道，我确实为此道歉，

00:01:06.530 --> 00:01:11.435
但你知道，我们真的希望我们能用这个来帮助你，

00:01:11.435 --> 00:01:15.050
给你反馈你在做什么和建议，

00:01:15.050 --> 00:01:17.120
它看起来真的，嗯，

00:01:17.120 --> 00:01:19.880
我们唯一的机会，嗯，

00:01:19.880 --> 00:01:23.900
回过头来对项目提供更多反馈，嗯，

00:01:23.900 --> 00:01:28.825
在进入本季度最后一周之前，如果我们能得到一些东西，

00:01:28.825 --> 00:01:30.710
嗯，星期二，希望到时候，

00:01:30.710 --> 00:01:32.810
有点像在周末前又把它扭转过来。

00:01:32.810 --> 00:01:36.040
所以希望不是帮助你，

00:01:36.040 --> 00:01:39.685
嗯，在你的生活中制造障碍和障碍。

00:01:39.685 --> 00:01:44.420
可以。所以今天我们要做的是，

00:01:44.420 --> 00:01:47.750
了解更多关于变化的语言主题并学习

00:01:47.750 --> 00:01:51.920
关于共指消解中发生的事情的更多信息。

00:01:51.920 --> 00:01:54.185
所以首先，我要谈谈这个任务，

00:01:54.185 --> 00:01:57.380
然后再看看人们的一些模型，

00:01:57.380 --> 00:01:59.990
嗯，做共指消解。

00:01:59.990 --> 00:02:03.035
首先，这是什么？

00:02:03.035 --> 00:02:08.850
嗯，共指消解的概念就是我们所做的，我们有一个文本，

00:02:08.850 --> 00:02:13.175
奥巴马提名希拉里·罗德姆·克林顿为他的国务卿。

00:02:13.175 --> 00:02:18.230
星期一，“像大多数文本一样，这些文本是关于实体的，

00:02:18.230 --> 00:02:21.200
如果实体通常是人类，

00:02:21.200 --> 00:02:26.000
但它们也可以是其他的东西，比如说上帝看到的长颈鹿或者其他什么东西。

00:02:26.000 --> 00:02:28.580
所以我们似乎想，

00:02:28.580 --> 00:02:32.225
找到提到实体的位置。

00:02:32.225 --> 00:02:34.040
所以我的实体被提到，

00:02:34.040 --> 00:02:35.990
它们被称为提及。

00:02:35.990 --> 00:02:39.500
像奥巴马和国务卿这样的人，

00:02:39.500 --> 00:02:43.265
他，她，他们被提到实体。

00:02:43.265 --> 00:02:46.990
然后，当我们讨论共指消解的时候，

00:02:46.990 --> 00:02:50.270
我们要做的任务是，

00:02:50.270 --> 00:02:54.680
其中哪一项提到同一实体，

00:02:54.680 --> 00:02:57.170
世界上同样的东西。

00:02:57.170 --> 00:03:02.330
好吧，本文中提到的一个实体是巴拉克·奥巴马，

00:03:02.330 --> 00:03:06.919
后来在课文中他被称为他和他，

00:03:06.919 --> 00:03:12.425
所以这三个红色名词短语都是相互参照的。

00:03:12.425 --> 00:03:17.270
那么，这就是这个现实世界的实体。

00:03:17.270 --> 00:03:21.110
嗯，然后，我们有希拉里·罗德姆·克林顿的参考资料，

00:03:21.110 --> 00:03:22.700
国务卿，她，

00:03:22.700 --> 00:03:28.445
她，第一夫人，他们都是指一个不同的实体。

00:03:28.445 --> 00:03:31.520
所以他们都是指这个人。

00:03:31.520 --> 00:03:34.390
这些就是我们共指的例子。

00:03:34.390 --> 00:03:40.745
嗯，在某种程度上，这是Triv-对人类来说似乎很明显，

00:03:40.745 --> 00:03:42.635
嗯，看看东西，嗯，

00:03:42.635 --> 00:03:45.590
但事实上，这可能有点棘手和困难。

00:03:45.590 --> 00:03:50.480
嗯，那么，嗯，我想我们可以花上几分钟

00:03:50.480 --> 00:03:55.655
相互交流，共同解决相互参照的问题，这样你们就可以，

00:03:55.655 --> 00:03:57.980
嗯，好好想想。

00:03:57.980 --> 00:04:01.010
嗯，这是一个小故事的一部分。

00:04:01.010 --> 00:04:04.270
嗯，这是Shruthi Rao的一个故事，叫做《星星》。

00:04:04.270 --> 00:04:08.089
嗯，现在，我承认，因为这是一个CS课程，

00:04:08.089 --> 00:04:10.250
嗯，不是文学课，

00:04:10.250 --> 00:04:11.840
我做了一点，嗯，

00:04:11.840 --> 00:04:15.049
有助于编辑此文本，使其更短，

00:04:15.049 --> 00:04:16.630
所以我可以更适合，

00:04:16.630 --> 00:04:18.800
发生了什么，嗯，

00:04:18.800 --> 00:04:22.145
在页面上，嗯，但是，嗯，

00:04:22.145 --> 00:04:24.439
一切都是一种语言

00:04:24.439 --> 00:04:27.300
[听不见]源于原文。

00:04:27.300 --> 00:04:31.605
可以。所以，在本文中，

00:04:31.605 --> 00:04:36.400
嗯，谁是第一个被提到的实体？

00:04:37.970 --> 00:04:41.100
瓦纳加，好的。

00:04:41.100 --> 00:04:42.570
可以。所以是瓦纳加。

00:04:42.570 --> 00:04:45.255
现在，在哪里，让我们向前做。

00:04:45.255 --> 00:04:51.040
文中还提到瓦纳加在哪里？

00:04:52.580 --> 00:04:54.720
她的儿子，对吗？

00:04:54.720 --> 00:04:56.460
所以她不是儿子，

00:04:56.460 --> 00:05:00.400
但这是瓦纳加的名字，对吧？

00:05:05.120 --> 00:05:08.520
嗯，她辞职了。

00:05:08.520 --> 00:05:12.090
可以。之后？

00:05:12.090 --> 00:05:15.810
她买了。

00:05:15.810 --> 00:05:17.535
可以。所以还有一个她。

00:05:17.535 --> 00:05:20.205
在那之前还有其他的参考资料吗？

00:05:20.205 --> 00:05:24.750
她自己，对吧？所以她自己也是瓦纳加的参考。

00:05:25.280 --> 00:05:27.770
嗯，好吧。那么，又是，

00:05:27.770 --> 00:05:32.750
她做了这个，她，好的。

00:05:32.750 --> 00:05:33.980
我们已经完成了瓦纳加。

00:05:33.980 --> 00:05:36.140
好吧，这是个好的开始。

00:05:36.140 --> 00:05:40.270
可以。那么，嗯，我们找到了阿凯拉。

00:05:40.270 --> 00:05:45.495
可以。嗯，下一个提到的Akhila在哪里？

00:05:45.495 --> 00:05:48.450
作为Akhila。好了，我们开始吧。

00:05:48.450 --> 00:05:54.940
嗯，还有其他的参考资料吗，嗯，关于阿凯拉？

00:05:58.280 --> 00:06:04.390
也许不是。可以。下一个被提到的实体是什么？

00:06:07.820 --> 00:06:10.200
普拉贾瓦尔。

00:06:10.200 --> 00:06:15.150
可以。那么Prajwal还有什么其他参考呢？

00:06:19.060 --> 00:06:20.180
他们。

00:06:20.180 --> 00:06:24.330
他们？可以。这是个棘手的问题，对吧？

00:06:24.330 --> 00:06:26.430
所以他们，我的意思是，

00:06:26.430 --> 00:06:29.020
那是指谁？

00:06:30.440 --> 00:06:35.790
它是指Prajwal和Akash。

00:06:35.790 --> 00:06:40.500
是的，所以这两个词都指Prajwal和Akash。

00:06:40.500 --> 00:06:44.180
也就是说，这是人类语言中发生的事情。

00:06:44.180 --> 00:06:46.790
这被称为分裂前因，

00:06:46.790 --> 00:06:49.220
你有一件事，他们，

00:06:49.220 --> 00:06:54.245
这有点像是指在它之前出现的两个分布式的东西。

00:06:54.245 --> 00:07:01.085
嗯，这是我第一次遗憾地承认自然语言处理技术。

00:07:01.085 --> 00:07:04.940
我们稍后将要讨论的所有NLP系统

00:07:04.940 --> 00:07:09.920
今天或一般来说，已经建立的处理分裂的前因。

00:07:09.920 --> 00:07:13.790
一旦有分裂的前因，它们就会自动丢失。

00:07:13.790 --> 00:07:15.435
嗯，有点伤心，

00:07:15.435 --> 00:07:17.300
嗯，但这就是技术的现状。

00:07:17.300 --> 00:07:18.710
所以这是个问题，嗯，

00:07:18.710 --> 00:07:20.390
我们仍然可以努力改进，

00:07:20.390 --> 00:07:26.030
但好吧，有一种是半普拉杰瓦尔式的。嗯，好吧。

00:07:26.030 --> 00:07:29.195
所以这里有直接的Prajwal，

00:07:29.195 --> 00:07:36.580
但是在文章的早期是否还有另一个地方有效地提到了Prajwal？

00:07:40.190 --> 00:07:46.565
是啊。所以阿基拉的儿子真的是另一个提到普拉杰瓦尔的人，对吧？

00:07:46.565 --> 00:07:52.590
可以。嗯，好吧。

00:07:52.590 --> 00:07:56.130
嗯，还有什么关于普拉杰瓦尔的事吗？也许不是。

00:07:56.130 --> 00:07:57.765
可以。然后我们继续。

00:07:57.765 --> 00:08:00.315
可以。下一个实体是谁？

00:08:00.315 --> 00:08:04.305
阿卡什。我们这里有阿卡什，

00:08:04.305 --> 00:08:05.700
然后再一次，

00:08:05.700 --> 00:08:09.150
我们看到她儿子指的是阿卡什。

00:08:09.150 --> 00:08:12.435
嗯，这是阿卡什。

00:08:12.435 --> 00:08:17.530
可以。还有什么其他的，还有什么关于阿卡什的？

00:08:20.450 --> 00:08:29.010
好吧，这里还有另一个阿卡什，嗯，第四个他。

00:08:29.010 --> 00:08:35.340
可以。呃，还有一个阿卡什。

00:08:35.340 --> 00:08:42.555
好吧，嗯，但是，那么，嗯，在这里。

00:08:42.555 --> 00:08:45.330
可以。显而易见的阿卡什也是。

00:08:45.330 --> 00:08:47.760
这里有个棘手的案子

00:08:47.760 --> 00:08:50.280
你可能会想，对这件事的正确处理是什么？

00:08:50.280 --> 00:08:55.800
你知道，有点像阿卡什要做一棵树，好吧。

00:08:55.800 --> 00:09:00.195
所以在某种意义上，这棵树是阿卡什。

00:09:00.195 --> 00:09:05.430
嗯，从这个故事的参考角度来看，

00:09:05.430 --> 00:09:09.990
树的参考与阿卡什相同。

00:09:09.990 --> 00:09:12.795
你可以想，嗯，

00:09:12.795 --> 00:09:16.440
这意味着你应该处理

00:09:16.440 --> 00:09:18.645
嗯，那棵树，

00:09:18.645 --> 00:09:20.925
树的实例，

00:09:20.925 --> 00:09:25.500
后来当最美的树对了，真的，

00:09:25.500 --> 00:09:28.215
这也是阿卡什的风格。

00:09:28.215 --> 00:09:30.255
感觉不太对劲，

00:09:30.255 --> 00:09:33.030
但这是一起出现的，对吗？

00:09:33.030 --> 00:09:38.145
这里我们有一种预测结构，嗯，

00:09:38.145 --> 00:09:39.770
有，你知道，B。

00:09:39.770 --> 00:09:41.810
当你准备好的时候，

00:09:41.810 --> 00:09:46.760
当你有这样的句子，嗯，你知道，

00:09:46.760 --> 00:09:52.270
我的孩子是班上最聪明的孩子，或者类似的，在某种意义上，

00:09:52.270 --> 00:09:54.960
你说的是最聪明的孩子

00:09:54.960 --> 00:09:58.560
这个班级和我的孩子有相同的参考资料。

00:09:58.560 --> 00:10:04.635
一些系统计算了这种预测的链接，

00:10:04.635 --> 00:10:07.215
说这是共指，而

00:10:07.215 --> 00:10:10.890
其他人不这样认为也不太合理。

00:10:10.890 --> 00:10:12.780
所以事情就不一样了。

00:10:12.780 --> 00:10:14.985
可以。所以，嗯，那些，

00:10:14.985 --> 00:10:17.925
这些是相当数量的实体。

00:10:17.925 --> 00:10:23.025
我的意思是，显然还有很多其他的事情被提到，

00:10:23.025 --> 00:10:25.440
嗯，那种，嗯，对吧？

00:10:25.440 --> 00:10:27.660
这就是当地的公园，对吧，

00:10:27.660 --> 00:10:30.450
这是对某个实体的提及。

00:10:30.450 --> 00:10:36.360
嗯，有，嗯，学校，嗯，对吗？

00:10:36.360 --> 00:10:44.475
所以这里有一所学校，所以学校和学前教育是相互参照的，

00:10:44.475 --> 00:10:47.370
幼儿园就在这里，对吗？

00:10:47.370 --> 00:10:49.380
嗯，还有，

00:10:49.380 --> 00:10:52.155
嗯，这又是一个棘手的问题，

00:10:52.155 --> 00:10:56.090
如何对待顽皮的孩子，克里希纳勋爵，因为，

00:10:56.090 --> 00:10:59.525
你知道，从某种意义上说，Prajwal代表着这个。

00:10:59.525 --> 00:11:02.510
还有很多其他的实体被提到，对吗？

00:11:02.510 --> 00:11:05.195
有一件T恤，还有一条裤子，

00:11:05.195 --> 00:11:08.355
嗯，还有，嗯，类似的事情。

00:11:08.355 --> 00:11:12.060
另一个棘手的问题是当你稍后进入

00:11:12.060 --> 00:11:16.950
故事是你可以拥有拥有部分的实体。

00:11:16.950 --> 00:11:19.425
所以我们不仅有一棵树，

00:11:19.425 --> 00:11:21.840
但是那棵树有很多部分，对吗？

00:11:21.840 --> 00:11:23.370
所以这棵树有一个树干，

00:11:23.370 --> 00:11:25.169
树上有树叶，

00:11:25.169 --> 00:11:28.275
嗯，像这样的事情。

00:11:28.275 --> 00:11:31.170
还有这些代表水果的红球，对吧？

00:11:31.170 --> 00:11:35.400
所以有很多东西，以某种方式连接在一起，以某种方式分开。

00:11:35.400 --> 00:11:39.330
那种，不太适合我们的模型

00:11:39.330 --> 00:11:43.425
与共指代一起使用，或者是因为我们确实在进行共指代，

00:11:43.425 --> 00:11:48.015
嗯，参考模型基本上脱离了实体的概念。

00:11:48.015 --> 00:11:50.325
嗯，但不知何故，有一种复杂性，

00:11:50.325 --> 00:11:52.290
你知道，人类也有部分，对吧？

00:11:52.290 --> 00:11:53.744
我们有手和脸，

00:11:53.744 --> 00:11:56.145
我们不能说，哦，那是一个独立的实体，

00:11:56.145 --> 00:11:59.895
但他们不知何故参与了另一个实体。

00:11:59.895 --> 00:12:04.740
可以。嗯，希望这对你有帮助。

00:12:04.740 --> 00:12:07.665
为什么共指消解有用？

00:12:07.665 --> 00:12:11.895
嗯，所以有很多事情我们都想做的很好

00:12:11.895 --> 00:12:16.379
在自然语言处理中，除非

00:12:16.379 --> 00:12:19.845
呃，你知道如何做共指消解。

00:12:19.845 --> 00:12:25.410
所以我们想在回答问题，总结问题，

00:12:25.410 --> 00:12:28.500
从文本或类似的东西中提取事实，

00:12:28.500 --> 00:12:32.985
有些地方我们会失败，除非我们能做共指消解。

00:12:32.985 --> 00:12:35.025
因为如果我们在读一段文字，

00:12:35.025 --> 00:12:38.640
据说他1961年出生，

00:12:38.640 --> 00:12:41.610
我们可以找出事实或回答问题，

00:12:41.610 --> 00:12:43.845
如果我们能找出他是谁，

00:12:43.845 --> 00:12:46.780
但我们可能不能。

00:12:49.040 --> 00:12:53.580
嗯，还有一个地方

00:12:53.580 --> 00:12:57.480
这在机器翻译中非常有用，

00:12:57.480 --> 00:13:02.130
所以很多语言都会掉代词。

00:13:02.130 --> 00:13:04.935
所以你不必给出明确的代词，

00:13:04.935 --> 00:13:09.105
但你需要能够想出如何填写这些表格。

00:13:09.105 --> 00:13:12.765
这是关于

00:13:12.765 --> 00:13:15.075
嗯，动词的论点。

00:13:15.075 --> 00:13:18.030
这里有几个例子，

00:13:18.030 --> 00:13:22.545
嗯，那个，嗯，从西班牙语到英语。

00:13:22.545 --> 00:13:27.660
所以在西班牙语中，你可以自由地去掉动词的主语和这些句子，

00:13:27.660 --> 00:13:29.520
在“因为”条款中，

00:13:29.520 --> 00:13:31.725
没有公开的话题。

00:13:31.725 --> 00:13:35.625
所以他让艾丽西娅喜欢胡安，因为他很聪明。

00:13:35.625 --> 00:13:40.620
所以谷歌翻译被困在一个HE中，这是对的。

00:13:40.620 --> 00:13:42.600
为了坚持他，

00:13:42.600 --> 00:13:47.700
它含蓄地做了一个相互参照的决定并说，“好吧，

00:13:47.700 --> 00:13:49.605
这个主题，嗯，

00:13:49.605 --> 00:13:54.224
形容词smart应该是juan，他是男性，

00:13:54.224 --> 00:13:56.985
因此，我应该说他。”

00:13:56.985 --> 00:14:00.060
但是，你知道，事实是谷歌翻译知道

00:14:00.060 --> 00:14:03.615
关于共指代和做出这些共指代的决定。

00:14:03.615 --> 00:14:05.280
和以前一样，嗯，

00:14:05.280 --> 00:14:10.365
现在在媒体上有点报道，我想是上早班的时候，

00:14:10.365 --> 00:14:15.240
嗯，谷歌翻译主要是默认为男性默认。

00:14:15.240 --> 00:14:18.075
嗯，所以如果你换了-扫了，呃，

00:14:18.075 --> 00:14:19.770
如果你把它翻过来说，

00:14:19.770 --> 00:14:23.370
胡安喜欢艾丽西娅，这也说明他很聪明。

00:14:23.370 --> 00:14:28.005
呃，也许应该是因为她很聪明。

00:14:28.005 --> 00:14:31.755
事实上，你会注意到这一切带来的不良影响。

00:14:31.755 --> 00:14:36.225
很多语言，嗯，土耳其语，印度尼西亚语，嗯，

00:14:36.225 --> 00:14:38.070
实际上没有性别，

00:14:38.070 --> 00:14:41.910
所以他们的性别歧视语言比英语少得多，

00:14:41.910 --> 00:14:43.350
法国或德国是。

00:14:43.350 --> 00:14:45.495
但是发生了什么，嗯，

00:14:45.495 --> 00:14:48.060
当你翻译你刚刚拥有的

00:14:48.060 --> 00:14:52.275
泛指第三人称代词，嗯，

00:14:52.275 --> 00:14:56.460
谷歌翻译基本上是在使用它的语言模型，

00:14:56.460 --> 00:14:59.055
这意味着重建，嗯，

00:14:59.055 --> 00:15:01.635
她最坏的成见是当厨师，

00:15:01.635 --> 00:15:03.855
他是一名工程师，一名医生。

00:15:03.855 --> 00:15:07.500
好吧，在这门课的一个连接部分，

00:15:07.500 --> 00:15:10.905
如果你希望谷歌翻译能够做得更好，

00:15:10.905 --> 00:15:14.160
再说一次，你需要做的是

00:15:14.160 --> 00:15:19.755
参考解析，并跟踪文本中的参与者。

00:15:19.755 --> 00:15:23.970
嗯，最后一个例子我们还没有真正讨论过，

00:15:23.970 --> 00:15:27.480
但是我们很快就会回来，因为课快结束了

00:15:27.480 --> 00:15:31.440
正在使用对话代理或聊天系统进行操作。

00:15:31.440 --> 00:15:36.240
一旦你要做的不仅仅是一个转弯，

00:15:36.240 --> 00:15:39.840
嗯，对话，你需要开始处理参考资料。

00:15:39.840 --> 00:15:41.655
所以如果你有，嗯，

00:15:41.655 --> 00:15:44.115
预定了看詹姆斯·邦德的票，

00:15:44.115 --> 00:15:46.200
嗯，那你想说点什么，

00:15:46.200 --> 00:15:49.050
“幽灵今天2:00和3:00在你附近玩耍。

00:15:49.050 --> 00:15:51.030
你想要几张票？”

00:15:51.030 --> 00:15:54.270
嗯，三点有两张演出的票。

00:15:54.270 --> 00:15:56.265
如颜色所示，

00:15:56.265 --> 00:16:02.340
这里有各种各样的参考文献，都有相关的参考文献，

00:16:02.340 --> 00:16:04.680
但这里有点复杂。

00:16:04.680 --> 00:16:07.470
这是我们稍后会讨论的问题。

00:16:07.470 --> 00:16:13.035
所以詹姆斯·邦德和幽灵显然不是一回事，

00:16:13.035 --> 00:16:16.530
但是在一个像预订电影这样的背景下，

00:16:16.530 --> 00:16:23.460
它们是一样的，因为一个是电影系列中一个角色的名字，

00:16:23.460 --> 00:16:28.530
另一个是目前正在上映的电影的名字，

00:16:28.530 --> 00:16:30.960
所以他们是有关联的，嗯，

00:16:30.960 --> 00:16:33.900
在某种微妙的方式，这不是确切的身份，

00:16:33.900 --> 00:16:37.125
但与我们想做的很多事情有关。

00:16:37.125 --> 00:16:39.480
等我们回来再谈

00:16:39.480 --> 00:16:41.655
再多谈谈这方面的语言学。

00:16:41.655 --> 00:16:45.760
可以。所以如果我们要做共指消解的任务，

00:16:45.760 --> 00:16:47.660
基本上有两个步骤。

00:16:47.660 --> 00:16:51.425
所以第一步是，我们要解决

00:16:51.425 --> 00:16:55.835
文中提到我们应该做些什么。

00:16:55.835 --> 00:16:58.640
这一个其实很简单，

00:16:58.640 --> 00:17:01.430
但我马上就要几张幻灯片。

00:17:01.430 --> 00:17:04.835
然后大部分的课程都是，

00:17:04.835 --> 00:17:08.810
嗯，计算出两次提及之间的相互参照。

00:17:08.810 --> 00:17:10.400
如果你想到这个，

00:17:10.400 --> 00:17:13.355
协同引用本质上是一个集群任务。

00:17:13.355 --> 00:17:15.275
因为如果你做第一件事，

00:17:15.275 --> 00:17:18.770
你有一系列的提到，然后你想说的很好，

00:17:18.770 --> 00:17:22.710
如何将它们分组为具有相同引用的集群？

00:17:22.710 --> 00:17:25.750
这就是我们要做的。

00:17:25.750 --> 00:17:28.080
这么快就提到检测。

00:17:28.080 --> 00:17:29.730
所以，嗯，举个例子，

00:17:29.730 --> 00:17:34.085
我们要找到所有的跨度，

00:17:34.085 --> 00:17:36.110
嗯，指的是某个实体。

00:17:36.110 --> 00:17:38.725
这些问题的答案，嗯，

00:17:38.725 --> 00:17:43.620
考生基本上都是课文中的名词短语。

00:17:43.620 --> 00:17:48.125
所以通常人们认为有三种类型的提到，我们确定。

00:17:48.125 --> 00:17:49.730
有代词，我，

00:17:49.730 --> 00:17:50.990
你，他，她，它，

00:17:50.990 --> 00:17:52.790
等等，也就是说，嗯，

00:17:52.790 --> 00:17:54.605
指不同的实体。

00:17:54.605 --> 00:17:57.170
他们是那种人的直白名字

00:17:57.170 --> 00:17:59.960
巴拉克·奥巴马和希拉里·克林顿的例子。

00:17:59.960 --> 00:18:02.210
还有许多棘手的例子，

00:18:02.210 --> 00:18:04.685
当我们有普通名词短语时

00:18:04.685 --> 00:18:07.670
像狗或大毛绒猫卡在树上。

00:18:07.670 --> 00:18:11.690
提到那只粘在树上的毛绒大猫。

00:18:11.690 --> 00:18:14.405
嗯，这实际上是一个复杂的问题，因为

00:18:14.405 --> 00:18:17.975
也嵌入了它的其他提到。

00:18:17.975 --> 00:18:22.230
嗯，所以这棵树也被提到了。

00:18:22.500 --> 00:18:26.560
可以。那么，我们如何检测提到的内容呢？

00:18:26.560 --> 00:18:28.180
一个答案是，

00:18:28.180 --> 00:18:30.055
我们已经看过了，嗯，

00:18:30.055 --> 00:18:32.740
各种其他NLP系统打开和关闭。

00:18:32.740 --> 00:18:39.250
我们可以使用这些NLP系统作为预处理系统来查找引用。

00:18:39.250 --> 00:18:43.900
所以对于代词来说，它们是说什么是名词的语言标记的一部分，

00:18:43.900 --> 00:18:45.475
或动词或代词，

00:18:45.475 --> 00:18:48.910
所以我们可以运行这些，找到所有的代词，我们就完成了。

00:18:48.910 --> 00:18:52.180
从-到，嗯，像巴拉克奥巴马这样的人的名字。

00:18:52.180 --> 00:18:54.970
我们已经讨论过几次命名实体识别器，

00:18:54.970 --> 00:18:57.730
所以我们可以运行这些并找到所有命名的实体。

00:18:57.730 --> 00:19:00.475
嗯，那么对于普通名词短语，

00:19:00.475 --> 00:19:03.400
这就是我们需要解析器找到的地方

00:19:03.400 --> 00:19:06.925
句子的结构，找出名词短语的位置。

00:19:06.925 --> 00:19:09.745
我们已经讨论了依赖性解析器，

00:19:09.745 --> 00:19:14.380
一种选择是，您可以使用依赖性解析器来查找名义参数，

00:19:14.380 --> 00:19:15.670
和他们一起工作。

00:19:15.670 --> 00:19:19.180
实际上，这有点微妙，而不仅仅是想挑选

00:19:19.180 --> 00:19:22.525
指常见名词短语的跨距。

00:19:22.525 --> 00:19:25.855
所以我们回到解析的另一个概念，

00:19:25.855 --> 00:19:28.150
嗯，下周是选区分析。

00:19:28.150 --> 00:19:30.280
从某种意义上讲，选民分析者

00:19:30.280 --> 00:19:34.465
找到这个过程中提到的最简单的方法。

00:19:34.465 --> 00:19:39.310
嗯，大部分看起来很容易，

00:19:39.310 --> 00:19:44.200
嗯，有一些棘手的案例可以算作是提还是不提。

00:19:44.200 --> 00:19:47.785
如果天气晴朗的话，

00:19:47.785 --> 00:19:49.975
我的意思是，这是一个提到什么？

00:19:49.975 --> 00:19:51.880
似乎不是真的，

00:19:51.880 --> 00:19:55.870
只是你似乎坚持在句子的开头，

00:19:55.870 --> 00:19:57.340
嗯，那没什么意义。

00:19:57.340 --> 00:19:59.215
所以这也许不是什么。

00:19:59.215 --> 00:20:00.730
嗯，每个学生。

00:20:00.730 --> 00:20:02.695
每个学生都有提到吗？

00:20:02.695 --> 00:20:07.810
我的意思是，它当然，充其量是某种集体，

00:20:07.810 --> 00:20:11.965
嗯，但这不是一个非常明确的具体参考，嗯。

00:20:11.965 --> 00:20:15.520
更进一步，如果我使用不同的量词，

00:20:15.520 --> 00:20:17.920
所以如果是这样的话，每一个都叫做量词。

00:20:17.920 --> 00:20:21.070
我是说没有学生绝对没有参考资料，

00:20:21.070 --> 00:20:23.560
因为它没有指向任何东西，对吗？

00:20:23.560 --> 00:20:25.990
它声称一种不存在的主张。

00:20:25.990 --> 00:20:28.015
所以肯定有，嗯，

00:20:28.015 --> 00:20:31.090
不-没提什么。

00:20:31.090 --> 00:20:34.420
嗯，是的，世界上最好的甜甜圈。

00:20:34.420 --> 00:20:37.675
嗯，有参考资料吗？

00:20:37.675 --> 00:20:40.125
嗯，还不清楚。

00:20:40.125 --> 00:20:44.460
这就是语言哲学家们争论的问题，对吧？

00:20:44.460 --> 00:20:48.315
所以如果世界上最好的甜甜圈是什么达成一致的话，

00:20:48.315 --> 00:20:50.535
也许有参考，嗯，

00:20:50.535 --> 00:20:52.815
但我可以说这样的句子，

00:20:52.815 --> 00:20:56.130
我到处寻找世界上最好的甜甜圈。

00:20:56.130 --> 00:20:57.960
然后在那句话里，

00:20:57.960 --> 00:20:59.340
它没有任何参考资料，对吧？

00:20:59.340 --> 00:21:03.975
这是对我希望找到的东西的有意描述，

00:21:03.975 --> 00:21:06.995
它没有具体的含义。

00:21:06.995 --> 00:21:11.605
嗯，数量之类的东西，100英里。

00:21:11.605 --> 00:21:14.170
这种行为就像名词短语，

00:21:14.170 --> 00:21:17.995
但它是在——它实际上是一个没有参考价值的量。

00:21:17.995 --> 00:21:23.200
嗯，那么问题是你如何处理这些东西？

00:21:23.200 --> 00:21:27.355
嗯，嗯，嗯，我们的工具，每当我们想处理东西的时候，

00:21:27.355 --> 00:21:30.265
我们是在训练分类器吗？

00:21:30.265 --> 00:21:34.150
就像他们挑选被提到的和没有被提到的。

00:21:34.150 --> 00:21:38.800
所以你可以做的就是写一个过滤掉的分类器，

00:21:38.800 --> 00:21:42.940
嗯，你想说的这些虚假的话没有提到。

00:21:42.940 --> 00:21:44.980
人们绝对做到了。

00:21:44.980 --> 00:21:47.650
但通常人们会跳过这一步，

00:21:47.650 --> 00:21:54.295
你只是让你的提词检测器找到所有的候选提词。

00:21:54.295 --> 00:21:57.610
因为事实证明这种方法很有效。

00:21:57.610 --> 00:22:01.510
因为在我们找到所有提到的事情之后，嗯，

00:22:01.510 --> 00:22:05.815
然后，我们将进行这个集群过程，以找到相关的引用。

00:22:05.815 --> 00:22:08.440
如果只是有一些零散的提到，比如

00:22:08.440 --> 00:22:12.655
没有学生，我们不会错误地把他们和其他东西聚集在一起，

00:22:12.655 --> 00:22:18.490
它不会造成任何伤害，因为我们主要参与这个集群过程。

00:22:18.490 --> 00:22:23.440
可以。嗯，你可能想知道的是，

00:22:23.440 --> 00:22:25.090
我现在有点暗示，

00:22:25.090 --> 00:22:26.605
我们有一条管道。

00:22:26.605 --> 00:22:29.770
我是说我们要做一个演讲记录，

00:22:29.770 --> 00:22:31.810
我们将运行一个命名实体识别器，

00:22:31.810 --> 00:22:33.265
我们将运行一个解析器。

00:22:33.265 --> 00:22:35.455
我们要运行一个，嗯，

00:22:35.455 --> 00:22:38.185
一个命名的提及检测器。

00:22:38.185 --> 00:22:41.530
最后，我们要运行这个coref集群系统，

00:22:41.530 --> 00:22:44.290
所以我们有一个五步的管道。

00:22:44.290 --> 00:22:50.950
嗯，这是你唯一能做到的方法吗，嗯，共指消解？

00:22:50.950 --> 00:22:53.020
传统的答案是对的，

00:22:53.020 --> 00:22:55.030
这就是你做共指消解的方式。

00:22:55.030 --> 00:22:59.275
基本上，所有的共指消解系统，

00:22:59.275 --> 00:23:05.800
直到大约2016年，一条管道经过了这些阶段。

00:23:05.800 --> 00:23:09.735
嗯，但就在最近，我将讨论一个这样的系统，

00:23:09.735 --> 00:23:12.180
嗯，在课后，嗯，

00:23:12.180 --> 00:23:15.570
神经世界的人已经开始做

00:23:15.570 --> 00:23:19.560
在神经网络世界的很多地方有效的说，

00:23:19.560 --> 00:23:22.815
我们能建立一个端到端的引用系统吗？

00:23:22.815 --> 00:23:26.385
从一个段落的纯文本开始，

00:23:26.385 --> 00:23:33.685
并且在没有任何干预管道步骤的情况下输出引用集群？

00:23:33.685 --> 00:23:36.625
我会告诉你更多关于这是如何工作的。

00:23:36.625 --> 00:23:40.090
但是在我们进入系统之前，

00:23:40.090 --> 00:23:45.220
我只想多说一点关于共指语言学的内容。

00:23:45.220 --> 00:23:49.570
嗯，实际上这里有很多有趣的东西，

00:23:49.570 --> 00:23:52.360
公平地说，

00:23:52.360 --> 00:23:55.810
其实并不是人们所想的

00:23:55.810 --> 00:23:59.065
很多人都在构建NLP系统，对吧？

00:23:59.065 --> 00:24:01.150
我已经说过了，嗯，

00:24:01.150 --> 00:24:03.505
从Shruthi Rao的故事中，

00:24:03.505 --> 00:24:06.250
分裂前因的例子，对吗？

00:24:06.250 --> 00:24:09.969
这只是一个明显的语言现象，

00:24:09.969 --> 00:24:12.160
它甚至不罕见，对吧？

00:24:12.160 --> 00:24:14.095
嗯，那，你知道，嗯，

00:24:14.095 --> 00:24:19.585
人们建立了这些简单的机器学习模型，但不能解决这个问题。

00:24:19.585 --> 00:24:22.630
而且确实有相当多的结构

00:24:22.630 --> 00:24:25.750
在共指语言学中发生了什么，

00:24:25.750 --> 00:24:30.280
在人们构建的大多数系统中，它并没有真正被利用。

00:24:30.280 --> 00:24:33.145
所以我只想让大家多看一点。

00:24:33.145 --> 00:24:38.200
基本上，为了理解，嗯，

00:24:38.200 --> 00:24:41.095
关于人们如何从语言上看待事物的更多信息，

00:24:41.095 --> 00:24:46.945
有两个概念是相关的，并且通常混淆了，

00:24:46.945 --> 00:24:48.370
这真的很不一样。

00:24:48.370 --> 00:24:50.635
所以一个是共指。

00:24:50.635 --> 00:24:54.700
所以我们说当有

00:24:54.700 --> 00:24:59.230
两次提及，它们指的是世界上的同一个实体。

00:24:59.230 --> 00:25:00.970
如果是这样的话，

00:25:00.970 --> 00:25:05.140
嗯，唐纳德·特朗普和现任总统，对吗？

00:25:05.140 --> 00:25:09.205
他们是两个被提及的人，他们指的是世界上的同一个人。

00:25:09.205 --> 00:25:12.190
所以这是一个相互参照的关系。

00:25:12.190 --> 00:25:16.345
嗯，然后和回指形成对比。

00:25:16.345 --> 00:25:24.595
因此，回指的概念是文本中的某些术语没有独立的参照物，

00:25:24.595 --> 00:25:30.835
你通过把它们和课文中的另一件事联系起来，得出它们的参考。

00:25:30.835 --> 00:25:32.800
所以如果我们有这个句子，

00:25:32.800 --> 00:25:35.500
奥巴马说他将签署这项法案。

00:25:35.500 --> 00:25:37.225
他是个回指。

00:25:37.225 --> 00:25:39.430
如果我说，他，

00:25:39.430 --> 00:25:41.905
他在摘要中指的是什么？

00:25:41.905 --> 00:25:45.775
嗯，你知道，除了说些男人的话，对吧？

00:25:45.775 --> 00:25:47.050
你不知道，对吧？

00:25:47.050 --> 00:25:50.110
因为你不能仅仅通过了解他就知道他的意思。

00:25:50.110 --> 00:25:54.370
你必须看一个文本，并根据文本来解释它。

00:25:54.370 --> 00:25:56.515
如果你要解释的话，

00:25:56.515 --> 00:25:58.795
嗯，相对于文本，

00:25:58.795 --> 00:26:00.370
你现在的处境是，

00:26:00.370 --> 00:26:03.880
好吧，我明白了，这是指巴拉克奥巴马。

00:26:03.880 --> 00:26:07.600
所以他又提到了奥巴马，

00:26:07.600 --> 00:26:10.915
这就是回指的概念。

00:26:10.915 --> 00:26:13.615
所以我们的照片是这样的，

00:26:13.615 --> 00:26:17.635
你可以有这些独立的提到，

00:26:17.635 --> 00:26:19.690
也就是说，嗯，

00:26:19.690 --> 00:26:21.310
为了世界上同样的事情。

00:26:21.310 --> 00:26:22.765
它们是共指。

00:26:22.765 --> 00:26:24.580
但在很多情况下，

00:26:24.580 --> 00:26:27.969
比如当他们像奥巴马总统那样被充分提及时，

00:26:27.969 --> 00:26:31.990
与巴拉克奥巴马相比，他们没有任何文本关系。

00:26:31.990 --> 00:26:35.455
只是他们碰巧提到了世界上相同的事情。

00:26:35.455 --> 00:26:40.825
这与巴拉克·奥巴马（Barack Obama）所说的情况形成了鲜明对比，

00:26:40.825 --> 00:26:45.265
他和巴拉克·奥巴马有着文本关系。

00:26:45.265 --> 00:26:47.530
这就是回指的例子。

00:26:47.530 --> 00:26:54.985
嗯，到目前为止，这可能是一个几乎毫无意义的区别。

00:26:54.985 --> 00:26:59.425
但有些东西可能会让你觉得这里有一些有用的东西，

00:26:59.425 --> 00:27:04.420
嗯，即使没有相互参照，这些文本关系也存在。

00:27:04.420 --> 00:27:06.790
所以我们之前提到过，

00:27:06.790 --> 00:27:09.430
这种情况就像没有舞者，对吧？

00:27:09.430 --> 00:27:12.610
所以没有舞者没有参考，对吧？

00:27:12.610 --> 00:27:14.305
它什么也没有。

00:27:14.305 --> 00:27:16.810
但是如果你有这样的句子，

00:27:16.810 --> 00:27:22.615
“没有舞者扭伤了膝盖，”好吧，我们这里有个回指。

00:27:22.615 --> 00:27:26.260
那个回指的是“不”

00:27:26.260 --> 00:27:30.520
“舞者”尽管“没有舞者”没有参考。

00:27:30.520 --> 00:27:34.150
所以我们仍然可以有回指的文本关系。

00:27:34.150 --> 00:27:36.070
事实上，你知道，

00:27:36.070 --> 00:27:39.280
她的膝盖是她的一部分。

00:27:39.280 --> 00:27:42.040
所以这又是部分关系。

00:27:42.040 --> 00:27:45.370
但她的膝盖，从某种意义上说，我会回来，

00:27:45.370 --> 00:27:51.325
也是一个回指，它被解释为尊重，嗯，舞者。

00:27:51.325 --> 00:27:54.370
所以我们这里有两个回指关系，

00:27:54.370 --> 00:27:57.250
即使我们没有参考资料。

00:27:57.250 --> 00:28:00.865
还有一个有趣的例子

00:28:00.865 --> 00:28:04.795
回指关系与参考不一样，

00:28:04.795 --> 00:28:08.380
也就是说，你可以有更松散的回指关系。

00:28:08.380 --> 00:28:10.810
所以你会有很多这样的句子。

00:28:10.810 --> 00:28:13.135
“我们昨晚去看了一场音乐会，

00:28:13.135 --> 00:28:15.250
门票真的很贵。”

00:28:15.250 --> 00:28:18.925
所以我们在这里提到了这些票。

00:28:18.925 --> 00:28:22.465
嗯，但实际上是为了解释门票，

00:28:22.465 --> 00:28:26.995
我们必须对它们进行解释，

00:28:26.995 --> 00:28:28.735
嗯，在后面提到，

00:28:28.735 --> 00:28:31.465
一个概念，因为实际上这是在说，

00:28:31.465 --> 00:28:35.095
音乐会的票真的很贵。

00:28:35.095 --> 00:28:39.205
所以这也被称为回指关系，

00:28:39.205 --> 00:28:42.190
如果必须解释门票的含义

00:28:42.190 --> 00:28:46.600
基于另一个，嗯，名词短语。

00:28:46.600 --> 00:28:49.690
但这不是一种共指关系

00:28:49.690 --> 00:28:53.335
音乐会和门票显然是两个不同的实体。

00:28:53.335 --> 00:28:56.979
所以这些比较宽松的案例被称为桥接回指，

00:28:56.979 --> 00:29:00.805
因为你得为自己提供桥梁，

00:29:00.805 --> 00:29:07.105
连接先行词和回指词的关系。

00:29:07.105 --> 00:29:10.780
可以。这就是为什么-然后我们有这些照片，

00:29:10.780 --> 00:29:14.890
我们有这种不完全的交叉

00:29:14.890 --> 00:29:19.510
在我们讨论过的共指和回指之间。

00:29:19.510 --> 00:29:24.200
嗯，我还有一个关于回指的笔记。嗯，

00:29:24.200 --> 00:29:28.825
谁——这里有人做过古希腊语吗？

00:29:28.825 --> 00:29:34.020
有古希腊语吗？[笑声]是的。

00:29:34.020 --> 00:29:36.035
可以。嗯，那么，嗯，

00:29:36.035 --> 00:29:40.745
从回指词的起源来看，

00:29:40.745 --> 00:29:47.135
回指是指你在你面前找到你的参考文献。

00:29:47.135 --> 00:29:53.300
嗯，实际上有一个互补的，嗯，

00:29:53.300 --> 00:29:56.940
艺术术语，简称

00:29:56.940 --> 00:30:02.140
你在那里找到你的参考。

00:30:02.140 --> 00:30:05.700
嗯，这是一个漂亮的回指例子。

00:30:05.700 --> 00:30:07.380
这是奥斯卡王尔德的作品，

00:30:07.380 --> 00:30:09.330
多里安·格雷的照片。

00:30:09.330 --> 00:30:14.339
“从他躺着的波斯马鞍袋沙发床的一角，

00:30:14.339 --> 00:30:16.620
吸烟，这是他的习惯，

00:30:16.620 --> 00:30:20.690
无数的香烟，亨利·沃顿勋爵正好能抓住

00:30:20.690 --> 00:30:25.470
蜂蜜的微光，又甜又蜜的花，是拉布农的花。

00:30:25.470 --> 00:30:28.865
嗯，对。这里我们有这个，嗯，提到过，

00:30:28.865 --> 00:30:33.060
亨利·沃顿勋爵还有两个回指，

00:30:33.060 --> 00:30:35.940
嗯，那是指亨利·沃顿勋爵。

00:30:35.940 --> 00:30:39.300
嗯，他和他的，

00:30:39.300 --> 00:30:41.730
他们都是先来的，

00:30:41.730 --> 00:30:43.995
嗯，亨利·沃顿勋爵。

00:30:43.995 --> 00:30:47.010
所以这些是指，嗯，

00:30:47.010 --> 00:30:53.670
作为某一类古典学者的回指例子。

00:30:53.670 --> 00:30:56.460
嗯，如果你不知道拉布努姆是什么，

00:30:56.460 --> 00:30:58.680
嗯，这是一个laburnum。

00:30:58.680 --> 00:31:01.890
[笑声]是的。但是，是的，

00:31:01.890 --> 00:31:03.365
所以这是回指。

00:31:03.365 --> 00:31:05.940
现在-现在有两件可悲的事要说。

00:31:05.940 --> 00:31:09.630
嗯，第一件可悲的事是现代语言学，

00:31:09.630 --> 00:31:12.375
这个词完全不用了。

00:31:12.375 --> 00:31:18.185
我们的意思是-我们只是用了“嗯”这个词，到处都是回指的意思

00:31:18.185 --> 00:31:21.300
从中的其他提到中引用的词。

00:31:21.300 --> 00:31:24.525
文本和它在哪边都不重要。

00:31:24.525 --> 00:31:28.560
嗯，那么，嗯，我们走下坡一个阶段

00:31:28.560 --> 00:31:34.055
语言学，但然后我们到了NLP，我们走下坡第二阶段。

00:31:34.055 --> 00:31:38.160
因为总的来说你会看到，

00:31:38.160 --> 00:31:40.485
人们正在建立的系统，

00:31:40.485 --> 00:31:47.355
嗯，参考分辨率，它们根本不区分方向。

00:31:47.355 --> 00:31:49.155
一旦你发现有人提到，

00:31:49.155 --> 00:31:52.230
你总是在寻找它的参考。

00:31:52.230 --> 00:31:54.875
嗯，你不知道，

00:31:54.875 --> 00:31:57.630
嗯，也许有时候你可以向前看。

00:31:57.630 --> 00:31:59.280
实际上，这意味着什么，

00:31:59.280 --> 00:32:01.370
系统最终会这样说，

00:32:01.370 --> 00:32:02.930
嗯，这里有个他，

00:32:02.930 --> 00:32:05.955
还有很多其他的东西，还有他的，等等。

00:32:05.955 --> 00:32:09.650
你最终会找到亨利·沃顿勋爵

00:32:09.650 --> 00:32:13.995
试图通过向后看找到它的参考资料，

00:32:13.995 --> 00:32:17.760
尽管这是由任何一种语言意义造成的。

00:32:17.760 --> 00:32:22.305
而实际上，他和他的那个人应该一直在寻找他们的前车之鉴。

00:32:22.305 --> 00:32:29.140
可以。嗯，大家都准备好了吗，有问题吗？

00:32:29.840 --> 00:32:34.110
可以。我们会继续前进，嗯，

00:32:34.110 --> 00:32:38.610
试着继续讨论各种共指，嗯，模型。

00:32:38.610 --> 00:32:41.715
所以我想，嗯，告诉你，嗯，

00:32:41.715 --> 00:32:45.300
尽我所能，我有45分钟，嗯，

00:32:45.300 --> 00:32:49.055
离开了，所以有点像人们用相互参照建立的模型。

00:32:49.055 --> 00:32:53.670
我希望能很快地提到四种不同的方式，即人们看待共指的方式。

00:32:53.670 --> 00:32:57.800
我想告诉你一点点关于基于规则的经典共指。

00:32:57.800 --> 00:33:02.010
嗯，那么，嗯，提及对共指。

00:33:02.010 --> 00:33:04.930
将大部分时间花在提到排名系统上

00:33:04.930 --> 00:33:07.995
往往是最简单的系统。

00:33:07.995 --> 00:33:09.580
然后说一点

00:33:09.580 --> 00:33:12.780
集群系统应该是正确的方法

00:33:12.780 --> 00:33:18.150
但实际上，这是一种很难获得最佳性能的方法。

00:33:18.150 --> 00:33:20.900
可以。这是一段历史。

00:33:20.900 --> 00:33:22.980
嗯，这家伙是杰里·霍布斯。

00:33:22.980 --> 00:33:28.320
上个月他刚从南加州大学举办了退休派对。

00:33:28.320 --> 00:33:29.670
嗯，那么杰里·霍布斯，

00:33:29.670 --> 00:33:31.815
回来的时候，嗯，

00:33:31.815 --> 00:33:33.660
写了一篇著名的论文，

00:33:33.660 --> 00:33:37.905
这是1976年关于共指决议的。

00:33:37.905 --> 00:33:41.520
在那篇论文中，他提议，

00:33:41.520 --> 00:33:45.600
嗯，现在通常所说的霍布斯算法。

00:33:45.600 --> 00:33:47.895
但实际上，在他的论文中，

00:33:47.895 --> 00:33:51.180
他称之为一种幼稚的算法。

00:33:51.180 --> 00:33:54.680
嗯，我马上就要回到这一点上。

00:33:54.680 --> 00:33:57.630
但是霍布斯算法是，

00:33:57.630 --> 00:34:01.980
如果你有一个句子-所以实际上我应该这么说，

00:34:01.980 --> 00:34:05.430
这个算法只是为了寻找代词的参考。

00:34:05.430 --> 00:34:08.500
所以可以延伸到其他案例，但我要展示的部分

00:34:08.500 --> 00:34:11.760
你只是做代词参考的部分。

00:34:11.760 --> 00:34:12.935
所以当你发现

00:34:12.935 --> 00:34:17.925
找一个代词，你想说它是什么，嗯，共指？

00:34:17.925 --> 00:34:22.700
你要做的是运行这个机械算法

00:34:22.700 --> 00:34:27.945
这是一个句子的语法分析，并正在研究如何处理它。

00:34:27.945 --> 00:34:30.824
从控制代词的np开始，

00:34:30.824 --> 00:34:35.325
到树上或第一个np或s。称这个x和路径p，

00:34:35.325 --> 00:34:37.760
横穿过去，啊，它继续前进。

00:34:37.760 --> 00:34:39.015
嗯，还有更多。

00:34:39.015 --> 00:34:40.110
那只是开始。

00:34:40.110 --> 00:34:41.475
还有很多阶段。

00:34:41.475 --> 00:34:43.230
但是，你知道，

00:34:43.230 --> 00:34:46.890
我不是-我真的不想谈这个细节。

00:34:46.890 --> 00:34:50.070
嗯，但是，你知道，试着解释一下它的味道，

00:34:50.070 --> 00:34:51.665
这是一段文字。

00:34:51.665 --> 00:34:53.980
“尼尔·弗格森多产，

00:34:53.980 --> 00:34:56.220
薪水高，衣橱也很时髦。

00:34:56.220 --> 00:34:58.395
史蒂芬·莫斯恨他。”

00:34:58.395 --> 00:35:02.854
如果你能记住算法的任何步骤，

00:35:02.854 --> 00:35:06.275
这是我们的，嗯，发音他。

00:35:06.275 --> 00:35:11.535
嗯，然后，它说要做的就是从NP开始，

00:35:11.535 --> 00:35:14.210
代词上的名词短语。

00:35:14.210 --> 00:35:19.010
然后它说，到上面的第一个名词短语，

00:35:19.010 --> 00:35:21.370
嗯，这是上面的S。

00:35:21.370 --> 00:35:24.765
嗯，然后你要做的就是，从那里，

00:35:24.765 --> 00:35:30.185
你应该从左到右穿过之前的东西。

00:35:30.185 --> 00:35:32.980
所以这个手写算法很聪明。

00:35:32.980 --> 00:35:36.440
你知道，这是在智能手写算法的领域。

00:35:36.440 --> 00:35:40.140
所以这反映的是你可能只是在想你

00:35:40.140 --> 00:35:44.045
应该去最近的地方寻找参考，

00:35:44.045 --> 00:35:48.735
但事实上，如果你在同一句话中有引用，

00:35:48.735 --> 00:35:51.730
这种情况比较常见

00:35:51.730 --> 00:35:56.085
最高的句法角色就是你所共指的。

00:35:56.085 --> 00:35:59.780
所以你更可能和一个主题而不是一个对象有共同的参照关系，

00:35:59.780 --> 00:36:03.760
你更可能与一个物体相互参照，而不是像

00:36:03.760 --> 00:36:08.935
名词短语，位于宾语后的介词短语内。

00:36:08.935 --> 00:36:11.855
所以我们从左边开始

00:36:11.855 --> 00:36:14.710
这里有个名词短语，史蒂芬·莫斯。

00:36:14.710 --> 00:36:16.520
这是我们第一次来。

00:36:16.520 --> 00:36:20.265
然后有一段聪明的文字说，

00:36:20.265 --> 00:36:24.820
嗯，横向分支，嗯，在x下，

00:36:24.820 --> 00:36:27.080
从左到右，

00:36:27.080 --> 00:36:31.040
作为先行词和名词短语，嗯，

00:36:31.040 --> 00:36:37.220
它之间有一个名词短语或句子，在S中是一个EC，所以它是说，

00:36:37.220 --> 00:36:38.990
这将是一个候选人，

00:36:38.990 --> 00:36:40.520
如果且仅如果，

00:36:40.520 --> 00:36:44.345
中间还有其他名词短语。

00:36:44.345 --> 00:36:48.870
嗯，那就是说史蒂芬·莫斯恨他。

00:36:48.870 --> 00:36:52.210
他不能再提这个了

00:36:52.210 --> 00:36:55.830
史蒂芬·莫斯和那种几乎是英语句法的事实。

00:36:55.830 --> 00:37:00.090
但它想做的是区分，

00:37:00.090 --> 00:37:02.940
另一件我们本可以在这里得到的东西是

00:37:02.940 --> 00:37:09.100
包含另一个所有格名词短语的名词短语。

00:37:09.100 --> 00:37:17.595
嗯，如果我们像史蒂芬·莫斯的母亲那样讨厌他，对吗？

00:37:17.595 --> 00:37:22.620
那么史蒂芬的母亲——莫斯的母亲恨他，那么他会，

00:37:22.620 --> 00:37:28.055
在这种情况下，他和史蒂芬·莫斯是一个很好的朋友。

00:37:28.055 --> 00:37:31.120
算法允许这样做，因为相对于

00:37:31.120 --> 00:37:35.760
这个名词短语是它上面和中间的另一个名词短语。

00:37:35.760 --> 00:37:38.205
可以。所以没用，嗯，

00:37:38.205 --> 00:37:40.740
作为一个前因-作为一个前因，

00:37:40.740 --> 00:37:43.415
然后我们进入算法的下一步。

00:37:43.415 --> 00:37:44.920
然后，下一步说，

00:37:44.920 --> 00:37:49.095
我们应该回顾前面的句子，

00:37:49.095 --> 00:37:50.595
嗯，从右到左。

00:37:50.595 --> 00:37:55.085
所以这捕捉到了一个重要的启发式，即接近实际上是

00:37:55.085 --> 00:37:58.085
找到共指代的一种很好的启发式方法

00:37:58.085 --> 00:38:02.115
因为代词的共指通常是靠整体接近的。

00:38:02.115 --> 00:38:05.055
所以我们回到第一句话。

00:38:05.055 --> 00:38:07.885
然后在这句话中，

00:38:07.885 --> 00:38:09.610
我们在句子里，

00:38:09.610 --> 00:38:13.335
从左到右走，因为有相同的主题突出角色。

00:38:13.335 --> 00:38:15.685
所以我们从这句话开始，

00:38:15.685 --> 00:38:16.990
我们会说好的，

00:38:16.990 --> 00:38:18.710
这是一个名词短语。

00:38:18.710 --> 00:38:21.315
现在因为我们的句子不同，

00:38:21.315 --> 00:38:23.360
这个没什么问题。

00:38:23.360 --> 00:38:24.725
所以我们说，啊哈，

00:38:24.725 --> 00:38:27.340
我们有一个候选人，尼尔·弗格森，

00:38:27.340 --> 00:38:32.385
嗯，是一个可能的先例，这是我们发现的第一个。

00:38:32.385 --> 00:38:35.700
因此，我们说他指的是尼尔·弗格森。

00:38:35.700 --> 00:38:38.640
这个算法给出了正确的答案，

00:38:38.640 --> 00:38:40.750
如果你能遵循所有这些。

00:38:40.750 --> 00:38:43.320
嗯，虽然听起来，嗯，

00:38:43.320 --> 00:38:47.020
可怕的手写材料。

00:38:47.020 --> 00:38:56.810
但是，嗯，所以杰里·霍布斯意识到这是可怕的手写材料，

00:38:56.810 --> 00:39:01.805
但他对这个算法感兴趣有几个原因。

00:39:01.805 --> 00:39:04.970
我是说，原因之一是，你知道，

00:39:04.970 --> 00:39:09.980
这实际上是自然语言处理的第一步，

00:39:09.980 --> 00:39:12.740
有人制作了基线，对吧。

00:39:12.740 --> 00:39:15.620
对于最终项目和其他地方，

00:39:15.620 --> 00:39:17.750
嗯，我们给你的东西，对吧，

00:39:17.750 --> 00:39:21.260
它现在出现在NLP和其他地区，

00:39:21.260 --> 00:39:22.490
你所做的一切，

00:39:22.490 --> 00:39:24.620
你应该做的第一件事就是有一个基线，

00:39:24.620 --> 00:39:27.440
一个简单的系统，看看它是如何工作的。

00:39:27.440 --> 00:39:31.955
这是他做共指的简单的基于规则的系统，

00:39:31.955 --> 00:39:36.575
嗯，他想观察一下，事实上这个基线很好。

00:39:36.575 --> 00:39:40.925
事实上，很多时候它都给出了正确的答案。

00:39:40.925 --> 00:39:47.360
因此，挑战在于如何构建一个比这个基线更好的系统。

00:39:47.360 --> 00:39:49.220
所以他很清楚，

00:39:49.220 --> 00:39:50.780
你知道，这是一个愚蠢的算法，

00:39:50.780 --> 00:39:55.580
但他提出这是做共指消解的一个很好的基线。

00:39:55.580 --> 00:39:57.920
所以他感兴趣的是，

00:39:57.920 --> 00:40:00.980
嗯，记住我们回到了70年代，

00:40:00.980 --> 00:40:06.860
是如何做基于知识的代词共指消解。

00:40:06.860 --> 00:40:12.250
所以，嗯，基本上他注意到的是，

00:40:12.250 --> 00:40:16.360
我提到的这些句法因素更喜欢主语，

00:40:16.360 --> 00:40:18.430
喜欢近在咫尺等，

00:40:18.430 --> 00:40:20.785
它们都是有用的预测器。

00:40:20.785 --> 00:40:23.830
但是很多情况下他们没有给出正确的答案，

00:40:23.830 --> 00:40:25.750
知道他们什么时候给予，什么时候给予，

00:40:25.750 --> 00:40:29.005
要知道什么才是真正的共同点，

00:40:29.005 --> 00:40:33.000
你必须真正理解世界上所描述的。

00:40:33.000 --> 00:40:35.105
所以如果我有这个句子，

00:40:35.105 --> 00:40:39.005
她把水罐里的水倒进杯子里，直到满了为止。

00:40:39.005 --> 00:40:41.700
它与什么有关联？

00:40:44.530 --> 00:40:45.740
杯子。

00:40:45.740 --> 00:40:46.700
[噪音]杯子。

00:40:46.700 --> 00:40:48.350
谢谢您。[笑声]好的。

00:40:48.350 --> 00:40:50.870
所以，它指的是杯子。

00:40:50.870 --> 00:40:53.225
但是让我们来看这个例子。

00:40:53.225 --> 00:40:57.530
她把水罐里的水倒进杯子里，直到杯子空了为止。

00:40:57.530 --> 00:40:59.375
它指的是什么？

00:40:59.375 --> 00:40:59.900
[重叠]。

00:40:59.900 --> 00:41:01.775
投手。[笑声]好的。

00:41:01.775 --> 00:41:06.125
所以在这两个句子中最重要的是，

00:41:06.125 --> 00:41:10.940
这些句子有相同的句法结构，对吧。

00:41:10.940 --> 00:41:15.695
所以杰里·霍布斯的算法不可能奏效，

00:41:15.695 --> 00:41:18.365
嗯，对于这两个句子。

00:41:18.365 --> 00:41:20.615
这对他们中的一个有用，

00:41:20.615 --> 00:41:22.550
但不是另一个。

00:41:22.550 --> 00:41:26.030
嗯，因为它在一个句子中从左到右工作，

00:41:26.030 --> 00:41:28.865
实际上，两次都会说投手，对吧。

00:41:28.865 --> 00:41:35.360
所以你不能通过杰里·霍布斯的算法得到正确的答案，杰里相信，

00:41:35.360 --> 00:41:37.415
仍然相信，嗯，

00:41:37.415 --> 00:41:40.475
只有这样才能让这些例子正确，

00:41:40.475 --> 00:41:43.415
如果你了解这个世界，

00:41:43.415 --> 00:41:46.640
你真的知道世界上发生了什么，

00:41:46.640 --> 00:41:49.040
所以你可以看到这是在说什么。

00:41:49.040 --> 00:41:51.020
有很多这样的例子。

00:41:51.020 --> 00:41:53.765
嗯，这是另一个非常著名的例子。

00:41:53.765 --> 00:41:58.310
市议会拒绝了妇女的许可证，因为她们害怕暴力。

00:41:58.310 --> 00:42:00.140
嗯，他们指的是谁？

00:42:00.140 --> 00:42:01.550
[听不见]。

00:42:01.550 --> 00:42:03.125
市议员们。

00:42:03.125 --> 00:42:05.360
嗯，但这是另一句话。

00:42:05.360 --> 00:42:10.415
市议会拒绝了妇女的许可，因为她们主张暴力。

00:42:10.415 --> 00:42:12.785
他们指的是谁？

00:42:12.785 --> 00:42:14.000
女人们。

00:42:14.000 --> 00:42:16.340
女人们。可以。所以这次是指女性。

00:42:16.340 --> 00:42:18.245
嗯，再说一遍，你知道，

00:42:18.245 --> 00:42:24.185
相同的句法结构，用霍布斯算法是不可能做到正确的。

00:42:24.185 --> 00:42:27.365
嗯，这对特殊的例子，

00:42:27.365 --> 00:42:29.270
嗯，来自特里·温诺格拉德。

00:42:29.270 --> 00:42:31.610
嗯，多久了，嗯，

00:42:31.610 --> 00:42:35.150
所以特里·温诺格拉德最初是一个全国人民党的教员，嗯，

00:42:35.150 --> 00:42:39.410
他对全国人民党的幻想有点破灭了，因为没有什么进展，嗯，

00:42:39.410 --> 00:42:42.065
冒险进入HCI的土地，

00:42:42.065 --> 00:42:43.880
嗯，那成了他的事业。

00:42:43.880 --> 00:42:46.250
但在他早期的工作中，

00:42:46.250 --> 00:42:48.109
他对这些现象很感兴趣，

00:42:48.109 --> 00:42:50.150
并提出了这个例子。

00:42:50.150 --> 00:42:52.955
所以这个例子真的很吸引人。

00:42:52.955 --> 00:42:56.030
所以这些对比被

00:42:56.030 --> 00:42:59.615
其他人如winograd句子或winograd模式。

00:42:59.615 --> 00:43:04.505
所以这实际上是一些有趣的东西，最近又重新出现了。

00:43:04.505 --> 00:43:07.190
嗯，赫克托·勒维斯基，嗯，

00:43:07.190 --> 00:43:09.875
我想五年前写了篇论文，

00:43:09.875 --> 00:43:14.030
他试图鼓吹重新开始做

00:43:14.030 --> 00:43:18.515
更多的是在知识、世界建模和人工智能方面，

00:43:18.515 --> 00:43:21.710
并且认为有很多问题你只是

00:43:21.710 --> 00:43:25.595
不能用那种粗糙的统计方法来解决，

00:43:25.595 --> 00:43:28.250
我们的机器学习系统正在使用。

00:43:28.250 --> 00:43:31.370
你真的需要做更多的世界了解。

00:43:31.370 --> 00:43:33.080
所以他提议

00:43:33.080 --> 00:43:38.240
这些Winograd模式将是图灵测试的一个很好的替代方案，

00:43:38.240 --> 00:43:40.760
作为衡量智力的一种方法。

00:43:40.760 --> 00:43:43.850
实际上，它们只是相互参照的决定，对吧。

00:43:43.850 --> 00:43:47.165
所以，嗯，这里有一种说法，

00:43:47.165 --> 00:43:50.675
如果你能百分之百地做一个相互参照，

00:43:50.675 --> 00:43:54.110
你已经解决了人工智能的问题，因为你是，差不多可以，

00:43:54.110 --> 00:43:58.745
能将世界知识编码成共指问题。

00:43:58.745 --> 00:44:04.010
嗯，是的，所以人们试图研究这些Winograd模式，

00:44:04.010 --> 00:44:07.070
莱夫斯基的感觉是，

00:44:07.070 --> 00:44:09.664
你就是做不到，

00:44:09.664 --> 00:44:11.240
嗯，使用某种，

00:44:11.240 --> 00:44:14.360
统计因素的种类，嗯，

00:44:14.360 --> 00:44:17.870
人们把它们放进机器学习系统。

00:44:17.870 --> 00:44:22.520
他在这方面有些错误，因为后来的工作，嗯，

00:44:22.520 --> 00:44:27.050
无论是神经系统还是其他系统都表明你可以

00:44:27.050 --> 00:44:32.165
用这些问题得到一个非常重要的距离，因为，你知道，

00:44:32.165 --> 00:44:33.709
如果是这样的话，

00:44:33.709 --> 00:44:35.270
嗯，你知道的，

00:44:35.270 --> 00:44:38.120
你可以看到足够多的例子，

00:44:38.120 --> 00:44:41.120
市议会拒绝许可的，

00:44:41.120 --> 00:44:42.755
你知道，害怕暴力。

00:44:42.755 --> 00:44:44.390
如果你走了-如果你在收集

00:44:44.390 --> 00:44:48.560
你的神经语言模型超过数百亿个单词，

00:44:48.560 --> 00:44:51.530
你可能见过这样的例子，

00:44:51.530 --> 00:44:54.845
你可以通过统计模式来预测。

00:44:54.845 --> 00:44:56.015
但问题是，你知道，

00:44:56.015 --> 00:44:58.340
你到底能走多远？

00:44:58.340 --> 00:45:00.605
没有更多的世界模式？

00:45:00.605 --> 00:45:02.030
所以，你知道，

00:45:02.030 --> 00:45:05.705
霍布斯在1978年对什么感兴趣。

00:45:05.705 --> 00:45:10.010
所以他写道，幼稚的方法是相当好的，

00:45:10.010 --> 00:45:14.809
从计算上讲，要实现基于语义的算法需要很长时间，

00:45:14.809 --> 00:45:17.585
足够老练的表演。

00:45:17.585 --> 00:45:21.650
这些结果为任何其他方法的目标设定了一个非常高的标准。

00:45:21.650 --> 00:45:23.990
他完全正确，嗯，

00:45:23.990 --> 00:45:28.655
直到20世纪10年代才有人

00:45:28.655 --> 00:45:33.830
设法产生一种代词回指消解算法，

00:45:33.830 --> 00:45:35.900
这比霍布斯算法好。

00:45:35.900 --> 00:45:38.420
即使只是，呃，

00:45:38.420 --> 00:45:40.535
他称之为幼稚的算法，

00:45:40.535 --> 00:45:44.000
或者他可以称之为一套粗糙的语言规则。

00:45:44.000 --> 00:45:46.325
但是他说，

00:45:46.325 --> 00:45:50.090
然而，有充分的理由去追求一种基于语义的方法，

00:45:50.090 --> 00:45:52.325
幼稚的算法不起作用。

00:45:52.325 --> 00:45:55.055
任何人都能想到失败的例子。

00:45:55.055 --> 00:45:57.409
在这些情况下，它不仅失败了，

00:45:57.409 --> 00:45:59.660
没有迹象表明它失败了，

00:45:59.660 --> 00:46:03.170
在寻找真正的前因方面没有任何帮助。

00:46:03.170 --> 00:46:05.510
嗯，所以这里是思考的食物。

00:46:05.510 --> 00:46:08.135
嗯，但是，嗯，尽管如此，

00:46:08.135 --> 00:46:10.400
我现在就冲过去，

00:46:10.400 --> 00:46:12.350
告诉你一些，嗯，

00:46:12.350 --> 00:46:14.450
统计和神经算法，

00:46:14.450 --> 00:46:17.120
嗯，这已经被用于共指消解。

00:46:17.120 --> 00:46:20.945
所以最简单的算法，通常使用，

00:46:20.945 --> 00:46:24.215
就是所谓的提到对模型。

00:46:24.215 --> 00:46:29.135
所以我们所说的配对模型是，嗯，

00:46:29.135 --> 00:46:32.030
我们会两次提到，

00:46:32.030 --> 00:46:36.110
我们要训练一个二元分类器，

00:46:36.110 --> 00:46:39.230
是指代还是不是指代。

00:46:39.230 --> 00:46:44.105
然后我们将从左到右通过文本。

00:46:44.105 --> 00:46:49.325
每次我们提到新的话题，

00:46:49.325 --> 00:46:55.895
然后我们将根据前面提到的每一个内容对分类器进行评估，

00:46:55.895 --> 00:46:58.835
我们要说的是，它们是共同的吗？

00:46:58.835 --> 00:47:01.235
它会说是或不是。

00:47:01.235 --> 00:47:03.500
我们会发现其中一些。

00:47:03.500 --> 00:47:06.155
它说是的，嗯，

00:47:06.155 --> 00:47:10.160
我投纳德尔的票是因为他和我的价值观一致。

00:47:10.160 --> 00:47:13.100
她说，如果我们有一个好的分类器，

00:47:13.100 --> 00:47:18.470
它会对两个蓝色的人说“是”，而不是对其他人说“是”。

00:47:18.470 --> 00:47:22.190
嗯，然后我们会在训练的时候，

00:47:22.190 --> 00:47:26.540
否定的例子说明纳德和他是否定的例子。

00:47:26.540 --> 00:47:30.860
[noise]所以如果你有标记为共指的数据，

00:47:30.860 --> 00:47:33.530
我们有一些正面和负面的例子，

00:47:33.530 --> 00:47:35.120
我们可以训练一个模特。

00:47:35.120 --> 00:47:36.980
为了训练一个模特，

00:47:36.980 --> 00:47:42.230
我们有一种分类器结果是1或0，

00:47:42.230 --> 00:47:45.665
基于两次提及是否相互参照。

00:47:45.665 --> 00:47:47.960
我们会有一个共指模型

00:47:47.960 --> 00:47:50.960
预测它们相互参照的概率。

00:47:50.960 --> 00:47:54.350
我们要用同样的交叉熵损失训练它，

00:47:54.350 --> 00:47:57.275
我们用过其他地方，嗯，

00:47:57.275 --> 00:48:01.160
尝试学习一个预测共指的模型。

00:48:01.160 --> 00:48:04.550
所以当我们开始测试的时候，

00:48:04.550 --> 00:48:08.495
我们有一段文字提到，嗯，

00:48:08.495 --> 00:48:12.230
我们要运行这个分类器，它会说，

00:48:12.230 --> 00:48:16.400
嗯，是还是不是，有可能。

00:48:16.400 --> 00:48:19.205
如果我们选择一个0.5的门槛，

00:48:19.205 --> 00:48:22.565
我们将添加某些引用链接。

00:48:22.565 --> 00:48:25.490
看起来不错。

00:48:25.490 --> 00:48:29.480
嗯，但我们要说“好”来完成它，

00:48:29.480 --> 00:48:34.280
如果a与b是共指，b与c是k是共指，那么真的

00:48:34.280 --> 00:48:40.040
另外，a和c是共指的，所以我们要做一个传递闭包，

00:48:40.040 --> 00:48:42.410
这将给我们提供集群。

00:48:42.410 --> 00:48:46.160
嗯，注意这里有一定的危险。

00:48:46.160 --> 00:48:48.650
因为这意味着，如果我们

00:48:48.650 --> 00:48:51.755
既然我们正处于过渡封闭状态，

00:48:51.755 --> 00:48:54.425
这总是添加群集链接。

00:48:54.425 --> 00:48:58.310
这就意味着危险在于我们要超越集群，

00:48:58.310 --> 00:49:04.400
因为如果我们犯了一个错误，我们就把应该分开的东西联系起来。

00:49:04.400 --> 00:49:06.920
例如，如果我们错误地说，

00:49:06.920 --> 00:49:08.870
他和我是同一个人，

00:49:08.870 --> 00:49:10.565
所有这些，嗯，

00:49:10.565 --> 00:49:13.774
话语会一起瓦解成一个整体，

00:49:13.774 --> 00:49:16.920
一切都将被视为共指。

00:49:16.920 --> 00:49:20.995
好吧，嗯，还有这个，

00:49:20.995 --> 00:49:25.480
一些我没有真正强调过的事情，但后来出现了，

00:49:25.480 --> 00:49:30.070
是的，有一些提到与什么都没有关联，对吧。

00:49:30.070 --> 00:49:32.890
在Shruthi Rao的故事中，有一个公园，

00:49:32.890 --> 00:49:35.875
刚才在课文里提到过，等等，

00:49:35.875 --> 00:49:38.190
在这种算法中，

00:49:38.190 --> 00:49:41.540
我们想让分类器说的是，不，

00:49:41.540 --> 00:49:42.755
不，不，不，不，

00:49:42.755 --> 00:49:44.615
所有的决定。

00:49:44.615 --> 00:49:46.970
因此，它被认为与任何事物都无关。

00:49:46.970 --> 00:49:49.915
然后这只是一个简单的提及。

00:49:49.915 --> 00:49:52.360
这类作品，

00:49:52.360 --> 00:49:58.660
但它并没有被证明是进行共指的最佳方式。

00:49:58.660 --> 00:50:03.585
很多原因说明它不是最好的引用方式

00:50:03.585 --> 00:50:09.410
因为我们有回指现象，在回指中我们有结构依赖性。

00:50:09.410 --> 00:50:11.065
很多时候，

00:50:11.065 --> 00:50:14.535
看来我们不是真的，

00:50:14.535 --> 00:50:19.815
嗯，什么-想做这些共同参考的决定。

00:50:19.815 --> 00:50:24.185
我们想做回指决定结构依赖。

00:50:24.185 --> 00:50:27.410
所以我们想说他是，

00:50:27.410 --> 00:50:33.140
嗯，依赖于纳达尔，而我则依赖于我。

00:50:33.140 --> 00:50:35.115
这些是回指关系。

00:50:35.115 --> 00:50:41.285
所以我们只想选择一个例子来说明这个回指关系。

00:50:41.285 --> 00:50:44.870
这样人们就会看到所谓的，

00:50:44.870 --> 00:50:47.475
嗯，提到配对模型，对吗？

00:50:47.475 --> 00:50:52.100
问题是，如果我们有一份长文件，上面提到很多，

00:50:52.100 --> 00:50:57.050
嗯，我们不想说——试着找到所有的人然后说，是的。

00:50:57.050 --> 00:51:00.160
我们只是想说有一个特别的-我们

00:51:00.160 --> 00:51:03.695
只是想说有一个特别的。

00:51:03.695 --> 00:51:05.770
所以对于最后的他来说，

00:51:05.770 --> 00:51:11.350
它的回指关系又回到了Nader身上，你不想这么说

00:51:11.350 --> 00:51:17.600
他还引用了本文前面提到的所有其他内容。

00:51:17.600 --> 00:51:22.355
所以这并不是一个被广泛探索的东西。

00:51:22.355 --> 00:51:24.940
但可以说，这又是一个案例，

00:51:24.940 --> 00:51:30.905
你应该把共指和回指分开，因为对于回指来说

00:51:30.905 --> 00:51:32.980
正确的思考方式是

00:51:32.980 --> 00:51:37.630
他们在文本中依赖的一个优先事项。

00:51:37.630 --> 00:51:43.345
而真正的共同引用，当你在拉尔夫·纳德尔的文章中有各种各样的提到，

00:51:43.345 --> 00:51:44.650
这个拉尔夫·纳德尔，

00:51:44.650 --> 00:51:48.050
纳德尔做到了，这些都不依赖文本。

00:51:48.050 --> 00:51:52.070
它们都应该作为共指代进行分组。

00:51:52.070 --> 00:51:58.520
嗯，但是我们的模特通常不会尝试用一种方式和另一种方式，

00:51:58.520 --> 00:52:00.725
但是你选择了其中一个模型。

00:52:00.725 --> 00:52:02.815
所以在另一个，

00:52:02.815 --> 00:52:06.010
我们这样做是为了-相反，

00:52:06.010 --> 00:52:08.160
你做什么就做什么排名。

00:52:08.160 --> 00:52:09.695
所以说排名，

00:52:09.695 --> 00:52:13.400
每提到一次，

00:52:13.400 --> 00:52:15.545
我们会找到的-试着找到它

00:52:15.545 --> 00:52:20.640
一个先例出现在文本中的前面，

00:52:20.640 --> 00:52:22.650
也就是说，嗯，

00:52:22.650 --> 00:52:26.810
与…共指，我们要做一个决定。

00:52:26.810 --> 00:52:29.509
所以当我们看到她在这里的时候，

00:52:29.509 --> 00:52:30.815
我们要说，

00:52:30.815 --> 00:52:35.400
“好吧，嗯，这是什么意思？”

00:52:35.400 --> 00:52:37.660
我们要选择一个共同参照物

00:52:37.660 --> 00:52:41.130
即使文本中可能还有其他内容。

00:52:41.130 --> 00:52:44.155
嗯，如果我们这么做，

00:52:44.155 --> 00:52:47.490
然后我们对单例提到有一个问题，因为如果

00:52:47.490 --> 00:52:51.160
我们正在努力-每提到一次，我们都会说，

00:52:51.160 --> 00:52:55.430
在与之相关的文本中选择之前的内容，

00:52:55.430 --> 00:52:58.575
正确的答案可能是没有这样的事情。

00:52:58.575 --> 00:53:00.580
所以我们要做的是增加

00:53:00.580 --> 00:53:06.410
另外一个虚拟人物在前面提到，NA提到。

00:53:06.410 --> 00:53:11.340
所以有一个选择就是你要说之前没有任何事。

00:53:11.340 --> 00:53:13.935
所以实际上，当你找到我，

00:53:13.935 --> 00:53:17.525
因为这是，嗯，第一个，嗯，

00:53:17.525 --> 00:53:19.265
在文中提到，

00:53:19.265 --> 00:53:21.775
你一定会选择，

00:53:21.775 --> 00:53:24.260
嗯，它的前身是。

00:53:24.260 --> 00:53:27.815
然后你去纳德尔，你有两个选择。

00:53:27.815 --> 00:53:34.110
你可以说它是我的共指，也可以说它是NA的共指。

00:53:34.110 --> 00:53:38.410
我，这是一个新的提到-一个新的实体，正在被提到的文本和

00:53:38.410 --> 00:53:43.280
正确的答案是这是一个新的提及-一个新的实体被提到的文本。

00:53:43.280 --> 00:53:46.935
然后你找到他，现在你有三个选择，

00:53:46.935 --> 00:53:51.100
正确的做法是说它与纳德是同一个参照物。

00:53:51.110 --> 00:53:55.199
可以。嗯，所以这次，

00:53:55.199 --> 00:53:57.640
为了训练我们的模特，

00:53:57.640 --> 00:54:00.525
差不多，嗯，

00:54:00.525 --> 00:54:04.510
除此之外，还有一种不同的语义。

00:54:04.510 --> 00:54:09.820
所以现在-以前，我们想说的是，

00:54:09.820 --> 00:54:15.030
提到将尝试对我和她进行分类的配对分类器，

00:54:15.030 --> 00:54:16.355
我和她，

00:54:16.355 --> 00:54:19.220
他们两个都得高分，

00:54:19.220 --> 00:54:22.030
现在只要其中一个就够了

00:54:22.030 --> 00:54:26.150
得分很高，因为这对我们来说已经足够了。

00:54:26.150 --> 00:54:30.605
所以我们要用的是我们的旧款SoftMax，对她来说，

00:54:30.605 --> 00:54:34.550
我们要把一个SoftMax放在前面。

00:54:34.550 --> 00:54:39.660
我们的希望就是我们有很高的可能性

00:54:39.660 --> 00:54:43.700
如果它有前科或者NA分数高，

00:54:43.700 --> 00:54:46.755
如果它没有任何以前的引用。

00:54:46.755 --> 00:54:51.365
所以当我们在运行时进行分类时，

00:54:51.365 --> 00:54:56.355
我们将只添加得分最高的引用链接。

00:54:56.355 --> 00:54:58.990
这意味着我们只是稍微训练一下

00:54:58.990 --> 00:55:03.180
不同的是，现在我们要做的是，

00:55:03.180 --> 00:55:06.200
我们想说的是，

00:55:06.200 --> 00:55:13.025
我们需要至少一个前因之间的高分数共指。

00:55:13.025 --> 00:55:15.010
所以一个可能的模型是，

00:55:15.010 --> 00:55:17.300
我们可以最大化这种可能性。

00:55:17.300 --> 00:55:21.105
所以对于金本位数据中相互参照的那些，

00:55:21.105 --> 00:55:24.885
我们希望他们分配的概率之和很高。

00:55:24.885 --> 00:55:31.135
这意味着如果我们有足够的

00:55:31.135 --> 00:55:34.300
嗯，其中一个

00:55:34.300 --> 00:55:38.375
概率很高，而且他们不必给出很高的概率。

00:55:38.375 --> 00:55:41.219
如果它的概率是0.9，

00:55:41.219 --> 00:55:43.535
说它是正确的先例之一，

00:55:43.535 --> 00:55:45.695
我们得分很高。

00:55:45.695 --> 00:55:49.660
可以。所以我们要把它变成一个损失函数

00:55:49.660 --> 00:55:53.585
我们用对数概率的标准方法，

00:55:53.585 --> 00:55:56.260
嗯，然后我们想，嗯，

00:55:56.260 --> 00:55:58.590
或负对数概率给我们

00:55:58.590 --> 00:56:02.150
损失，然后我们想把损失降到最低。

00:56:02.150 --> 00:56:05.909
所以在提到排名模型时，

00:56:05.909 --> 00:56:07.870
嗯，在测试时，

00:56:07.870 --> 00:56:09.360
基本上是一样的，

00:56:09.360 --> 00:56:16.280
但是我们的SoftMax分类器只是为每一次提到分配一个先行项。

00:56:16.280 --> 00:56:20.470
所以我们希望这些能给我们带来

00:56:20.470 --> 00:56:25.640
我们想要的集群，没有后续的集群阶段。

00:56:25.820 --> 00:56:30.875
所以我遗漏了一个很大的部分，

00:56:30.875 --> 00:56:32.510
我刚说，“好吧，

00:56:32.510 --> 00:56:38.590
我们把mi和mj的概率作为-它们是相互参照的吗？”

00:56:38.590 --> 00:56:41.050
但我有点说

00:56:41.050 --> 00:56:43.760
如何确定它们是否相互参照。

00:56:43.760 --> 00:56:46.640
嗯，简单地说，嗯，

00:56:46.640 --> 00:56:49.775
这里-这是经典的方法。

00:56:49.775 --> 00:56:51.895
传统的做法是，

00:56:51.895 --> 00:56:56.090
你有很多特点

00:56:56.090 --> 00:57:00.480
一种基于特征的统计分类器，给出了分数。

00:57:00.480 --> 00:57:02.650
这些是你可以使用的功能。

00:57:02.650 --> 00:57:06.490
因此，在人、数、性别认同等方面都有很强的特点。

00:57:06.490 --> 00:57:09.720
如果你有阳性或阴性代词，

00:57:09.720 --> 00:57:12.290
你想找到一个合适的前因。

00:57:12.290 --> 00:57:16.630
有较弱的，嗯，语义兼容性特征。

00:57:16.630 --> 00:57:18.980
所以矿业集团公司

00:57:18.980 --> 00:57:21.755
这家联合企业可能有点像一家公司。

00:57:21.755 --> 00:57:25.700
你可以使用类似于word2vec的东西来评估它。

00:57:25.700 --> 00:57:28.120
有句法限制。

00:57:28.120 --> 00:57:30.730
所以这有点像，嗯，

00:57:30.730 --> 00:57:34.570
霍布斯的算法是关于我们解决什么问题的

00:57:34.570 --> 00:57:38.700
不同的句法结构有多可能意味着共指。

00:57:38.700 --> 00:57:40.950
事实上是这样的，你知道，

00:57:40.950 --> 00:57:46.150
很多基于特征的系统都把霍布斯算法作为特征

00:57:46.150 --> 00:57:51.860
加权的系统，通常是决定共指的一个很强的特征。

00:57:51.860 --> 00:57:55.425
嗯，还有很多其他的东西可以作为特性放进去。

00:57:55.425 --> 00:57:56.860
嗯，最近。

00:57:56.860 --> 00:57:58.240
所以约翰去看电影，

00:57:58.240 --> 00:57:59.290
杰克也去了，

00:57:59.290 --> 00:58:00.600
他不忙。

00:58:00.600 --> 00:58:05.180
对他来说，最有可能的人选是更接近的候选人杰克。

00:58:05.180 --> 00:58:10.120
嗯，我提到过，受试者更可能是，嗯，先例。

00:58:10.120 --> 00:58:11.550
约翰和杰克去看电影，

00:58:11.550 --> 00:58:12.930
他不忙。

00:58:12.930 --> 00:58:15.990
嗯，约翰似乎更像是个先例。

00:58:15.990 --> 00:58:18.155
这就是主题偏好。

00:58:18.155 --> 00:58:20.395
还有一个并行性偏好。

00:58:20.395 --> 00:58:22.295
约翰和杰克一起去看电影，

00:58:22.295 --> 00:58:24.170
乔和他一起去了一家酒吧。

00:58:24.170 --> 00:58:28.405
我认为认为认为他可能是杰克是有道理的，

00:58:28.405 --> 00:58:32.825
这有点类似于平行性的原因，而不是主题。

00:58:32.825 --> 00:58:36.480
所以有各种语言特征和制约因素等等，

00:58:36.480 --> 00:58:39.970
你可以把这些都放到统计分类器里，

00:58:39.970 --> 00:58:44.910
2000年代的十年核心系统是如何构建的。

00:58:44.910 --> 00:58:49.350
最近，人们已经建立了神经系统。

00:58:49.350 --> 00:58:50.560
所以对于这些，

00:58:50.560 --> 00:58:53.810
我们通常使用相同的嵌入方式。

00:58:53.810 --> 00:58:58.250
所以我们会有一个候选的前因，它会嵌入，

00:58:58.250 --> 00:59:00.510
我们会提到嵌入的。

00:59:00.510 --> 00:59:01.785
这就像是

00:59:01.785 --> 00:59:05.595
平均词向量或类似的东西。

00:59:05.595 --> 00:59:09.935
我们将把这些信息输入一个神经网络，这样我们就能得到分数。

00:59:09.935 --> 00:59:13.070
但你发现的是

00:59:13.070 --> 00:59:16.995
这些系统中的大多数都有类似于词向量的东西，

00:59:16.995 --> 00:59:20.610
它们还有其他功能，嗯，

00:59:20.610 --> 00:59:23.910
这些功能仍然捕获了

00:59:23.910 --> 00:59:28.265
基于特征的统计分类器中的内容。

00:59:28.265 --> 00:59:31.865
因此，通常会有反映以下情况的特征：

00:59:31.865 --> 00:59:37.270
这句话有什么语法关系？它是一个主题吗？

00:59:37.270 --> 00:59:38.515
它是一个物体吗？

00:59:38.515 --> 00:59:42.825
这是你可以加入到一个提到的特征中去的。

00:59:42.825 --> 00:59:46.565
但是，越接近的事情就越可能是相互参照的。

00:59:46.565 --> 00:59:51.270
因此，您可能在这里有一些额外的特性来记录维度之间的距离，

00:59:51.270 --> 00:59:54.180
这些东西也会被扔进去。

00:59:54.180 --> 01:00:00.935
嗯，即使在神经系统中，这些特征仍然很重要。

01:00:00.935 --> 01:00:07.165
所以我现在跳到前面给你看一点，嗯，

01:00:07.165 --> 01:00:11.450
共指消解的最新技术是什么？

01:00:11.450 --> 01:00:14.950
这是华盛顿大学在年完成的一个系统。

01:00:14.950 --> 01:00:20.495
2017年作者：Kenton Lee和其他作者。

01:00:20.495 --> 01:00:26.910
嗯，所以这里的目标是产生一个端到端的引用系统，它是文本输入的，

01:00:26.910 --> 01:00:30.715
嗯，提到那些相互引用的集群。

01:00:30.715 --> 01:00:35.335
嗯，所以他们想用一种更复杂的

01:00:35.335 --> 01:00:40.420
能够端到端地完成整个事情的神经网络。所以我会通过的，

01:00:40.420 --> 01:00:41.730
嗯，步骤。

01:00:41.730 --> 01:00:45.985
所以第一步就是我们从文字开始。

01:00:45.985 --> 01:00:47.705
所以每一个词，

01:00:47.705 --> 01:00:53.020
我们要找一个嵌入它的单词，这在我们看到的其他东西中。

01:00:53.020 --> 01:00:55.795
我们还将加入一个角色级别的CNN，

01:00:55.795 --> 01:01:00.885
其中两个连接起来的将给出每个令牌的表示。

01:01:00.885 --> 01:01:02.600
看起来应该很熟悉。

01:01:02.600 --> 01:01:05.065
可以。之后，

01:01:05.065 --> 01:01:11.255
我们将在整个句子中来回运行一个深入的双向lstm。

01:01:11.255 --> 01:01:15.440
同样，从我们以前看到的东西来看，这应该是很熟悉的。

01:01:15.440 --> 01:01:21.700
下一步让我们做一些更特别的事情，

01:01:21.700 --> 01:01:24.115
共同引用。

01:01:24.115 --> 01:01:30.790
之后他们想做的就是为跨度做一个表示。

01:01:30.790 --> 01:01:32.635
所以从跨度来看，

01:01:32.635 --> 01:01:38.050
我们指的是句子中单词的任何相邻子短语。

01:01:38.050 --> 01:01:40.030
所以这是一个跨度。

01:01:40.030 --> 01:01:41.380
这是一个跨度。

01:01:41.380 --> 01:01:42.670
这是一个跨度。

01:01:42.670 --> 01:01:46.315
电邮说是一个跨度，每一个子序列。

01:01:46.315 --> 01:01:48.250
嗯，那我再来讲。

01:01:48.250 --> 01:01:50.215
但是，你知道，原则上他们会

01:01:50.215 --> 01:01:53.155
你正在为每个子序列计算这个。

01:01:53.155 --> 01:01:55.360
所以对于每个子序列，

01:01:55.360 --> 01:01:58.675
他们想提出一个跨度表示。

01:01:58.675 --> 01:02:04.975
所以这个跨度表示将分为三部分，

01:02:04.975 --> 01:02:09.325
嗯，代表这些子序列之一。

01:02:09.325 --> 01:02:13.660
嗯，所以每一个都会有自己的表现。

01:02:13.660 --> 01:02:15.640
所以问题是，什么？

01:02:15.640 --> 01:02:18.910
所以我们有这个跨度表示，

01:02:18.910 --> 01:02:22.375
在这三个部分。

01:02:22.375 --> 01:02:26.770
嗯，这些部分是什么，

01:02:26.770 --> 01:02:28.420
首先，

01:02:28.420 --> 01:02:31.450
我们会有一个代表，嗯，

01:02:31.450 --> 01:02:35.035
它只是在看

01:02:35.035 --> 01:02:40.450
根据bilstm的跨度和跨度的最后一个字。

01:02:40.450 --> 01:02:43.135
所以如果我们在看跨度，邮政服务，

01:02:43.135 --> 01:02:45.670
我们要拍这部电影

01:02:45.670 --> 01:02:50.245
这个bilstm并将其用作跨度表示的一部分。

01:02:50.245 --> 01:02:52.225
嗯，这是个好的开始，

01:02:52.225 --> 01:02:54.730
但实际上他们做了一些有点棘手的事情。

01:02:54.730 --> 01:02:59.710
所以有点像当我们进行依赖性分析时，

01:02:59.710 --> 01:03:02.815
嗯，短语会有一个词头，

01:03:02.815 --> 01:03:05.050
如果是这样，

01:03:05.050 --> 01:03:10.420
嗯，你知道的，我妹妹，她说的是“姐姐”，

01:03:10.420 --> 01:03:14.905
在那里-如果它像是田角里的山羊，

01:03:14.905 --> 01:03:16.960
这句话的开头将是“山羊”。

01:03:16.960 --> 01:03:21.520
因此，他们想找到一种从文本中捕获单词的方法。

01:03:21.520 --> 01:03:26.200
嗯，所以他们要做的就是集中注意力。

01:03:26.200 --> 01:03:30.820
所以他们会说我们有这个跨度，邮政服务，

01:03:30.820 --> 01:03:33.640
我们要把注意力当作

01:03:33.640 --> 01:03:38.050
一种类似于头部的跨内机构。

01:03:38.050 --> 01:03:42.205
所以我们要做的，呃，在这里，

01:03:42.205 --> 01:03:45.520
我们要做的是

01:03:45.520 --> 01:03:50.020
学习注意力重量，我只是想，是的。

01:03:50.020 --> 01:03:54.220
嗯，我们要做的就是这个跨度，嗯，

01:03:54.220 --> 01:03:58.810
我们将在希望的基础上学习，

01:03:58.810 --> 01:04:03.250
跨度的尽头要注意哪些单词。

01:04:03.250 --> 01:04:06.970
所以我们要把注意力放在不同的词上，

01:04:06.970 --> 01:04:09.730
然后我们将以通常的方式，

01:04:09.730 --> 01:04:15.220
把这个词对的加权和-

01:04:15.220 --> 01:04:19.360
双向LSTM通过前馈网络和终端配对

01:04:19.360 --> 01:04:23.695
用这个新的加权表示法。

01:04:23.695 --> 01:04:25.450
希望在这种情况下，

01:04:25.450 --> 01:04:28.630
大部分的重量都将放在最后的服务器上，

01:04:28.630 --> 01:04:30.445
这将是标题。

01:04:30.445 --> 01:04:32.755
但是会有一些分布在它上面。

01:04:32.755 --> 01:04:36.055
所以这给了他们一个模型

01:04:36.055 --> 01:04:41.875
有点提到，用两端，希望找到提到的关键词。

01:04:41.875 --> 01:04:46.015
可以。嗯，那么，嗯，

01:04:46.015 --> 01:04:48.010
这是跨度的三分之二，

01:04:48.010 --> 01:04:51.235
但他们在这里仍然有这些附加功能。

01:04:51.235 --> 01:04:54.235
所以它们还有一些附加功能。

01:04:54.235 --> 01:04:58.195
他们希望能够标记演讲者和收件人。

01:04:58.195 --> 01:05:02.200
嗯，他们想标记其他东西，比如语法角色。

01:05:02.200 --> 01:05:03.970
但是如果事情发生了，

01:05:03.970 --> 01:05:07.240
拥有一些附加功能仍然很有用。

01:05:07.240 --> 01:05:08.620
所以他们所做的是，

01:05:08.620 --> 01:05:11.860
这是每个跨度的表示，

01:05:11.860 --> 01:05:16.390
然后他们要说的是两个跨度的相互参照。

01:05:16.390 --> 01:05:22.120
所以他们会在两个跨距中各得一分，两个跨距，每个跨距，

01:05:22.120 --> 01:05:23.365
也就是说，

01:05:23.365 --> 01:05:24.850
这是个好消息吗？

01:05:24.850 --> 01:05:26.920
然后你会得到很多，

01:05:26.920 --> 01:05:29.170
它们看起来是共同的吗？

01:05:29.170 --> 01:05:34.870
因此，计算了每个跨度的这些表示，

01:05:34.870 --> 01:05:39.220
你通过一个完全连接的前馈网络运行三通，

01:05:39.220 --> 01:05:41.245
乘以重量系数，

01:05:41.245 --> 01:05:42.490
这就给了你，呃，

01:05:42.490 --> 01:05:44.635
这是一个很好的推荐分数吗？

01:05:44.635 --> 01:05:46.960
然后，因为它们是共指的，

01:05:46.960 --> 01:05:49.330
你有两个跨距，

01:05:49.330 --> 01:05:53.650
两跨点哈达玛积和

01:05:53.650 --> 01:05:56.140
一些额外的功能，比如在

01:05:56.140 --> 01:05:59.469
通过另一个神经网络，

01:05:59.469 --> 01:06:01.285
那就是给你的，是

01:06:01.285 --> 01:06:03.475
这两个跨度相互参照？

01:06:03.475 --> 01:06:05.590
但所有这些碎片，

01:06:05.590 --> 01:06:10.480
嗯，给你一个整体损失函数。

01:06:10.480 --> 01:06:14.815
所以你可以说你的模型是，嗯，好的。

01:06:14.815 --> 01:06:16.885
我们将运行这些LSTM，

01:06:16.885 --> 01:06:18.880
我们要测量所有跨度，

01:06:18.880 --> 01:06:20.829
我们要得分，

01:06:20.829 --> 01:06:24.370
我们知道我们共指系统的黄金答案。

01:06:24.370 --> 01:06:29.200
所以我们想预测那些相互参照的

01:06:29.200 --> 01:06:34.375
基于我们用这些分数计算的概率的损失，

01:06:34.375 --> 01:06:35.770
嗯，正如我之前提到的，

01:06:35.770 --> 01:06:39.205
像以前一样，使用SoftMax损失对模型进行排名。

01:06:39.205 --> 01:06:42.775
所以，如果你把所有这些都放在一起，并把它训练到最后，

01:06:42.775 --> 01:06:48.685
你有一个完整的共指代系统，从单词到共指代决策。

01:06:48.685 --> 01:06:52.045
嗯，这有个大问题，

01:06:52.045 --> 01:06:55.810
嗯，如果你真的很幼稚地运用了这个，

01:06:55.810 --> 01:06:58.930
问题是一段

01:06:58.930 --> 01:07:03.055
文字是文字长度的平方。

01:07:03.055 --> 01:07:06.400
因此，如果你在做相互参照的决定，

01:07:06.400 --> 01:07:10.060
在，嗯，对跨距之间，

01:07:10.060 --> 01:07:13.060
然后你得到了一个算法，嗯，

01:07:13.060 --> 01:07:15.415
O-OT到第四个，

01:07:15.415 --> 01:07:18.025
其中文本长度为t字。

01:07:18.025 --> 01:07:22.375
所以这在计算上有点不切实际。

01:07:22.375 --> 01:07:23.515
所以在这一点上，

01:07:23.515 --> 01:07:26.350
他们说，实际上，

01:07:26.350 --> 01:07:29.905
我们确实想用我们的嘴，我们想解决

01:07:29.905 --> 01:07:34.090
不同的事情有多可能被提及。

01:07:34.090 --> 01:07:38.650
有效地说，嗯，然后他们在修剪

01:07:38.650 --> 01:07:43.765
决定哪些跨度实际上是他们想要在模型中考虑的东西。

01:07:43.765 --> 01:07:45.730
所以在这一点上，在某种意义上，

01:07:45.730 --> 01:07:47.170
有点作弊，对吧？

01:07:47.170 --> 01:07:50.440
因为这里的修剪步骤很好，

01:07:50.440 --> 01:07:51.760
我们要坚持下去

01:07:51.760 --> 01:07:54.205
一个提及的检测模块，

01:07:54.205 --> 01:07:57.040
嗯，就像传统系统一样。

01:07:57.040 --> 01:08:01.225
嗯，但它的漂亮程度是

01:08:01.225 --> 01:08:05.440
用定义的损失函数表示的算法。

01:08:05.440 --> 01:08:09.730
损失函数实际上是从一系列

01:08:09.730 --> 01:08:14.380
令牌到提到的排名决定。

01:08:14.380 --> 01:08:18.204
所以它是一个端到端的模型，

01:08:18.204 --> 01:08:20.320
即使在实践中使之实用，

01:08:20.320 --> 01:08:24.680
你必须有一个像提纲探测器一样的东西才能让它工作。

01:08:26.100 --> 01:08:30.520
可以。暂停呼吸。嗯，是的，

01:08:30.520 --> 01:08:34.510
所以还有最后一个。

01:08:34.510 --> 01:08:40.180
所以我们已经做了一些提到配对模型和提到排名模型。

01:08:40.180 --> 01:08:42.370
嗯，对这两个来说，

01:08:42.370 --> 01:08:44.830
你只是把个人提到并说，

01:08:44.830 --> 01:08:46.870
再提一次，什么，

01:08:46.870 --> 01:08:48.550
我该怎么办？

01:08:48.550 --> 01:08:53.125
让我们看一下“提到”这个词，看看我们是否是相互参照的。

01:08:53.125 --> 01:09:00.280
而且，没有真正的实体概念，这些实体是一系列的提到。

01:09:00.280 --> 01:09:02.680
你只是在做这种一次性的决定

01:09:02.680 --> 01:09:06.040
一对一对的提到，不知何故，

01:09:06.040 --> 01:09:09.610
将实体分类为集群

01:09:09.610 --> 01:09:14.050
这些提到配对决定的结果。

01:09:14.050 --> 01:09:19.555
所以有一种长久以来的感觉，

01:09:19.555 --> 01:09:22.570
哦，那不可能是真的，

01:09:22.570 --> 01:09:28.060
正确的方法来做共指必须真的把它作为一个集群任务来做，

01:09:28.060 --> 01:09:30.040
人们常说，

01:09:30.040 --> 01:09:33.235
我们希望实体成为一流公民。

01:09:33.235 --> 01:09:34.600
所以我们想成为，

01:09:34.600 --> 01:09:40.300
有点像是将提到放在代表实体的集群中。

01:09:40.300 --> 01:09:45.010
最明显的方法就是做一种自下而上的聚集聚类。

01:09:45.010 --> 01:09:46.900
所以你先说，

01:09:46.900 --> 01:09:49.855
每提到一个都是它自己的单例集群，

01:09:49.855 --> 01:09:55.585
然后你决定合并clu-集群

01:09:55.585 --> 01:09:58.150
嗯，说两次提及是相互参照的。

01:09:58.150 --> 01:09:59.695
但当你继续这样做的时候，

01:09:59.695 --> 01:10:04.285
然后，您将做出两个集群是否相互引用的决定。

01:10:04.285 --> 01:10:07.120
所以这里的想法是你要有一段文字，

01:10:07.120 --> 01:10:09.265
谷歌最近在说废话，

01:10:09.265 --> 01:10:12.055
该公司宣布谷歌Plus，blah blah blah，

01:10:12.055 --> 01:10:14.380
该产品的特点是废话废话。

01:10:14.380 --> 01:10:17.170
所以你在这里提到了一些。

01:10:17.170 --> 01:10:20.950
所以你要做的就是开始说，好的，

01:10:20.950 --> 01:10:24.445
这里有四个提到，每个集群都有自己的集群。

01:10:24.445 --> 01:10:26.170
然后我们要做的，

01:10:26.170 --> 01:10:28.525
我们要做些决定吗？

01:10:28.525 --> 01:10:32.740
嗯，所以我们可以决定这两个星系团

01:10:32.740 --> 01:10:37.375
将它们合并到一个集群中。

01:10:37.375 --> 01:10:41.965
然后我们可以决定这两个，

01:10:41.965 --> 01:10:48.095
嗯，集群是相互参照的，并将它们合并到一个集群中。

01:10:48.095 --> 01:10:51.255
所以我们是逐渐聚集的。

01:10:51.255 --> 01:10:54.030
然后，我们来看看这两个星系团，

01:10:54.030 --> 01:10:56.835
集群1和集群2，然后说，

01:10:56.835 --> 01:11:00.585
不，我们不认为这些是相互参照的，

01:11:00.585 --> 01:11:03.030
所以我们要把它们分开。

01:11:03.030 --> 01:11:10.645
所以，当没有东西可以合并的时候，你的引用算法就停止了。

01:11:10.645 --> 01:11:15.430
人们认为这是正确做法的原因是，

01:11:15.430 --> 01:11:19.930
感觉是如果我们建立这样的部分集群，

01:11:19.930 --> 01:11:22.405
你能做得更好。

01:11:22.405 --> 01:11:24.040
因为如果我只是说，

01:11:24.040 --> 01:11:25.615
这里有两个提到，

01:11:25.615 --> 01:11:27.459
google和google plus，

01:11:27.459 --> 01:11:32.020
是否应将它们视为共同引用？

01:11:32.020 --> 01:11:34.450
嗯，既然你是聪明人，

01:11:34.450 --> 01:11:36.640
知道什么是Google，知道什么是Google Plus，

01:11:36.640 --> 01:11:39.070
当然你会回答不，当然不会。

01:11:39.070 --> 01:11:40.495
但是，你知道，

01:11:40.495 --> 01:11:43.180
如果你只是一台想做决定的电脑，

01:11:43.180 --> 01:11:45.325
很难知道正确的答案，

01:11:45.325 --> 01:11:49.240
因为有很多其他的情况下，有缩短，

01:11:49.240 --> 01:11:52.030
正确的答案是它们是相互参照的，对吧。

01:11:52.030 --> 01:11:56.199
因为如果这是谷歌和谷歌公司，

01:11:56.199 --> 01:11:59.200
那么，将它们视为共同参照物是正确的。

01:11:59.200 --> 01:12:01.435
或者如果它是，嗯，

01:12:01.435 --> 01:12:04.210
有点像希拉里·克林顿和希拉里，

01:12:04.210 --> 01:12:06.610
将它们视为共同参照物是正确的。

01:12:06.610 --> 01:12:09.895
所以很难分辨出共指是什么。

01:12:09.895 --> 01:12:11.830
但是希望是，

01:12:11.830 --> 01:12:14.980
如果你先做了一些简单的决定，

01:12:14.980 --> 01:12:17.830
所以如果你决定谷歌和公司是同一个参照物

01:12:17.830 --> 01:12:20.950
而google plus和产品是相互参照的，

01:12:20.950 --> 01:12:24.580
那么应该更容易说出来，

01:12:24.580 --> 01:12:25.990
好的产品和公司，

01:12:25.990 --> 01:12:27.865
它们是完全不同的东西。

01:12:27.865 --> 01:12:31.510
所以我们应该把这些分开。

01:12:31.510 --> 01:12:34.405
嗯，这就是目标，

01:12:34.405 --> 01:12:36.955
为了实现这个目标，

01:12:36.955 --> 01:12:39.160
人们建立的模型。

01:12:39.160 --> 01:12:43.675
这实际上是一个模型，凯文·克拉克是这里的博士生之一，

01:12:43.675 --> 01:12:46.080
嗯，几年前我们做过。

01:12:46.080 --> 01:12:47.415
想法很好，

01:12:47.415 --> 01:12:49.350
我们要做的是，

01:12:49.350 --> 01:12:52.860
我们首先考虑提到的配对，

01:12:52.860 --> 01:12:57.180
构建某种分布式的、提到对的表示，

01:12:57.180 --> 01:13:01.815
这类似于我们以前对以前的模型所做的。

01:13:01.815 --> 01:13:07.900
但接下来我们将超越这一点，提出集群表示。

01:13:07.900 --> 01:13:11.095
然后我们可以看看集群对表示。

01:13:11.095 --> 01:13:16.045
我们希望通过查看这些集群表示，

01:13:16.045 --> 01:13:21.760
我们将能够更好地决定要合并的内容或下一个要合并的内容。

01:13:21.760 --> 01:13:27.760
嗯，我还有几张幻灯片介绍克拉克和曼宁算法。

01:13:27.760 --> 01:13:30.490
嗯，但我还有几分钟的时间。

01:13:30.490 --> 01:13:33.680
所以我想我会跳过细节。

01:13:33.680 --> 01:13:37.120
嗯，我觉得这里最有趣的是，

01:13:37.120 --> 01:13:41.740
是基于聚类的共指代算法的思想，

01:13:41.740 --> 01:13:43.465
为什么原则上，

01:13:43.465 --> 01:13:45.490
它应该给你额外的动力。

01:13:45.490 --> 01:13:49.135
嗯，这是最主要的有用的事情了。

01:13:49.135 --> 01:13:51.280
因为我想确保我们已经

01:13:51.280 --> 01:13:54.115
最后几分钟我什么也没说，

01:13:54.115 --> 01:13:58.630
你是如何评价共指消解的，它有多有效？

01:13:58.630 --> 01:14:01.330
所以让我跳到前面。

01:14:01.330 --> 01:14:07.120
嗯，如果你看一下共指决议文件，

01:14:07.120 --> 01:14:08.680
或者类似的，

01:14:08.680 --> 01:14:15.250
嗯，人们用来评估共指的指标很多，

01:14:15.250 --> 01:14:17.680
他们有一长串的字母汤。

01:14:17.680 --> 01:14:20.140
所以有muc，ceaf，lea，

01:14:20.140 --> 01:14:22.510
B-小熊，布兰克和，

01:14:22.510 --> 01:14:24.010
嗯，像这样的事情。

01:14:24.010 --> 01:14:29.080
嗯，有效的一部分是，如果你看聚类文献，

01:14:29.080 --> 01:14:32.215
人们尝试和评估集群的方法很多，

01:14:32.215 --> 01:14:36.610
基本上，任何一个度量和其他度量，你可以，嗯，

01:14:36.610 --> 01:14:41.590
端口over，um，to，um，coreference评估。

01:14:41.590 --> 01:14:45.895
我的意思是，你的处境有点困难，

01:14:45.895 --> 01:14:49.900
你有一个黄金标准来挑选特定的星团，

01:14:49.900 --> 01:14:52.885
系统会挑选出特定的集群，

01:14:52.885 --> 01:14:58.000
你会得到这样的结果，你必须决定它有多好。

01:14:58.000 --> 01:15:01.375
所以我将很快向你们展示一个特定的算法。

01:15:01.375 --> 01:15:04.630
所以B-cubed算法使用

01:15:04.630 --> 01:15:08.725
像我们以前想象的那样，精确的回忆和F-测量。

01:15:08.725 --> 01:15:11.290
所以它看起来，呃，

01:15:11.290 --> 01:15:13.870
由系统标识的群集。

01:15:13.870 --> 01:15:19.105
它说，这个星系团是五分之四，

01:15:19.105 --> 01:15:20.890
嗯，金簇一号，

01:15:20.890 --> 01:15:23.470
所以精度是五分之四。

01:15:23.470 --> 01:15:28.240
但实际上，嗯，在黄金簇一中有六个东西。

01:15:28.240 --> 01:15:33.760
所以它只召回了六分之四的星团。

01:15:33.760 --> 01:15:36.985
另一个也一样，

01:15:36.985 --> 01:15:39.445
同样的计算。

01:15:39.445 --> 01:15:43.990
然后它会在精度和召回中平均，

01:15:43.990 --> 01:15:49.045
嗯，它会得出一个总的，嗯，B-立方分数。

01:15:49.045 --> 01:15:54.400
嗯，如果你从算法的角度考虑这个问题，

01:15:54.400 --> 01:15:57.205
这实际上很棘手，因为我有点说，

01:15:57.205 --> 01:16:00.460
嗯，好吧，这个星系团主要是黄金星系团。

01:16:00.460 --> 01:16:03.730
所以用它作为参考，

01:16:03.730 --> 01:16:06.820
但这意味着你要做一个二分图的对齐。

01:16:06.820 --> 01:16:09.520
在系统集群和黄金集群之间。

01:16:09.520 --> 01:16:12.955
所以隐藏在-隐藏在这个评估中，

01:16:12.955 --> 01:16:16.210
系统实际上是一个NP完全问题。

01:16:16.210 --> 01:16:19.525
但在实践中，你通常可以很好地进行启发式分析，

01:16:19.525 --> 01:16:21.610
评估方法，嗯，

01:16:21.610 --> 01:16:23.245
运行和工作。

01:16:23.245 --> 01:16:25.435
嗯，好吧。

01:16:25.435 --> 01:16:28.210
所以需要注意的是，

01:16:28.210 --> 01:16:29.965
如果你在集群里，

01:16:29.965 --> 01:16:32.350
你会自动获得很高的精度，

01:16:32.350 --> 01:16:34.135
但你的记忆力很差。

01:16:34.135 --> 01:16:35.815
如果你在集群上，

01:16:35.815 --> 01:16:40.405
你会得到很好的回忆，因为所有应该在同一个集群中的东西都是，

01:16:40.405 --> 01:16:42.910
嗯，但你的精确度很差。

01:16:42.910 --> 01:16:48.175
所以你想做的就是平衡这两件事。

01:16:48.175 --> 01:16:51.280
可以。最后两分钟，

01:16:51.280 --> 01:16:53.380
只是想让你了解一下表演。

01:16:53.380 --> 01:16:58.285
所以这些都是来自本体注释数据集的结果，这个数据集大约有3000个文档。

01:16:58.285 --> 01:17:01.495
中文，英文，标注为共指。

01:17:01.495 --> 01:17:05.980
嗯，我报告的分数实际上是三个指标的平均值。

01:17:05.980 --> 01:17:09.295
其中一个是我刚给你看的B-cubed，

01:17:09.295 --> 01:17:11.965
嗯，这是一些数字。

01:17:11.965 --> 01:17:17.245
嗯，李等2010年是斯坦福系统。

01:17:17.245 --> 01:17:21.400
所以-有一个共同的任务评估共指系统。

01:17:21.400 --> 01:17:24.265
我们相信杰里·霍布斯，

01:17:24.265 --> 01:17:28.885
仍然是正确的，使用基于规则的引用也可以做得很好。

01:17:28.885 --> 01:17:30.890
所以在2010年，

01:17:30.890 --> 01:17:36.030
我们用一个基于规则的互指系统击败了所有机器学习系统，

01:17:36.030 --> 01:17:37.725
我们为此感到骄傲。

01:17:37.725 --> 01:17:40.455
嗯，这就是它的表现。

01:17:40.455 --> 01:17:42.240
嗯，以后几年，

01:17:42.240 --> 01:17:45.150
人们确实开始做得更好，嗯，

01:17:45.150 --> 01:17:50.110
有，嗯，有，呃，机器学习系统。

01:17:50.110 --> 01:17:51.820
但正如你所看到的，不是很多，

01:17:51.820 --> 01:17:57.040
对这些2012年的系统来说，这个有点，

01:17:57.040 --> 01:17:58.930
更好，这一个确实不好，

01:17:58.930 --> 01:18:02.335
嗯，这个，嗯，但是有点进步。

01:18:02.335 --> 01:18:07.975
从2015年开始，神经系统开始出现。

01:18:07.975 --> 01:18:11.200
嗯，所以怀斯曼等人是第一个神经系统，

01:18:11.200 --> 01:18:14.245
I vaguely mentioned this Clark &amp; Manning system,

01:18:14.245 --> 01:18:16.945
数字一直上升到60年代中期。

01:18:16.945 --> 01:18:21.355
这就是Kenton-Lee系统，它有端到端的神经相互参照，

01:18:21.355 --> 01:18:23.815
在英语方面，大约有67分。

01:18:23.815 --> 01:18:25.795
所以你会注意到，

01:18:25.795 --> 01:18:28.075
数字不是很好。

01:18:28.075 --> 01:18:31.420
因此，共指仍然是一个远未解决的问题。

01:18:31.420 --> 01:18:33.790
嗯，如果你想找点乐子，嗯，

01:18:33.790 --> 01:18:37.450
你可以自己出去试试共指系统。

01:18:37.450 --> 01:18:41.470
嗯，在第一个链接上有一个斯坦福大学的，或者从拥抱的脸上有一个

01:18:41.470 --> 01:18:44.965
是一个很好的现代共指系统。

01:18:44.965 --> 01:18:47.740
如果你只是用一些文字来尝试这些，

01:18:47.740 --> 01:18:50.380
你会注意到他们仍然有很多错误。

01:18:50.380 --> 01:18:52.480
嗯，还有很多工作要做，

01:18:52.480 --> 01:18:55.270
因为这只是一个更难理解语言的任务，

01:18:55.270 --> 01:18:57.535
[噪音]有点像，嗯，

01:18:57.535 --> 01:19:01.270
杰里霍布斯和特里-特里温诺格拉德早些时候观察到。

01:19:01.270 --> 01:19:04.675
好吧，嗯，不过我现在就停在那儿。谢谢。

01:19:04.675 --> 01:19:09.745
嗯，哦，是的，我应该有个提醒，下周二邀请的演讲者。

01:19:09.745 --> 01:19:11.575
嗯，那我就去，

01:19:11.575 --> 01:19:14.720
um, attendance for invited speakers.

