WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:10.650
[NOISE] Okay everyone, let's get started for today.

00:00:10.650 --> 00:00:15.345
Okay. So, we're into week five of CS224n.

00:00:15.345 --> 00:00:18.450
And so, this is the plan for today.

00:00:18.450 --> 00:00:22.080
Um, in some sense a lot of this class is gonna be

00:00:22.080 --> 00:00:26.955
an easy class because I'm gonna talk about things like,

00:00:26.955 --> 00:00:30.780
um, final projects and tips for what you're meant to do,

00:00:30.780 --> 00:00:32.100
and finding a topic,

00:00:32.100 --> 00:00:33.510
and writing up your work,

00:00:33.510 --> 00:00:34.680
and things like that.

00:00:34.680 --> 00:00:36.240
Um, so for, um, so,

00:00:36.240 --> 00:00:39.135
two-thirds of the class there isn't a lot of,

00:00:39.135 --> 00:00:41.010
um, deep technical content.

00:00:41.010 --> 00:00:42.110
But I hope they're actually

00:00:42.110 --> 00:00:46.610
just some useful stuff and stuff that would be good to know about.

00:00:46.610 --> 00:00:49.820
One way you can think about this is until,

00:00:49.820 --> 00:00:53.090
until this year we had a midterm in this class.

00:00:53.090 --> 00:00:56.540
So, you know, if we weren't doing this class should instead be doing the

00:00:56.540 --> 00:01:00.740
the mid-term based on all the material that we've covered, um, so far.

00:01:00.740 --> 00:01:03.380
So, this should be really pleasant by comparison.

00:01:03.380 --> 00:01:06.650
Um, but that isn't gonna be quite the entire class.

00:01:06.650 --> 00:01:09.615
So, for this piece here in the middle I'm gonna

00:01:09.615 --> 00:01:13.910
spend a while back on some of the topics of last week.

00:01:13.910 --> 00:01:19.415
So, I wanted to have one more look at some of these gated recurrent models,

00:01:19.415 --> 00:01:21.905
um, that Abby introduced last week.

00:01:21.905 --> 00:01:24.380
And I guess my hope is that now that you've

00:01:24.380 --> 00:01:26.780
had a bit more time to look and read about things,

00:01:26.780 --> 00:01:31.670
and hopefully even have started working on homework for that.

00:01:31.670 --> 00:01:36.800
Maybe it starts to make a bit more sense or else even if it's more confusing then before,

00:01:36.800 --> 00:01:40.100
you've got some idea of what your confusions are and questions.

00:01:40.100 --> 00:01:41.840
And so, hopefully it's, um,

00:01:41.840 --> 00:01:47.715
good to think about those one more time because I think they are quite a complex notion,

00:01:47.715 --> 00:01:51.860
and it's not so obvious what they're doing and why they're doing anything useful,

00:01:51.860 --> 00:01:55.085
or whether they're just this big complex blob of mystery.

00:01:55.085 --> 00:01:59.210
And then also to touch on a couple of machine translation topics that have um, come up

00:01:59.210 --> 00:02:03.300
in the final project that we didn't really get m- time to say much about last week.

00:02:03.300 --> 00:02:04.620
[NOISE] Okay.

00:02:04.620 --> 00:02:06.480
So, let's get started.

00:02:06.480 --> 00:02:12.515
Um, so, this is our coursework in grading that we showed at the beginning.

00:02:12.515 --> 00:02:17.000
And so, the main thing I wanna do today is talk about this final project.

00:02:17.000 --> 00:02:18.620
Um, but before tha- I do that,

00:02:18.620 --> 00:02:22.145
let's just save one minute on participation.

00:02:22.145 --> 00:02:27.350
Um, so, I guess we started into one aspect of the participation policy, um,

00:02:27.350 --> 00:02:29.780
last Thursday when we took attendance,

00:02:29.780 --> 00:02:31.730
and that makes it sound draconian,

00:02:31.730 --> 00:02:33.215
but I wanted to say, um,

00:02:33.215 --> 00:02:34.820
the positive viewpoint of,

00:02:34.820 --> 00:02:36.970
um, the participation points.

00:02:36.970 --> 00:02:38.840
I mean, obviously this is a big class.

00:02:38.840 --> 00:02:40.640
There are lots of people.

00:02:40.640 --> 00:02:44.090
Um, our hope is just that people will variously,

00:02:44.090 --> 00:02:47.480
they're sort of engaged and involved in the class,

00:02:47.480 --> 00:02:49.580
and the participation points,

00:02:49.580 --> 00:02:51.335
ah, are our way of doing that.

00:02:51.335 --> 00:02:53.945
I mean, basically the way this is set up.

00:02:53.945 --> 00:02:57.005
I mean, if you do much of anything

00:02:57.005 --> 00:03:00.230
you should just get three percent for the participation points.

00:03:00.230 --> 00:03:01.610
It shouldn't be hard.

00:03:01.610 --> 00:03:05.730
I mean, I will bet you that there will be some people who at the end,

00:03:05.730 --> 00:03:09.005
will have gotten seven points in the participation category.

00:03:09.005 --> 00:03:11.420
And unfortunately we cap you, we'll only give you

00:03:11.420 --> 00:03:14.450
three percent for the participation category, but you know,

00:03:14.450 --> 00:03:17.450
providing you usually come to class,

00:03:17.450 --> 00:03:19.400
or usually write the,

00:03:19.400 --> 00:03:22.160
um, what we've got to [NOISE] the invited speakers

00:03:22.160 --> 00:03:25.220
the reaction paragraphs if you are an SCPD student.

00:03:25.220 --> 00:03:29.210
Sometimes, um, write a helpful answer on Piazza, right.

00:03:29.210 --> 00:03:31.895
You're already gonna be there on three percent.

00:03:31.895 --> 00:03:33.450
Um, yeah.

00:03:33.450 --> 00:03:36.060
And so, one, but one other thing, um,

00:03:36.060 --> 00:03:39.905
that's a way to get some parti- participation points that's out today.

00:03:39.905 --> 00:03:44.120
So, um, today we're putting up our Mid-quarter feedback survey.

00:03:44.120 --> 00:03:46.280
And we'd love to have you fill that in.

00:03:46.280 --> 00:03:49.565
I mean, we'd like to get your thoughts on the course so far.

00:03:49.565 --> 00:03:51.720
And, you know, for you guys,

00:03:51.720 --> 00:03:53.370
there are two ways that you can win.

00:03:53.370 --> 00:03:57.500
First if you give us some feedback that can help the rest of your quarter be better,

00:03:57.500 --> 00:04:00.860
but we've also got a simple bribe built into this, um,

00:04:00.860 --> 00:04:04.640
which is you get half a participation point simply for filling in,

00:04:04.640 --> 00:04:06.890
um, the, um, Mid-quarter survey,

00:04:06.890 --> 00:04:09.265
but it'd be really good to get your feedback on that.

00:04:09.265 --> 00:04:11.780
Okay. So, then the main thing I want to get to

00:04:11.780 --> 00:04:15.925
today is to talk about [NOISE] the final project.

00:04:15.925 --> 00:04:19.410
Okay. And so, I'll jump right ahead, um, into that.

00:04:19.410 --> 00:04:23.240
So, for the final project there are two choices.

00:04:23.240 --> 00:04:26.599
Um, you, you can either do our default final project,

00:04:26.599 --> 00:04:30.560
which I'll say a little bit about, it's doing SQuAD question answering,

00:04:30.560 --> 00:04:32.675
or you can propose a final,

00:04:32.675 --> 00:04:34.310
a custom final project,

00:04:34.310 --> 00:04:36.110
which we then have to approve.

00:04:36.110 --> 00:04:37.835
And in the course of that,

00:04:37.835 --> 00:04:40.910
um, if you have some outside mentor, um,

00:04:40.910 --> 00:04:43.840
you can say who they are and your project proposal,

00:04:43.840 --> 00:04:49.150
but otherwise, um, we'll attempt to assign you a mentor somewhere out of the course staff.

00:04:49.150 --> 00:04:51.295
Um, so, for all the assignments,

00:04:51.295 --> 00:04:53.215
through assignments one through five,

00:04:53.215 --> 00:04:55.495
you have to do them by yourself.

00:04:55.495 --> 00:04:59.135
Um, for the final project in either form of that,

00:04:59.135 --> 00:05:00.905
you can do it as a team.

00:05:00.905 --> 00:05:02.210
So, you can do it as one,

00:05:02.210 --> 00:05:04.310
two, or three people.

00:05:04.310 --> 00:05:06.515
And how does that work?

00:05:06.515 --> 00:05:10.350
Um, well, it works like this, um,

00:05:10.350 --> 00:05:12.410
if you're a bigger team,

00:05:12.410 --> 00:05:14.569
we do expect you to do more,

00:05:14.569 --> 00:05:17.825
and there are actually two ways you can be a bigger team that I'll point out.

00:05:17.825 --> 00:05:20.900
One way is having more people being two or three people.

00:05:20.900 --> 00:05:23.750
And the other thing that comes up is, um,

00:05:23.750 --> 00:05:27.970
sometimes people wanna do a final project for more than one class at the same time.

00:05:27.970 --> 00:05:30.050
In particular for this quarter I know there are

00:05:30.050 --> 00:05:32.480
at least a couple of people who are hoping to do,

00:05:32.480 --> 00:05:37.065
um, a joint project with Emma's reinforcement learning class.

00:05:37.065 --> 00:05:38.675
And we allow that as well.

00:05:38.675 --> 00:05:43.490
But we sort of do multiplication because if you're two people using it for two classes,

00:05:43.490 --> 00:05:46.910
that means it should be four times as great as

00:05:46.910 --> 00:05:50.390
what one person is doing for one class, right?

00:05:50.390 --> 00:05:54.470
So, how, how it works with larger teams, you know,

00:05:54.470 --> 00:05:59.510
in all honesty it's a little bit subtle because, you know,

00:05:59.510 --> 00:06:02.975
the truth is if something is just bad, um,

00:06:02.975 --> 00:06:05.495
your model was broken, um,

00:06:05.495 --> 00:06:08.540
or you, your experiment failed,

00:06:08.540 --> 00:06:10.390
um, and you don't know why.

00:06:10.390 --> 00:06:16.040
Um, you know. If, if there's just obvious ways in what you've done as bad as it's sort of,

00:06:16.040 --> 00:06:19.325
it's sort of bad whether you're one person or four person.

00:06:19.325 --> 00:06:21.860
Um, and if you've written it up beautifully,

00:06:21.860 --> 00:06:23.840
you've written up beautifully regardless of whether

00:06:23.840 --> 00:06:26.240
you're one person or four per- people,

00:06:26.240 --> 00:06:32.000
that you know nevertheless the expectation is that if you're one person will be pleased,

00:06:32.000 --> 00:06:35.960
that if you put together one model and gotten it to work well, um,

00:06:35.960 --> 00:06:38.790
but if you're three people will say, "Well,

00:06:38.790 --> 00:06:40.905
that wasn't such a big effort, um,

00:06:40.905 --> 00:06:43.620
running this one model against this task."

00:06:43.620 --> 00:06:45.315
Surely if there are three people,

00:06:45.315 --> 00:06:46.700
they could have investigated

00:06:46.700 --> 00:06:51.515
some other model classes and seeing whether they perform better or worse on this task.

00:06:51.515 --> 00:06:53.450
And we'll feel a sense of lightweight.

00:06:53.450 --> 00:06:58.175
So, we are expecting that sort of both more ambitious projects,

00:06:58.175 --> 00:07:01.190
and more thorough exploration of them if you're

00:07:01.190 --> 00:07:04.735
being a bigger team or you're using it for multiple classes.

00:07:04.735 --> 00:07:06.410
Um, for the final project,

00:07:06.410 --> 00:07:09.545
you are allowed to use any language or deep learning,

00:07:09.545 --> 00:07:11.960
um, framework that you choose to.

00:07:11.960 --> 00:07:13.910
We don't insist on what you use,

00:07:13.910 --> 00:07:16.025
though in practice in past years.

00:07:16.025 --> 00:07:18.725
Basically everyone keeps on using what they've learned,

00:07:18.725 --> 00:07:19.880
um, in the assignments.

00:07:19.880 --> 00:07:21.695
I expect that will be true, um,

00:07:21.695 --> 00:07:24.030
this time as well. [NOISE]

00:07:24.030 --> 00:07:29.880
Okay. So, um, let me just mention quickly the default final project,

00:07:29.880 --> 00:07:31.320
so that you've got, um,

00:07:31.320 --> 00:07:33.120
some sense of context.

00:07:33.120 --> 00:07:36.375
So, the materials of that will be released this Thursday.

00:07:36.375 --> 00:07:38.460
And so, for the tasks for it is,

00:07:38.460 --> 00:07:42.090
a textural question-answering task which is done over the,

00:07:42.090 --> 00:07:45.240
the Stanford Question Answering Dataset, SQuAD,

00:07:45.240 --> 00:07:47.475
which was a dataset put together, um,

00:07:47.475 --> 00:07:51.870
by Percy Liang and the department and the student .

00:07:51.870 --> 00:07:55.380
Um, so, we've used this as a default final project,

00:07:55.380 --> 00:07:58.680
um, before but we're mixing up a couple of things this year.

00:07:58.680 --> 00:08:03.840
I mean, firstly, the starter code we're providing this year is in pytorch,

00:08:03.840 --> 00:08:06.465
to fit in with what we've done to the rest of the class.

00:08:06.465 --> 00:08:09.765
But secondly, the SQuAD team,

00:08:09.765 --> 00:08:11.700
released a new version of SQuAD,

00:08:11.700 --> 00:08:15.840
SQuAD 2.0 and we're going to use that for the class this year.

00:08:15.840 --> 00:08:18.630
And the essential difference in SQuAD 2.0,

00:08:18.630 --> 00:08:21.975
is in SQuAD 1.1 or 1.0,

00:08:21.975 --> 00:08:28.065
every question had an answer in the passage of text whereas in SQuAD 2.0,

00:08:28.065 --> 00:08:30.210
a lot of questions don't have answers.

00:08:30.210 --> 00:08:34.770
So, there's this extra significant thing that you need to do which is working out,

00:08:34.770 --> 00:08:36.960
um, whether a question has an answer.

00:08:36.960 --> 00:08:39.510
So, th- this is just one example,

00:08:39.510 --> 00:08:43.430
um, which just gives you a sense of the SQuAD,  what SQuAD is like.

00:08:43.430 --> 00:08:45.680
So, there's a paragraph of text.

00:08:45.680 --> 00:08:48.680
I've just put a subset of it here, um, Bill Aken,

00:08:48.680 --> 00:08:52.460
adopted by Mexican movie actress, Lupe Mayorga, um,

00:08:52.460 --> 00:08:55.290
grew up in the neighborhood town, neighboring, sorry,

00:08:55.290 --> 00:08:57.990
neighboring town of Madeira and his song chronicled

00:08:57.990 --> 00:09:01.650
the hardships faced by the migrant farm workers he saw as a child.

00:09:01.650 --> 00:09:04.035
Right, there's then a question, um,

00:09:04.035 --> 00:09:05.760
in what town did Bill,

00:09:05.760 --> 00:09:07.650
right, actually I misspelled that sorry,

00:09:07.650 --> 00:09:13.230
it should have been Aken without an I. I got confused with our former department chair,

00:09:13.230 --> 00:09:15.315
Alex Aiken, I guess when I was typing.

00:09:15.315 --> 00:09:17.175
Um, Bill Aken grow up?

00:09:17.175 --> 00:09:19.920
And the answer you are meant to give is Madeira.

00:09:19.920 --> 00:09:22.320
Um, so, just incidentally,

00:09:22.320 --> 00:09:24.180
it's a random fact.

00:09:24.180 --> 00:09:28.500
Um, so, quite a few of you know about something that was

00:09:28.500 --> 00:09:30.450
recently in the kind of tech news, tech

00:09:30.450 --> 00:09:33.285
news and we're going to talk about later in the class.

00:09:33.285 --> 00:09:34.860
Um, that people, um,

00:09:34.860 --> 00:09:39.015
from Google produced this very strong New Natural Language

00:09:39.015 --> 00:09:42.090
Understanding representation model called BERT.

00:09:42.090 --> 00:09:46.695
And which is one of several kind of models that are in a class of,

00:09:46.695 --> 00:09:52.650
models that contextually model words that have come into prominence in 2017 and 18.

00:09:52.650 --> 00:09:58.770
And in general, BERT has sort of produced very good performance for very many tasks.

00:09:58.770 --> 00:10:03.900
Indeed, if you look at the SQuAD 2.0 leader board online, um,

00:10:03.900 --> 00:10:06.975
at this URL, what you'll find is that

00:10:06.975 --> 00:10:11.625
all of the leading systems use BERT in some way or another, these days.

00:10:11.625 --> 00:10:14.910
Um, but nevertheless, this was actually a question that BERT got wrong.

00:10:14.910 --> 00:10:16.290
Um, that BERT said,

00:10:16.290 --> 00:10:18.000
"No answer to this question,

00:10:18.000 --> 00:10:19.680
" rather than getting the correct answer.

00:10:19.680 --> 00:10:23.070
Even though it looks kind of straightforward reading it as a human being.

00:10:23.070 --> 00:10:27.315
It doesn't really look a human tricky reading comprehension question.

00:10:27.315 --> 00:10:30.390
Um, so, that's the default final project.

00:10:30.390 --> 00:10:35.355
So, on Thursday, I'm going to talk more about the default final project.

00:10:35.355 --> 00:10:39.255
I'm going to talk about how people build textual question answering systems.

00:10:39.255 --> 00:10:43.740
And the details on the default final project should all be posted by then,

00:10:43.740 --> 00:10:47.220
but that's just to give you a bit of context of what the other choice is.

00:10:47.220 --> 00:10:51.165
And today, I'm sort of more going to be aiming at people,

00:10:51.165 --> 00:10:54.180
um, doing the custom final project.

00:10:54.180 --> 00:10:58.590
But let me just sort of say a bit first about the choice between the two of them.

00:10:58.590 --> 00:11:02.940
So, um, why might you want to choose the default final project?

00:11:02.940 --> 00:11:07.320
So, if you have limited experience with research,

00:11:07.320 --> 00:11:12.180
you don't have any clear idea of a research project you want to do this quarter,

00:11:12.180 --> 00:11:14.850
you're just really busy with other classes that, uh,

00:11:14.850 --> 00:11:17.700
you're enrolled in CS140 and you're just really loade- loaded

00:11:17.700 --> 00:11:21.195
[LAUGHTER] now with other classes you're doing this quarter.

00:11:21.195 --> 00:11:25.890
Um, you'd be happy to have just a clear goal towards, to work towards.

00:11:25.890 --> 00:11:29.550
A leaderboard of your fellow students that you can compete against.

00:11:29.550 --> 00:11:31.890
Um, do the default final project.

00:11:31.890 --> 00:11:36.510
Um, I think for many people it's actually the good right choice.

00:11:36.510 --> 00:11:38.670
And I mean, for what it's worth, I mean,

00:11:38.670 --> 00:11:43.160
typically, slightly over half of people have done the default final project.

00:11:43.160 --> 00:11:45.170
It's normally that, so 55 percent have done

00:11:45.170 --> 00:11:48.680
the default final project and the rest the custom final project.

00:11:48.680 --> 00:11:51.140
So, if you do the default final project,

00:11:51.140 --> 00:11:52.715
you'll get lots of guidance.

00:11:52.715 --> 00:11:54.545
You get lots of scaffolding.

00:11:54.545 --> 00:11:58.355
There are clear things to aim at in what you do.

00:11:58.355 --> 00:12:04.015
Um, the course staff are in general most prepared and most able to help you.

00:12:04.015 --> 00:12:05.990
Um, and in particular,

00:12:05.990 --> 00:12:09.005
I mean, the, for the bottom bullet here.

00:12:09.005 --> 00:12:11.510
I mean, you know, something to think about in making

00:12:11.510 --> 00:12:16.040
the choices that some of it comes down to how committed,

00:12:16.040 --> 00:12:21.320
organized, and keen are you to be wanting to do your own custom final project.

00:12:21.320 --> 00:12:24.890
If you've got a, something you really want to do for a custom final project, great.

00:12:24.890 --> 00:12:28.270
We love to see interesting custom final projects.

00:12:28.270 --> 00:12:32.760
But, you know, if you're going to end up doing something that just looks

00:12:32.760 --> 00:12:39.150
worse like [LAUGHTER] not done as well [LAUGHTER] as you would've done a, done a project.

00:12:39.150 --> 00:12:42.090
If you'd just done the fin-, default final project,

00:12:42.090 --> 00:12:45.090
then you should probably choose the default final project [LAUGHTER].

00:12:45.090 --> 00:12:47.180
Um, okay.

00:12:47.180 --> 00:12:48.785
But even if you are doing,

00:12:48.785 --> 00:12:51.125
think you'll do the default final project.

00:12:51.125 --> 00:12:54.620
I hope that some of this lecture will still, um, be useful.

00:12:54.620 --> 00:12:56.660
While the part in the middle, when I talk back about

00:12:56.660 --> 00:12:59.525
MT and Gater or current networks are definitely useful.

00:12:59.525 --> 00:13:01.670
But, you know, beyond that, um,

00:13:01.670 --> 00:13:05.345
some of the tips on doing research and discussions of,

00:13:05.345 --> 00:13:10.230
sort of looking at how to make neural networks work and error analysis, paper writing.

00:13:10.230 --> 00:13:14.715
These are all good topics that apply to the default final project as well.

00:13:14.715 --> 00:13:16.770
So, in the other direction, um,

00:13:16.770 --> 00:13:19.680
if you have some research project that you're excited about.

00:13:19.680 --> 00:13:22.590
Possibly, it's one you are already working on or possibly,

00:13:22.590 --> 00:13:24.615
that you've just always wished to do.

00:13:24.615 --> 00:13:27.690
Something exciting with neural networks and rap music.

00:13:27.690 --> 00:13:32.340
Um, well, you know, that custom final project is an opportunity to do that.

00:13:32.340 --> 00:13:35.550
Um, so, it's a chance for you to do something on your own.

00:13:35.550 --> 00:13:37.980
Um, it, you know, obviously,

00:13:37.980 --> 00:13:40.200
if you're not interested in textural question-answering

00:13:40.200 --> 00:13:42.150
but do you think you might like machine translation.

00:13:42.150 --> 00:13:43.740
Well, it's an opportunity, um,

00:13:43.740 --> 00:13:45.765
to choose any topic of your own.

00:13:45.765 --> 00:13:52.590
It's also a way to sort of experience much more of the research pro- process because,

00:13:52.590 --> 00:13:55.290
you know, for the default final project, it's a bigger,

00:13:55.290 --> 00:13:58.545
more open-ended thing than any of our assignments.

00:13:58.545 --> 00:13:59.895
But, you know, nevertheless,

00:13:59.895 --> 00:14:01.800
the default final project is still

00:14:01.800 --> 00:14:05.790
sort of a pre-setup thing that you don't have to find your own problem,

00:14:05.790 --> 00:14:07.185
find your own data,

00:14:07.185 --> 00:14:08.940
work out a good approach to it.

00:14:08.940 --> 00:14:10.980
A lot of that's sort of been done for you.

00:14:10.980 --> 00:14:14.505
So, that, for a custom final project it's much more

00:14:14.505 --> 00:14:18.900
your own job to sort of define and execute a mini research project.

00:14:18.900 --> 00:14:22.440
And so, if all of that stuff seems appealing or some of it seems appealing,

00:14:22.440 --> 00:14:24.975
um, then aim at the custom final project.

00:14:24.975 --> 00:14:30.045
Um, doing this just reminded me about a fact about assignments one to five.

00:14:30.045 --> 00:14:32.309
You know, for assignments one to five,

00:14:32.309 --> 00:14:36.090
we are hoping that they can be a set of stepping

00:14:36.090 --> 00:14:39.885
stones for learning how to build deep learning systems.

00:14:39.885 --> 00:14:47.310
But, you know, one of our goals in that is to give you less hand holds as time goes by.

00:14:47.310 --> 00:14:51.650
So, you know, assignment one was really easy and assignment three,

00:14:51.650 --> 00:14:53.880
we tried to make it really handholdy,

00:14:53.880 --> 00:14:56.700
so people could start to learn PyTorch.

00:14:56.700 --> 00:14:59.280
But, you know, we're actually hoping for assignments

00:14:59.280 --> 00:15:02.280
four and five that they're actually harder,

00:15:02.280 --> 00:15:04.850
so that you're getting more experience of working

00:15:04.850 --> 00:15:07.430
out how to build and do things by yourself

00:15:07.430 --> 00:15:12.830
because if the only thing you ever see is completely scaffolded assignments.

00:15:12.830 --> 00:15:17.300
It's sort of like when you do CS106A that you have to do a great job on

00:15:17.300 --> 00:15:21.980
the CS106A assignments but you don't really know how to write a program by yourselves.

00:15:21.980 --> 00:15:23.555
And that's sort of what we want to, um,

00:15:23.555 --> 00:15:25.310
sort of get you beyond,

00:15:25.310 --> 00:15:27.050
um, in the latter two assignments.

00:15:27.050 --> 00:15:29.860
So, I hope you have started on assignment four.

00:15:29.860 --> 00:15:34.885
If not, you really should start and get underway soon as Abby was emphasizing.

00:15:34.885 --> 00:15:37.575
Okay. So, this year for the,

00:15:37.575 --> 00:15:40.935
um, final project, whichever one you're doing.

00:15:40.935 --> 00:15:43.770
Um, we're actually putting more structure in than we have

00:15:43.770 --> 00:15:46.730
in previous years to encourage people to get going.

00:15:46.730 --> 00:15:48.035
And so, in particular,

00:15:48.035 --> 00:15:52.190
there are early on components which are worth points in the grading.

00:15:52.190 --> 00:15:55.505
So, the first part of that is a project proposal,

00:15:55.505 --> 00:15:57.410
um, which is, um,

00:15:57.410 --> 00:15:59.020
we want from each team.

00:15:59.020 --> 00:16:00.915
So, one per team, um,

00:16:00.915 --> 00:16:02.670
you can just do a joint one,

00:16:02.670 --> 00:16:04.620
um, which is worth five percent.

00:16:04.620 --> 00:16:08.300
Um, so, it's, we're releasing the details on Thursday which is when

00:16:08.300 --> 00:16:12.650
assignment four is due and it'll be due the following Thursday.

00:16:12.650 --> 00:16:16.430
So, we're actually having an interruption in the sequence of current assignments, right.

00:16:16.430 --> 00:16:19.250
So, for the next week, um,

00:16:19.250 --> 00:16:22.805
what the thing to do is project proposal.

00:16:22.805 --> 00:16:24.770
And then the week after that, um,

00:16:24.770 --> 00:16:29.080
we're back to assignment five and then we go full time into final project.

00:16:29.080 --> 00:16:30.590
So, what we're wanting for

00:16:30.590 --> 00:16:34.250
the project proposal is we're actually wanting you to do a little bit

00:16:34.250 --> 00:16:39.470
of starting off research and the fine ter- terms of reading some paper.

00:16:39.470 --> 00:16:41.750
So, find some paper that's, um,

00:16:41.750 --> 00:16:43.520
relevant to your research,

00:16:43.520 --> 00:16:45.545
um, that you are going to do.

00:16:45.545 --> 00:16:49.215
Um, read it, write a summary of what it does.

00:16:49.215 --> 00:16:54.275
Um, write down some thoughts on how you could adapt or extend ideas in it,

00:16:54.275 --> 00:16:56.450
in your own final project.

00:16:56.450 --> 00:16:59.810
Um, and then say something about what your plan is for

00:16:59.810 --> 00:17:03.080
what you're goi- hoping to do for your final project.

00:17:03.080 --> 00:17:05.660
And especially, if you're doing a custom final project

00:17:05.660 --> 00:17:08.210
there's more to write there because we'll want to make

00:17:08.210 --> 00:17:10.445
sure that you have some idea as to

00:17:10.445 --> 00:17:13.360
what data you can use and how are you going to evaluate it.

00:17:13.360 --> 00:17:16.130
Whereas a couple of those things are actually sort of

00:17:16.130 --> 00:17:20.250
determined for you if you're doing the default final project.

00:17:20.430 --> 00:17:25.540
Um, and so then after that we're going to have a project milestone, um,

00:17:25.540 --> 00:17:28.390
which is the progress report where we're hoping that you can

00:17:28.390 --> 00:17:31.300
report that you're well along in your final project.

00:17:31.300 --> 00:17:33.850
That you've run at least some experiment and have

00:17:33.850 --> 00:17:37.075
some results on some data that you can talk about.

00:17:37.075 --> 00:17:39.820
So the default- the project milestone is due on,

00:17:39.820 --> 00:17:41.785
um, Thursday, March seven.

00:17:41.785 --> 00:17:45.010
So it's actually more than halfway through

00:17:45.010 --> 00:17:48.130
the period that's sort of dedicated to the final project.

00:17:48.130 --> 00:17:51.220
So, if you are not- we sort of put it past

00:17:51.220 --> 00:17:54.970
halfway because the fact of the matter is it always takes people time to get going,

00:17:54.970 --> 00:17:56.635
um, but nevertheless, you know,

00:17:56.635 --> 00:17:59.350
what you should have in your head is unless you're halfway

00:17:59.350 --> 00:18:02.440
through by the time you're handing in your,

00:18:02.440 --> 00:18:06.040
um, project milestone, then you're definitely behind.

00:18:06.040 --> 00:18:09.910
And you'll be doing that typical Stanford thing of having a lot of late nights

00:18:09.910 --> 00:18:14.750
and lack of sleep in the last week [LAUGHTER] of class trying to catch up for that.

00:18:14.760 --> 00:18:17.485
Um, okay. So, um,

00:18:17.485 --> 00:18:19.015
so now I've sort of, um,

00:18:19.015 --> 00:18:22.900
want to sort of just start saying a bit of- for

00:18:22.900 --> 00:18:25.270
custom final projects of some of the sort of

00:18:25.270 --> 00:18:28.195
thinking and types of things that you could do about that.

00:18:28.195 --> 00:18:31.570
Um, so you have to determine some project,

00:18:31.570 --> 00:18:35.140
um, for- if you're doing a custom final project.

00:18:35.140 --> 00:18:37.330
So, in philosophy of science, you know,

00:18:37.330 --> 00:18:40.810
there are basically two ways for any field you can have a project.

00:18:40.810 --> 00:18:44.515
You either start with some domain problem of interest.

00:18:44.515 --> 00:18:48.460
You're [NOISE] just got something you're interested in or say,

00:18:48.460 --> 00:18:51.895
"Gee, I'd like to do better machine translation."

00:18:51.895 --> 00:18:55.225
And then you work out some ways to address it with technology,

00:18:55.225 --> 00:18:56.560
or you start with some, um,

00:18:56.560 --> 00:18:58.705
technical approach of interest.

00:18:58.705 --> 00:19:00.550
And you say, "Oh well,

00:19:00.550 --> 00:19:02.500
those LSTMs seemed kind of neat,

00:19:02.500 --> 00:19:04.360
but I didn't understand why there's

00:19:04.360 --> 00:19:08.035
that extra 10H and I think it'd be better if it changed in this other way.

00:19:08.035 --> 00:19:13.570
And you start exploring from a technical direction to try and come up with a better idea.

00:19:13.570 --> 00:19:15.970
And then you're wanting to prove that it works.

00:19:15.970 --> 00:19:20.589
So in kinds of the projects that people do for this class,

00:19:20.589 --> 00:19:22.510
this isn't quite an exhaustive list,

00:19:22.510 --> 00:19:24.970
but this is sort of in general what people do.

00:19:24.970 --> 00:19:28.510
So, the first category and really I think this

00:19:28.510 --> 00:19:32.080
is the bulk of projects over half is people find

00:19:32.080 --> 00:19:35.650
some task replication of interest and they build

00:19:35.650 --> 00:19:39.745
some neural network models to try and do it as effectively as possible.

00:19:39.745 --> 00:19:47.020
Um, there's a second category where people sort of concentrate on implementing,

00:19:47.020 --> 00:19:53.575
so re-implementing some complex neural architecture and getting it to work on some data.

00:19:53.575 --> 00:19:57.115
And so let me just say a couple of sentences on this.

00:19:57.115 --> 00:20:01.525
Um, so, it's certainly okay for you to,

00:20:01.525 --> 00:20:05.395
um, start by re-implementing some existing model.

00:20:05.395 --> 00:20:10.975
Um, and some people that's as far as they get.

00:20:10.975 --> 00:20:14.635
And then the question is, um, is that okay?

00:20:14.635 --> 00:20:17.650
And the answer to whether that's okay sort

00:20:17.650 --> 00:20:20.920
of largely depends on how complex your neural model is.

00:20:20.920 --> 00:20:28.060
Um, so if what you think is okay I'm going to, um,

00:20:28.060 --> 00:20:31.270
re-implement something like we've seen already,

00:20:31.270 --> 00:20:34.600
like a window-based classification model and you

00:20:34.600 --> 00:20:38.110
just re-implement that and run it on some data and get some results and stop.

00:20:38.110 --> 00:20:40.360
That's definitely a bad project.

00:20:40.360 --> 00:20:45.100
Um, but there are lots of very complicated and sophisticated neural,

00:20:45.100 --> 00:20:47.065
um, architectures out there.

00:20:47.065 --> 00:20:51.790
And if you're trying to do something complicated well then that can be a fine project.

00:20:51.790 --> 00:20:55.840
Um, so, I actually sort of stuck in a few examples of projects.

00:20:55.840 --> 00:21:00.490
So, I mean, here's one that was actually from a couple of years ago.

00:21:00.490 --> 00:21:03.535
Um, so this was in the 2017 class.

00:21:03.535 --> 00:21:07.150
And so, shortly before the 2017 class,

00:21:07.150 --> 00:21:11.230
"Deep Mind" who's one of the um, organizations producing

00:21:11.230 --> 00:21:14.380
the most complicated neural models had just released

00:21:14.380 --> 00:21:17.890
a paper about the differentiable neural computer model,

00:21:17.890 --> 00:21:20.170
which was a model of how to have something like

00:21:20.170 --> 00:21:23.109
a differentiate- differentiable Turing machine-like

00:21:23.109 --> 00:21:26.665
architecture inside a neural network, um,

00:21:26.665 --> 00:21:29.050
and  thought, um,

00:21:29.050 --> 00:21:32.230
this would be a great challenge to try and, um,

00:21:32.230 --> 00:21:36.970
re-implement the differentiable neural computer which Deep Mind hadn't released

00:21:36.970 --> 00:21:39.100
any source code for because they're not the kind of

00:21:39.100 --> 00:21:41.860
place that generally releases their source code.

00:21:41.860 --> 00:21:46.420
Um, and, you know, this was actually an extremely ambitious project because it

00:21:46.420 --> 00:21:51.835
was, it's a very complex architecture which is hard to get to train.

00:21:51.835 --> 00:21:54.265
And so, you know, at the end,

00:21:54.265 --> 00:21:58.180
at the end she hadn't been able to sort of train as

00:21:58.180 --> 00:22:02.230
big a model or get as good results as they report in the paper that,

00:22:02.230 --> 00:22:04.030
you know, frankly we thought it was pretty

00:22:04.030 --> 00:22:07.120
miraculous that she managed to get it working at all.

00:22:07.120 --> 00:22:11.920
In the period of time we had in the class and she did successfully do an open-source

00:22:11.920 --> 00:22:16.600
re-implementation of this model which basically worked the same as in their paper.

00:22:16.600 --> 00:22:17.770
Though not quite as well.

00:22:17.770 --> 00:22:19.810
So, you know, that seemed a huge achievement.

00:22:19.810 --> 00:22:23.905
So, you certainly can do something of that sort.

00:22:23.905 --> 00:22:28.210
Right. So, um, so you- you can sort of from

00:22:28.210 --> 00:22:32.845
a technical direction have some ideas for variant model and explore,

00:22:32.845 --> 00:22:35.650
um, how to make a different kind of model class and then look

00:22:35.650 --> 00:22:39.065
at how it works on some problem that works well.

00:22:39.065 --> 00:22:43.200
Another kind of project you can do is an analysis project,

00:22:43.200 --> 00:22:45.690
so that you might be interested in something in

00:22:45.690 --> 00:22:49.515
natural language or something on the behavior of neural networks,

00:22:49.515 --> 00:22:52.740
and just think that you want to analyze them more closely.

00:22:52.740 --> 00:22:54.705
So, you might think, "Oh,

00:22:54.705 --> 00:22:58.230
maybe these neural machine translation systems work great

00:22:58.230 --> 00:23:02.530
providing the word order is the same in the source and target language,

00:23:02.530 --> 00:23:07.180
but can they really do a good job of reordering phrases for different language types?

00:23:07.180 --> 00:23:09.670
How much does their performance vary based on

00:23:09.670 --> 00:23:12.625
the amount of reordering between the source and target language?"

00:23:12.625 --> 00:23:14.755
And you could do some experiments to try and

00:23:14.755 --> 00:23:18.610
investigate that as an analysis problem that looks at a model,

00:23:18.610 --> 00:23:21.010
and we sometimes get projects like that.

00:23:21.010 --> 00:23:24.040
Down at the bottom is the rarest kind of project,

00:23:24.040 --> 00:23:26.860
which is when some people try to do something

00:23:26.860 --> 00:23:30.625
theoretical which is to prove some properties of a system.

00:23:30.625 --> 00:23:35.410
So if- this is easiest to do in simple systems for something like word vectors,

00:23:35.410 --> 00:23:39.130
that if you might want to prove something about

00:23:39.130 --> 00:23:43.165
the kind of spaces that are induced by word vectors,

00:23:43.165 --> 00:23:45.490
and what properties you need to have in

00:23:45.490 --> 00:23:49.375
models for word analogies to work or something like that.

00:23:49.375 --> 00:23:53.995
Um here are just another couple of examples that so- shows some of the other classes.

00:23:53.995 --> 00:23:57.940
So, this one is an example of find a problem and build some models.

00:23:57.940 --> 00:24:04.150
So, these three people um, looked at Shakespearean Sonnet generation and then they considered

00:24:04.150 --> 00:24:07.780
several different models for Shakespearean Sonnet generation and

00:24:07.780 --> 00:24:11.770
got the best results from this sort of- you'd probably can't really see all the details,

00:24:11.770 --> 00:24:15.070
but they have a sort of a mixture of word level and

00:24:15.070 --> 00:24:18.400
character level gated model that feeds into

00:24:18.400 --> 00:24:23.125
a word level LSTM and produces sonnets and the output wasn't totally bad.

00:24:23.125 --> 00:24:26.305
"Thy youth's time and face his form shall cover.

00:24:26.305 --> 00:24:28.870
Now all fresh beauty my love there.

00:24:28.870 --> 00:24:32.290
Will ever time to greet forget each like ever decease,

00:24:32.290 --> 00:24:35.815
but in a- in a best at worship his glory die."

00:24:35.815 --> 00:24:37.780
Okay. It's maybe not perfect,

00:24:37.780 --> 00:24:41.965
[LAUGHTER] but it sort of sounds like a Shakespearean sonnet.

00:24:41.965 --> 00:24:44.160
Um, okay.

00:24:44.160 --> 00:24:46.880
Yeah. So, I showed you that one already.

00:24:46.880 --> 00:24:54.215
Um, here's, um, an example of someone who designed a different kind of network,

00:24:54.215 --> 00:24:58.760
and this was a project that came out of this class that was then continued with,

00:24:58.760 --> 00:25:01.310
and the- they got a conference paper out of it,

00:25:01.310 --> 00:25:03.860
the ICLR 2017 paper.

00:25:03.860 --> 00:25:09.440
So, this was looking at doing a better job at building a neural language model.

00:25:09.440 --> 00:25:12.110
And essentially, they had two ideas,

00:25:12.110 --> 00:25:16.430
both of which seem useful for building better neural language models.

00:25:16.430 --> 00:25:20.750
And so, one is that in the stuff that we've presented so far,

00:25:20.750 --> 00:25:22.790
whether it was the early word vectors,

00:25:22.790 --> 00:25:25.610
or what Abby presented last week in the neural language model,

00:25:25.610 --> 00:25:30.440
there are effectively two vectors for each word: there's one for the word encoding

00:25:30.440 --> 00:25:35.420
on the input and then when you have the softmax on the other side effectively,

00:25:35.420 --> 00:25:39.500
the rows of that matrix that go into the softmax are also

00:25:39.500 --> 00:25:44.195
word vectors for determining how likely you are to produce different words.

00:25:44.195 --> 00:25:48.710
And so, um, these two people had the idea that maybe if we actually in the model

00:25:48.710 --> 00:25:54.950
tied those two word ve- vectors together that would help and produce a better model and,

00:25:54.950 --> 00:25:57.230
um, and so this was actually done

00:25:57.230 --> 00:26:00.860
several years ago when that was a novel idea which hadn't actually been done.

00:26:00.860 --> 00:26:04.085
So, this was done in the 2016 class,

00:26:04.085 --> 00:26:06.875
and then they had this second idea which was,

00:26:06.875 --> 00:26:09.080
well maybe doing the kind of,

00:26:09.080 --> 00:26:11.660
cross entropy one, zero,

00:26:11.660 --> 00:26:14.600
sort of you look at the correct word that you are meant to

00:26:14.600 --> 00:26:18.620
produce and sort of work out a loss based on that.

00:26:18.620 --> 00:26:21.140
Maybe that's not very good because you don't get

00:26:21.140 --> 00:26:25.520
partial points if you produce a different word that's semantically similar.

00:26:25.520 --> 00:26:28.100
And so, that they had this idea that they could use

00:26:28.100 --> 00:26:33.350
word vector similarity and then you'd be giving a score for any word that was

00:26:33.350 --> 00:26:36.305
produced next based on how similar it was

00:26:36.305 --> 00:26:39.470
according to word vector similarity to the word that you are

00:26:39.470 --> 00:26:41.720
meant to produce next and that was also

00:26:41.720 --> 00:26:45.875
a useful idea that they're able to produce improved language models with.

00:26:45.875 --> 00:26:47.420
So, that was a cool project.

00:26:47.420 --> 00:26:50.180
Um, here's an example of, um,

00:26:50.180 --> 00:26:52.010
somebody from last year,

00:26:52.010 --> 00:26:54.560
um, who did an analysis project.

00:26:54.560 --> 00:26:57.135
So, their idea was,

00:26:57.135 --> 00:26:59.660
um, that they- well,

00:26:59.660 --> 00:27:00.680
they were going to, um,

00:27:00.680 --> 00:27:02.345
evaluate on some task,

00:27:02.345 --> 00:27:04.160
they actually did several tasks, um,

00:27:04.160 --> 00:27:07.130
word similarity, analogy, and the SQuAD,

00:27:07.130 --> 00:27:09.215
um, question answering system.

00:27:09.215 --> 00:27:11.180
But the question was, okay,

00:27:11.180 --> 00:27:16.235
a lot of neural network models are big and so aren't very suitable for phones, um,

00:27:16.235 --> 00:27:21.950
could we get away with compressing the models a lot so that rather than having doubles,

00:27:21.950 --> 00:27:25.580
or 32-bit floats, or even 16-bit floats,

00:27:25.580 --> 00:27:28.595
that are now used quite a bit in neural networks, could we,

00:27:28.595 --> 00:27:32.900
um, compress a lot more and quantize, um,

00:27:32.900 --> 00:27:35.450
numeric values so that we can only be, say,

00:27:35.450 --> 00:27:40.385
using two bits fo- per parameter so they'll literally need four bits per parameter?

00:27:40.385 --> 00:27:42.890
And if you do that naively, it doesn't work.

00:27:42.890 --> 00:27:48.500
But if you explore some cleverer ways of doing it and see how to make things work,

00:27:48.500 --> 00:27:51.455
you can actually get it to work, um, really well.

00:27:51.455 --> 00:27:54.680
Um, in fact, it actually seems like sometimes you can improve

00:27:54.680 --> 00:27:59.390
your performance doing this because the quantization acts as a form of regularizer.

00:27:59.390 --> 00:28:03.290
Um, you can find lots of other projects, um, online,

00:28:03.290 --> 00:28:07.145
if you look at the CS224n pages and you should.

00:28:07.145 --> 00:28:08.990
Um, okay.

00:28:08.990 --> 00:28:12.830
So, if you want to do a final project you have to find someplace to start.

00:28:12.830 --> 00:28:15.950
You know, one place is to start looking at papers there's

00:28:15.950 --> 00:28:19.760
online anthology of most of the NLP conference papers.

00:28:19.760 --> 00:28:23.690
You can look at M- ML conferences have lots of relevant papers as well.

00:28:23.690 --> 00:28:28.715
You can look at past CS224n papers that cover lots of topics.

00:28:28.715 --> 00:28:33.200
Um, though, you know, I- I sugge- don't also forget, um,

00:28:33.200 --> 00:28:36.185
the advice down the bottom, um,

00:28:36.185 --> 00:28:39.980
which is look for an interesting problem in the world.

00:28:39.980 --> 00:28:43.670
Um, so, our Stanford's CS emeritus professor

00:28:43.670 --> 00:28:47.240
Ed Feigenbaum likes to quote the advice of his,

00:28:47.240 --> 00:28:50.465
um, advisor, Herb Simon, um,

00:28:50.465 --> 00:28:55.655
of "If you see a research area where many people are working, go somewhere else."

00:28:55.655 --> 00:28:56.870
Um, well, you know,

00:28:56.870 --> 00:29:01.115
in the context of this class don't go so far away that you're not using

00:29:01.115 --> 00:29:05.825
neural networks or NLP because that won't work for project for this class.

00:29:05.825 --> 00:29:08.090
But, you know, nevertheless, I mean,

00:29:08.090 --> 00:29:10.250
in some sense it's a bad strategy of

00:29:10.250 --> 00:29:12.920
saying let's look at all the papers that were published last year,

00:29:12.920 --> 00:29:15.485
and let's wo- start working on one of their problems,

00:29:15.485 --> 00:29:18.605
or lots of people are working on question-answering, I'll do it too.

00:29:18.605 --> 00:29:21.695
You know, there are lots of interesting different problems

00:29:21.695 --> 00:29:24.245
in the world and if you know of some, you know,

00:29:24.245 --> 00:29:28.340
cool website that somehow does something interesting related to language,

00:29:28.340 --> 00:29:31.505
you know, maybe you can make a final project out of that.

00:29:31.505 --> 00:29:34.685
Um, other ways to find final projects.

00:29:34.685 --> 00:29:38.090
Um, so the person who's first put together most of

00:29:38.090 --> 00:29:43.220
the CS231n content was And- Andrej Karpathy, um,

00:29:43.220 --> 00:29:46.760
who now works at Tesla and among his other- things

00:29:46.760 --> 00:29:50.735
he did for the world he put together this site Arxiv Sanity Preserver, um,

00:29:50.735 --> 00:29:54.560
which is a way to find online archive papers which is

00:29:54.560 --> 00:29:59.000
a major pre-print server and if you say a few papers you're interested in,

00:29:59.000 --> 00:30:01.430
it'll show you other papers that you're interested in.

00:30:01.430 --> 00:30:03.755
It'll show you papers that are currently trending.

00:30:03.755 --> 00:30:05.705
So, that can be a good way to look.

00:30:05.705 --> 00:30:08.150
Um, if you think it'd be just good to be in

00:30:08.150 --> 00:30:10.610
some competition where you're wanting to

00:30:10.610 --> 00:30:13.205
build a system that's better than other people's,

00:30:13.205 --> 00:30:16.415
um, you can look at leaderboards for various tasks.

00:30:16.415 --> 00:30:19.160
So, there's this brand new site which is pretty good though

00:30:19.160 --> 00:30:21.950
not completely error free and correct, of

00:30:21.950 --> 00:30:26.120
paperswithcode.com, and it collects a whole lot of

00:30:26.120 --> 00:30:31.190
leaderboards for a whole lot of machine learning tasks including tons of language ones.

00:30:31.190 --> 00:30:33.860
So, it gives leaderboards for question answering,

00:30:33.860 --> 00:30:35.990
machine translation, named entity recognition,

00:30:35.990 --> 00:30:38.090
language modeling, part of speech tagging.

00:30:38.090 --> 00:30:40.115
All sorts of tasks you can find there,

00:30:40.115 --> 00:30:44.670
and find out what the current states of the art and datasets are.

00:30:44.920 --> 00:30:48.470
Okay. Um, so, you know,

00:30:48.470 --> 00:30:50.300
different projects are different,

00:30:50.300 --> 00:30:54.680
but often for a lot of projects the things you need to be making sure of is

00:30:54.680 --> 00:30:59.210
that something that you can get a decent amount of data about so you can train a model.

00:30:59.210 --> 00:31:00.800
It's a feasible task,

00:31:00.800 --> 00:31:04.100
it's not so enormous you can't possibly do it in four weeks.

00:31:04.100 --> 00:31:08.420
Um, you'll want to have some evaluation metric and

00:31:08.420 --> 00:31:10.760
normally for deep learning you have to have-

00:31:10.760 --> 00:31:13.220
even if you hope to do some human evaluation,

00:31:13.220 --> 00:31:17.105
as well, you have to have some automatic evaluation metric.

00:31:17.105 --> 00:31:19.655
Because unless there's just some code that you can run

00:31:19.655 --> 00:31:22.415
that gives you a score for how well you're doing,

00:31:22.415 --> 00:31:24.020
then unless you have that,

00:31:24.020 --> 00:31:27.920
you just sort of can't do the deep learning trick of saying, "Okay,

00:31:27.920 --> 00:31:34.040
let's, um, do backpropagation to optimize our scores according to this metric."

00:31:34.040 --> 00:31:39.050
And pretty much you'll want to do that to be able to do neural network optimization.

00:31:39.050 --> 00:31:45.020
Um, and we do require that there is an important part of NLP in your class project.

00:31:45.020 --> 00:31:46.400
I mean, it doesn't have to be only thing,

00:31:46.400 --> 00:31:48.665
you can be doing reinforcement learning as well,

00:31:48.665 --> 00:31:51.380
or you could do images to caption, say you're

00:31:51.380 --> 00:31:53.300
doing joint vision and NLP,

00:31:53.300 --> 00:31:55.650
but there has to be NLP in it.

00:31:55.650 --> 00:32:02.345
Okay. Ah, last bit before I get back onto the content from last week.

00:32:02.345 --> 00:32:07.605
Ah, so, something that you'll need to do is have data for your project.

00:32:07.605 --> 00:32:12.365
Um, so some people collect their own data for a project and, you know,

00:32:12.365 --> 00:32:14.700
it's not impossible to collect your own data

00:32:14.700 --> 00:32:17.950
especially if there's something you can do with unsupervised data.

00:32:17.950 --> 00:32:21.455
You might be able to get it by just sort of crawling an interesting website.

00:32:21.455 --> 00:32:25.170
You can annotate a small amount of data yourself.

00:32:25.170 --> 00:32:28.665
If you have any site that has some kind of, you know,

00:32:28.665 --> 00:32:31.325
ratings annotation stars on it,

00:32:31.325 --> 00:32:36.210
you can treat those as a form of, ah, annotation.

00:32:36.210 --> 00:32:41.985
Right? So, if you want to predict something like, um, you know,

00:32:41.985 --> 00:32:46.670
which descriptions on product review websites

00:32:46.670 --> 00:32:50.230
or which reviews on product review websites do people like?

00:32:50.230 --> 00:32:53.290
Well, they get star ratings at the bottom from people and

00:32:53.290 --> 00:32:56.605
then you can try and fit to that as your supervision.

00:32:56.605 --> 00:33:01.030
Um, sometimes people have data from an existing project for a company.

00:33:01.030 --> 00:33:02.630
You can use that.

00:33:02.630 --> 00:33:05.330
But nevertheless for most people, um,

00:33:05.330 --> 00:33:08.130
given that classes are short and things like that,

00:33:08.130 --> 00:33:10.530
the practical thing to do is use

00:33:10.530 --> 00:33:15.190
an existing curated dataset that's been built by previous researchers.

00:33:15.190 --> 00:33:20.120
That normally gives you a fast start and lets you get to work building models, um,

00:33:20.120 --> 00:33:21.935
there's obvious prior work,

00:33:21.935 --> 00:33:24.630
there are baselines and previous systems

00:33:24.630 --> 00:33:28.250
that you can compare your performance on, et cetera.

00:33:28.250 --> 00:33:32.040
Okay. Um, so, where can you find data?

00:33:32.040 --> 00:33:35.145
I'll just mention a couple of places here and there are lots more.

00:33:35.145 --> 00:33:37.470
So, traditionally the biggest source of

00:33:37.470 --> 00:33:40.540
linguistic data used by academics was this place called

00:33:40.540 --> 00:33:43.420
the Linguistic Data Consortium and they have lots of

00:33:43.420 --> 00:33:46.960
datasets for treebanks and named entities and coreference,

00:33:46.960 --> 00:33:48.980
parallel machine, translation data,

00:33:48.980 --> 00:33:50.405
et cetera, et cetera.

00:33:50.405 --> 00:33:55.310
And so, um, the Linguistic Data Consortium licenses their data,

00:33:55.310 --> 00:33:59.110
Stanford pays that license so you can use any of it.

00:33:59.110 --> 00:34:01.500
Um, but if you want to use it, um,

00:34:01.500 --> 00:34:05.355
you go to that, um, linguistics.stanford.edu page.

00:34:05.355 --> 00:34:08.315
And there's a sign-up, um, ah,

00:34:08.315 --> 00:34:12.490
piece on how to sign up where you basically, um, say,

00:34:12.490 --> 00:34:14.200
"I will use this data only for

00:34:14.200 --> 00:34:17.940
good Stanford purposes and not as the basis of my startup."

00:34:17.940 --> 00:34:21.075
And, um, then you can have access to that data

00:34:21.075 --> 00:34:24.785
and it can be made available by NFS or otherwise.

00:34:24.785 --> 00:34:27.340
Um, but as time has gone by,

00:34:27.340 --> 00:34:32.280
there's a ton of curated NLP data that's available on various websites.

00:34:32.280 --> 00:34:34.610
In fact, if anything the problem is it's just sort of

00:34:34.610 --> 00:34:37.985
spread over the web and that's sort of hard to find different things.

00:34:37.985 --> 00:34:42.310
But there are some, some sites that have a lot of data for various purposes.

00:34:42.310 --> 00:34:45.975
So, anything related to machine translation or just parallel,

00:34:45.975 --> 00:34:47.975
um, data across different languages.

00:34:47.975 --> 00:34:52.680
The statistical MT statmt.org site has a great amount of

00:34:52.680 --> 00:34:57.425
data and that organization runs shared tasks every year,

00:34:57.425 --> 00:34:59.315
the Workshop on Machine Translation,

00:34:59.315 --> 00:35:03.365
WMT which Abby already mentioned in her class.

00:35:03.365 --> 00:35:05.280
And they've got datasets that we use for

00:35:05.280 --> 00:35:08.210
those tasks and then there are leaderboards for those tasks.

00:35:08.210 --> 00:35:10.410
And you can find data for that.

00:35:10.410 --> 00:35:13.900
Um, if you thought dependency parsing was cool, um,

00:35:13.900 --> 00:35:18.695
there's the Universal Dependencies site which has parallel, not parallel site,

00:35:18.695 --> 00:35:21.720
which has treebanks in the same annotation scheme for

00:35:21.720 --> 00:35:24.300
about 60 different languages and you can work on

00:35:24.300 --> 00:35:27.800
parsers for different languages and things like that.

00:35:27.800 --> 00:35:31.330
Um, I'm not gonna bore you with going through all of them but, you know,

00:35:31.330 --> 00:35:33.840
there are just tons and tons of other datasets that

00:35:33.840 --> 00:35:37.675
Facebook has released datasets, Google's released datasets,

00:35:37.675 --> 00:35:41.375
I said Stanford have released several other datasets including

00:35:41.375 --> 00:35:45.230
the Stanford Sentiment Treebank and the Stanford Na- Natural Language, um,

00:35:45.230 --> 00:35:48.780
Inference corpus, uh, new question-answering datasets and

00:35:48.780 --> 00:35:52.980
including HotPotQA and conversational question answering.

00:35:52.980 --> 00:35:56.180
Other groups at different universities have released datasets.

00:35:56.180 --> 00:35:57.660
There are just tons of them.

00:35:57.660 --> 00:36:02.955
You can find data on sites like Kaggle where it has machine-learning competitions.

00:36:02.955 --> 00:36:06.020
There are sites with lists of datasets.

00:36:06.020 --> 00:36:09.860
You can look at research papers and see what datasets they used.

00:36:09.860 --> 00:36:12.695
And of course, you can ask the course staff or on Piazza

00:36:12.695 --> 00:36:16.305
to try and find suitable datasets for a project.

00:36:16.305 --> 00:36:19.570
Okay. Um, so that's a fair bit about

00:36:19.570 --> 00:36:23.180
the projects that I've got a bit more to say later about doing projects.

00:36:23.180 --> 00:36:27.230
Does anyone have any questions up until now on projects?

00:36:28.640 --> 00:36:34.180
Okay. Um, well, so now we're gonna sort of, um,

00:36:34.180 --> 00:36:39.205
flip a switch in our brains and go back and have one more look,

00:36:39.205 --> 00:36:42.105
um, at gated recurrent units,

00:36:42.105 --> 00:36:45.490
um, and what happens and what they mean.

00:36:45.490 --> 00:36:47.245
Um, and, you know,

00:36:47.245 --> 00:36:48.725
this is sort of,

00:36:48.725 --> 00:36:51.570
sort of the same material that Abby presented,

00:36:51.570 --> 00:36:54.065
presented a little bit differently but, you know,

00:36:54.065 --> 00:36:57.130
I hope it might just sort of give one more way of

00:36:57.130 --> 00:37:00.520
sort of thinking a bit about what's happening about

00:37:00.520 --> 00:37:03.795
these gated recurrent units and why they might be doing

00:37:03.795 --> 00:37:07.445
something useful and what are the alternatives to them.

00:37:07.445 --> 00:37:11.640
So, if you remember the problem we started with is that we

00:37:11.640 --> 00:37:16.525
wanted to understand sort of derivatives backward in time.

00:37:16.525 --> 00:37:18.270
And so, the idea of that is well,

00:37:18.270 --> 00:37:22.064
if we twiddle this a little bit at time T,

00:37:22.064 --> 00:37:27.240
how much effect is that going to have so we make some adjustment here.

00:37:27.240 --> 00:37:32.045
How much effect is that going to have n time steps later?

00:37:32.045 --> 00:37:38.210
Um, and well, we sort of looked at the derivatives and we sort of saw we got these,

00:37:38.210 --> 00:37:41.900
um, terms for each successive time step.

00:37:41.900 --> 00:37:48.700
And so as Abby discussed the problem is that for the derivatives that we got,

00:37:48.700 --> 00:37:52.225
we kind of got this matrix form for each time step.

00:37:52.225 --> 00:37:55.165
And so that if we're going through a lot of time steps,

00:37:55.165 --> 00:38:00.585
we got a lot of matrix multiplies and as the result of those matrix multiplies,

00:38:00.585 --> 00:38:03.280
pretty much either things disappeared down to

00:38:03.280 --> 00:38:07.280
zero or exploded upward depending on what was in the matrix.

00:38:07.280 --> 00:38:10.235
And so that- and so that's sort of means we,

00:38:10.235 --> 00:38:11.590
When the gradient goes to zero,

00:38:11.590 --> 00:38:14.870
we kind of can't know what's happening there.

00:38:14.870 --> 00:38:18.630
Whether there isn't any conditioning or just we can't measure it.

00:38:18.630 --> 00:38:23.030
And so that's sort of made people think that maybe this naive, um,

00:38:23.030 --> 00:38:29.350
recurrent neural network transition function just isn't a good one to use.

00:38:29.350 --> 00:38:33.755
And that sort of leads into these ideas of gated recurrent units.

00:38:33.755 --> 00:38:35.930
Right? Because if we have

00:38:35.930 --> 00:38:39.245
the simple recurrent neural network where we're

00:38:39.245 --> 00:38:42.800
sort of feeding forward for each step in time.

00:38:42.800 --> 00:38:45.520
Well, what happens is when we backpropagate.

00:38:45.520 --> 00:38:46.950
We have to backpropagate through

00:38:46.950 --> 00:38:52.230
every intermediate node and that's where we sort of have our gradients disappear.

00:38:52.230 --> 00:38:57.190
And so an idea of how you could fix that is to say well,

00:38:57.190 --> 00:39:03.130
suppose we just put in direct connections that were longer distance, um,

00:39:03.130 --> 00:39:07.215
then we'd also get direct backpropagation signal

00:39:07.215 --> 00:39:11.855
and so then we wouldn't have this same problem of vanishing gradients.

00:39:11.855 --> 00:39:17.130
And effectively, we've sort of looked at two ways in which you can achieve that effect.

00:39:17.130 --> 00:39:21.240
Because one way of you can achieve that effect which Abby looked at

00:39:21.240 --> 00:39:25.450
in the end part of the last lecture was this idea of attention.

00:39:25.450 --> 00:39:27.455
So, when you've got attention,

00:39:27.455 --> 00:39:31.890
you're actually are creating these shortcut connections,

00:39:31.890 --> 00:39:33.770
oops, they're the blue ones, um,

00:39:33.770 --> 00:39:38.870
from every time step and using it to calculate an attention distribution.

00:39:38.870 --> 00:39:41.320
But the way the attention was done that we looked at,

00:39:41.320 --> 00:39:46.125
it was sort of mushing together all previous time steps into some kind of an average.

00:39:46.125 --> 00:39:50.550
But the idea of the gated recurrent units is in some sense we want to

00:39:50.550 --> 00:39:55.760
achieve this same kind of ability to have shortcut connections.

00:39:55.760 --> 00:39:57.955
But we want to do it in

00:39:57.955 --> 00:40:04.415
a more controlled and adaptive fashion where we still do remember the position of things.

00:40:04.415 --> 00:40:08.975
So, how can we create an adaptive shortcut connection?

00:40:08.975 --> 00:40:10.770
And so that's, um,

00:40:10.770 --> 00:40:17.580
what we start to do with the gates that are put into a gated recurrent network.

00:40:17.580 --> 00:40:22.355
So, if- so first off we sort of say let's have

00:40:22.355 --> 00:40:26.219
a candidate update which is exactly the same

00:40:26.219 --> 00:40:30.390
as the one that's used in a simple recurrent neural network.

00:40:30.390 --> 00:40:34.285
But what we can do is add a gate.

00:40:34.285 --> 00:40:37.895
And so, the gate will calculate a value from zero to one.

00:40:37.895 --> 00:40:41.595
And so what we're going to do here is mix together

00:40:41.595 --> 00:40:46.210
using our candidate update which is just like

00:40:46.210 --> 00:40:51.720
a simple recurrent neural network which will be then mixed together with simply

00:40:51.720 --> 00:40:57.845
directly carrying forward the hidden state from the previous time step.

00:40:57.845 --> 00:41:02.710
So, once we're doing that we are sort of then adaptively-

00:41:02.780 --> 00:41:09.990
we're adaptively partly using a computation from one time step back,

00:41:09.990 --> 00:41:13.080
um, done as a recurrent neural network.

00:41:13.080 --> 00:41:16.980
And we're partly just inheriting the,

00:41:16.980 --> 00:41:19.540
we're just part- sorry, we're partly inheriting

00:41:19.540 --> 00:41:22.265
the hidden state from the previous time step.

00:41:22.265 --> 00:41:26.240
So, it's sort of like a shortcut connection but we're waiting as to

00:41:26.240 --> 00:41:30.840
how much we're short cutting and how much we're doing our computation.

00:41:30.840 --> 00:41:38.750
And we control that adaptive choice by using a calculation to set the gate.

00:41:38.750 --> 00:41:41.070
And we do that with a sigmoid, um,

00:41:41.070 --> 00:41:46.540
computed over the import and the hidden- previous hidden state and using it again,

00:41:46.540 --> 00:41:50.775
an equation kind of like a simple recurrent neural network.

00:41:50.775 --> 00:41:53.930
Okay. Um, but, you know,

00:41:53.930 --> 00:41:57.725
if you wanted to go a bit further than that,

00:41:57.725 --> 00:42:00.380
um, you could think well,

00:42:00.380 --> 00:42:05.825
maybe sometimes we sort of might actually

00:42:05.825 --> 00:42:11.435
just want to get rid of the stuff that was in the past.

00:42:11.435 --> 00:42:15.470
That maybe the stuff in the past sometimes becomes irrelevant, like,

00:42:15.470 --> 00:42:18.290
maybe sometimes we start a new sentence or a new

00:42:18.290 --> 00:42:21.905
thought and we just want to get rid of the stuff that's in the past.

00:42:21.905 --> 00:42:25.700
And so, that can lead into this idea of having a second gate,

00:42:25.700 --> 00:42:31.355
a reset gate and so the reset gate calculates a value from 0 to 1, um,

00:42:31.355 --> 00:42:33.065
just like the other gates,

00:42:33.065 --> 00:42:38.660
and then we're doing this element wise dot-product between

00:42:38.660 --> 00:42:44.435
the reset gate and the previous hidden state and that's then sort of saying well,

00:42:44.435 --> 00:42:47.900
maybe we want to keep some parts of what was stored

00:42:47.900 --> 00:42:52.355
previously and some parts that we now want to throw away.

00:42:52.355 --> 00:42:56.150
And so we put that into the model as a second gate.

00:42:56.150 --> 00:43:01.010
Um, and so an interesting way to think about that is to sort of think

00:43:01.010 --> 00:43:05.540
about this as if this recurrent neural network is like

00:43:05.540 --> 00:43:10.130
a little tiny computer as the kind of little tiny computers you

00:43:10.130 --> 00:43:15.035
might do in a sort of simple architecture class and if you think about it that way,

00:43:15.035 --> 00:43:20.300
um, for the basic simple recurrent neural network

00:43:20.300 --> 00:43:25.475
the way the tiny computer works is that you've got a bank of registers h,

00:43:25.475 --> 00:43:30.035
your hidden state, and at each time step you have to

00:43:30.035 --> 00:43:37.910
read- whoops, at each time step you have to read the entirety of your bank of registers,

00:43:37.910 --> 00:43:41.000
you do some computation and then you write

00:43:41.000 --> 00:43:44.600
the entirety of your bank of registers and, you know,

00:43:44.600 --> 00:43:47.960
if in terms of thinking about computer architecture,

00:43:47.960 --> 00:43:52.190
that sounds like a pretty bad way to implement a simple computer.

00:43:52.190 --> 00:43:57.545
Um, so precisely what a gated recurrent unit is doing is saying,

00:43:57.545 --> 00:44:01.960
"Well, maybe we can have a slightly more sophisticated little baby computer."

00:44:01.960 --> 00:44:08.095
Instead of that, we could select a subset of the registers that we want to read.

00:44:08.095 --> 00:44:11.170
And so, the reset gate can control that because it can say,

00:44:11.170 --> 00:44:13.720
"We'll just ignore a bunch of the other registers."

00:44:13.720 --> 00:44:20.785
Um, it then will compute a new value based on just these, um,

00:44:20.785 --> 00:44:27.220
stored registers and then the update gate which is also adaptive can say, "Well,

00:44:27.220 --> 00:44:29.305
I want you to write

00:44:29.305 --> 00:44:34.580
some registers but the rest of the registers will just keep their previous value."

00:44:34.580 --> 00:44:37.490
That seems a useful idea to have in a computer.

00:44:37.490 --> 00:44:39.680
And so, that's what we're doing here.

00:44:39.680 --> 00:44:42.710
And so, this model here is, um,

00:44:42.710 --> 00:44:49.115
what was- Abby presented second as the gated recurrent unit.

00:44:49.115 --> 00:44:53.390
So, this is sort of a much more realistic model

00:44:53.390 --> 00:44:57.515
and it sort of in some sense overlaps with the ideas of attention.

00:44:57.515 --> 00:45:03.245
Okay. Um, so gated recurrent units are actually a quite new model.

00:45:03.245 --> 00:45:07.970
Um, the model that was done way earlier and has had huge impact

00:45:07.970 --> 00:45:13.340
is these LSTM long short-term memory units and they are a bit more complex.

00:45:13.340 --> 00:45:15.035
Um, but, you know,

00:45:15.035 --> 00:45:17.690
a lot of it is sort of the same, right?

00:45:17.690 --> 00:45:20.210
So, the hidden state of

00:45:20.210 --> 00:45:25.040
a gated recurrent unit is kind of equivalent to the cell of the LSTM.

00:45:25.040 --> 00:45:29.990
So, both of them are using the same idea of summing together,

00:45:29.990 --> 00:45:34.460
a mixture of just directly interpret- directly inheriting

00:45:34.460 --> 00:45:39.140
what you had from the previous time step together with, um,

00:45:39.140 --> 00:45:43.790
something that you've calculated for the current time step and the way you count-

00:45:43.790 --> 00:45:49.550
calculate it for the current time step is exactly the same in both cases.

00:45:49.550 --> 00:45:53.375
Whoops, sorry. Both cases again that you're calculating

00:45:53.375 --> 00:45:58.130
the current update using this sort of simple RNN equation.

00:45:58.130 --> 00:46:00.560
So, those parts are exactly the same.

00:46:00.560 --> 00:46:04.310
Um, but the LSTM is a little bit more complicated.

00:46:04.310 --> 00:46:07.310
It now has three gates, um,

00:46:07.310 --> 00:46:08.795
and it's got this extra, um,

00:46:08.795 --> 00:46:12.500
hidden state that's then worked out with a bit more complexity.

00:46:12.500 --> 00:46:17.170
So, in terms of my LSTM picture, you know,

00:46:17.170 --> 00:46:22.360
the LSTM picture looks as if you sort of pull apart all of its math pretty

00:46:22.360 --> 00:46:29.990
complex but so there are three gates so that you can forget or ignore everything.

00:46:29.990 --> 00:46:32.030
So, you can forget or ignore the input,

00:46:32.030 --> 00:46:33.890
you can forget or ignore parts of

00:46:33.890 --> 00:46:38.750
your previous hidden state and you can forget or ignore parts of the cell

00:46:38.750 --> 00:46:42.065
when calculating the output and each of these

00:46:42.065 --> 00:46:46.145
is produce- when I say forget or ignore parts of,

00:46:46.145 --> 00:46:50.630
what that's meaning is you're calculating a vector which is then going to be element-wise

00:46:50.630 --> 00:46:56.075
multiplied by the import of the previous hidden state or the cell.

00:46:56.075 --> 00:46:59.270
And so, that's why you have this effective now an addressable bank of

00:46:59.270 --> 00:47:03.335
registers where you can use some of them but not others of them.

00:47:03.335 --> 00:47:06.785
Okay. So, the bottom part of the LSTM is just

00:47:06.785 --> 00:47:10.400
like a simpler simple recurrent neural network,

00:47:10.400 --> 00:47:12.815
um, which then calculates,

00:47:12.815 --> 00:47:15.125
um, a candidate update.

00:47:15.125 --> 00:47:21.290
And so, for both of the GRU and the LSTM the real secret is

00:47:21.290 --> 00:47:24.140
that rather than just keeping on multiplying

00:47:24.140 --> 00:47:28.025
stuff what you do is you add two things together.

00:47:28.025 --> 00:47:32.120
Um, and so this adding is why you don't

00:47:32.120 --> 00:47:36.050
get the same vanishing gradient evil effects because you're calculating a

00:47:36.050 --> 00:47:39.320
new candidate update and you're adding it to stuff that was

00:47:39.320 --> 00:47:42.665
previously in the cell and that gives you

00:47:42.665 --> 00:47:46.190
a simple gradient when you backpropagate that- that you have

00:47:46.190 --> 00:47:52.745
direct linear connection between the cell at time t and the cell at time t minus one.

00:47:52.745 --> 00:47:56.240
And so, really that simple addition there is sort of

00:47:56.240 --> 00:48:00.350
the secret of most of the power of LSTMs and

00:48:00.350 --> 00:48:04.010
this same idea of adding two things together has also been a

00:48:04.010 --> 00:48:08.105
secret of many of the other advances in deep learning recently.

00:48:08.105 --> 00:48:12.455
So, envision in the last couple of years the sort of standard model

00:48:12.455 --> 00:48:17.060
that everybody uses as ResNets, residual networks and they use

00:48:17.060 --> 00:48:23.000
exactly the same secret of allowing these adaptive updates where you add

00:48:23.000 --> 00:48:30.680
together a current layer's value with directly inheriting a value from the layer below.

00:48:30.680 --> 00:48:35.060
Um, other things that use similar ideas are things like highway networks and so on.

00:48:35.060 --> 00:48:39.050
So, that's proven to be an extremely powerful idea.

00:48:39.050 --> 00:48:42.440
Um, the LSTM is slightly different from

00:48:42.440 --> 00:48:46.505
the GRU because when we look back at its equations

00:48:46.505 --> 00:48:53.989
that the- the GRU kind of does a linear mixture where you have one gate value,

00:48:53.989 --> 00:48:57.545
UT, and one minus UT,

00:48:57.545 --> 00:49:02.870
where the LSTM adds values controlled by two different gates,

00:49:02.870 --> 00:49:05.615
a forget gate, and an input gate.

00:49:05.615 --> 00:49:09.290
Theoretically, having the adding of

00:49:09.290 --> 00:49:13.940
two separate gates rather than than a mixture is theoretically more powerful.

00:49:13.940 --> 00:49:16.550
Um, depending on the application,

00:49:16.550 --> 00:49:19.370
sometimes it doesn't seem to make much difference, um,

00:49:19.370 --> 00:49:23.480
but there's definitely a theoretical advantage to the LSTM there.

00:49:23.480 --> 00:49:31.070
Okay. Um, just, I hope that's maybe a little bit more helpful to have seen those again,

00:49:31.070 --> 00:49:35.550
um, any questions on gated recurrent units?

00:49:37.970 --> 00:49:41.350
Still look confusing?

00:49:42.650 --> 00:49:48.450
I think it's useful to have some kind of idea as to why the people come up with

00:49:48.450 --> 00:49:53.670
these things and why do they make sense but,

00:49:53.670 --> 00:49:58.680
you know, nevertheless, the reality is in the sort of era of

00:49:58.680 --> 00:50:03.750
2015 plus any deep learning package you use whether it's PyTorch,

00:50:03.750 --> 00:50:05.940
TensorFlow, MXNet whatever, you know,

00:50:05.940 --> 00:50:11.250
it just comes with LSTM and GRUs and you don't have to program your own.

00:50:11.250 --> 00:50:13.170
In fact, you're at disadvantage if you

00:50:13.170 --> 00:50:16.020
program your own because if you are using the built-in one,

00:50:16.020 --> 00:50:19.070
it's using an efficient CUDA kernel from

00:50:19.070 --> 00:50:23.915
Nvidia whereas your custom built one won't and/or run three times slower.

00:50:23.915 --> 00:50:26.915
Um, so, you know, essentially don't have to know how to do it,

00:50:26.915 --> 00:50:30.530
you can just take the attitude that an LSTM is just like

00:50:30.530 --> 00:50:35.345
a fancy recurrent network which will be easier to train and that's true.

00:50:35.345 --> 00:50:39.620
Um, but you know, these kind of architectural ideas have actually been

00:50:39.620 --> 00:50:45.420
central to most of the big advances that have come in deep learning in the last couple of years,

00:50:45.420 --> 00:50:47.640
so there's actually good to have an ID,

00:50:47.640 --> 00:50:49.920
to have some sense of what were

00:50:49.920 --> 00:50:53.685
these important ideas that made everything so much better because they had

00:50:53.685 --> 00:50:56.850
the same kind of component building blocks you might also want

00:50:56.850 --> 00:51:00.970
to use in custom models that you design for yourself.

00:51:02.120 --> 00:51:06.840
Okay, two bits of machine translation.

00:51:06.840 --> 00:51:11.250
Um, so a bit of machine translation that we

00:51:11.250 --> 00:51:15.720
sort of didn't cover next week but lots of people have been seeing

00:51:15.720 --> 00:51:19.920
and getting confused by in the assignments so I thought I'd explain

00:51:19.920 --> 00:51:24.210
a bit about is UNKs and explain where do UNKs

00:51:24.210 --> 00:51:28.410
come from and why are there UNKs and the reason why

00:51:28.410 --> 00:51:33.075
there are UNKs is effectively kind of for efficiency reasons.

00:51:33.075 --> 00:51:39.705
So, if you sort of think about producing output in a neural machine translation system

00:51:39.705 --> 00:51:43.170
and really this is the same as producing output

00:51:43.170 --> 00:51:46.680
in any natural, neural natural language generation system,

00:51:46.680 --> 00:51:49.785
so that's really the same for neural language model, um,

00:51:49.785 --> 00:51:56.970
that if you have a very large output vocabulary is just a expensive operation.

00:51:56.970 --> 00:52:04.850
So you have a big matrix of softmax parameters where you have a row for every word, um,

00:52:04.850 --> 00:52:12.420
and then you have what,

00:52:12.420 --> 00:52:15.330
[NOISE] then we have an animation that is not working for me.

00:52:15.330 --> 00:52:18.210
Oh, all right there, there we go.

00:52:18.210 --> 00:52:21.030
Um, so then we have some hidden state that we've

00:52:21.030 --> 00:52:25.335
calculated in our recurrent neural network.

00:52:25.335 --> 00:52:29.985
And so, what we gonna do is sort of multiply, um,

00:52:29.985 --> 00:52:33.105
that vector by every row of the matrix,

00:52:33.105 --> 00:52:39.030
put it through a softmax and then get probabilities without putting every word.

00:52:39.030 --> 00:52:40.770
Um, and you know,

00:52:40.770 --> 00:52:44.040
this seems pretty simple but the problem is that

00:52:44.040 --> 00:52:47.400
to the extent that you have a humongous vocabulary here,

00:52:47.400 --> 00:52:51.240
you just have to do a humongous number of rows

00:52:51.240 --> 00:52:55.185
of this multiplication and it actually turns out that

00:52:55.185 --> 00:52:59.025
doing this is the expensive part of

00:52:59.025 --> 00:53:03.600
having a neural machine translation or neural language model system, right?

00:53:03.600 --> 00:53:07.380
The LSTM might look complicated and hard to understand, but you know,

00:53:07.380 --> 00:53:11.939
it's relatively small vectors that you multiply or dot-product once,

00:53:11.939 --> 00:53:16.020
and it's not that much work whereas if you have a huge number of words,

00:53:16.020 --> 00:53:17.430
this is a huge amount of work.

00:53:17.430 --> 00:53:22.560
So, just for instance sort of for the pion- pioneering sequence to sequence,

00:53:22.560 --> 00:53:26.355
um, neural machine translation system that Google first did,

00:53:26.355 --> 00:53:30.840
they ran it on an eight GPU machine because they have lots of GPUs but

00:53:30.840 --> 00:53:36.075
the way they set it up to maximize performance was of those eight GPUs,

00:53:36.075 --> 00:53:38.490
three of them were running

00:53:38.490 --> 00:53:44.070
a deep multi-layer neural sequence model and the other five GPUs,

00:53:44.070 --> 00:53:47.970
the only thing that they were doing was calculating softmaxes because that's

00:53:47.970 --> 00:53:52.770
actually the bulk of the computation that you need to be able to do.

00:53:52.770 --> 00:53:56.850
Um, so the simplest way to make this, um,

00:53:56.850 --> 00:54:01.560
computation not completely excessive is to say,

00:54:01.560 --> 00:54:03.930
"Hey, I'll just limit the vocabulary."

00:54:03.930 --> 00:54:07.365
Yeah I know that you can make

00:54:07.365 --> 00:54:13.230
a million different words in English and if you look at Spanish inflections of verbs,

00:54:13.230 --> 00:54:16.245
there are a lot of them and there's gonna be huge number of words, um,

00:54:16.245 --> 00:54:20.220
but maybe I can just make do with a modest vocabulary and it'll be near enough.

00:54:20.220 --> 00:54:22.305
Surely 50,000 common words,

00:54:22.305 --> 00:54:25.245
I can cover a lot of stuff and so,

00:54:25.245 --> 00:54:29.580
that was sort of the starting off point of neural machine translation that you,

00:54:29.580 --> 00:54:34.515
people use the modest vocabulary like around 50,000 words.

00:54:34.515 --> 00:54:36.915
And well, if you do that, um,

00:54:36.915 --> 00:54:40.980
well, then what happens is you have UNKs.

00:54:40.980 --> 00:54:43.260
So UNK means, this is an unknown word,

00:54:43.260 --> 00:54:47.325
that's not in my vocabulary and so there are two kinds of UNKs,

00:54:47.325 --> 00:54:51.315
they can be UNKs in the source language and you know,

00:54:51.315 --> 00:54:55.710
they're sort of optional because, you know,

00:54:55.710 --> 00:54:59.475
it's not actually a problem having a large source language vocabulary,

00:54:59.475 --> 00:55:02.070
but the fact of the matter is if you've sort of trained

00:55:02.070 --> 00:55:04.620
a model on a certain amount of data,

00:55:04.620 --> 00:55:06.720
there are some words you aren't going to have seen,

00:55:06.720 --> 00:55:09.000
so you are going to have words that you just didn't

00:55:09.000 --> 00:55:11.520
see in your training data and you won't have

00:55:11.520 --> 00:55:14.430
any pre-trained or trained word vector

00:55:14.430 --> 00:55:17.760
for them and you can deal with that by either just treating them as UNK,

00:55:17.760 --> 00:55:20.595
so giving them a new word vector when you encounter them.

00:55:20.595 --> 00:55:24.570
But the tricky part is on the translation that you're wanting to

00:55:24.570 --> 00:55:28.725
produce these rare words but they're not in your output vocabulary,

00:55:28.725 --> 00:55:35.550
so your system is producing UNK, UNK to UNK, which is not a very good translation really.

00:55:35.550 --> 00:55:39.720
Um, yeah, and so that was sort of what the first,

00:55:39.720 --> 00:55:44.220
um, machine, neural machine translation systems, um, did.

00:55:44.220 --> 00:55:46.260
And so, you know, obviously that's not

00:55:46.260 --> 00:55:51.555
a very satisfactory state of affairs and so there's been a whole bunch of work,

00:55:51.555 --> 00:55:53.220
um, as to how to deal with this,

00:55:53.220 --> 00:56:00.465
so you can use methods that allow you to deal with a larger output vocabulary,

00:56:00.465 --> 00:56:03.780
um, without the computation being excessive.

00:56:03.780 --> 00:56:07.785
So one method of doing that is to have what's called a hierarchical softmax,

00:56:07.785 --> 00:56:11.505
so that rather than just having a huge matrix of words,

00:56:11.505 --> 00:56:14.910
you sort of have a tree structure in your vocabulary

00:56:14.910 --> 00:56:18.480
so you can do calculations with hierarchical,

00:56:18.480 --> 00:56:22.815
um, multiple small softmaxes and you can do that more quickly.

00:56:22.815 --> 00:56:25.620
Um, I'm not gonna go through all these exam,

00:56:25.620 --> 00:56:27.270
all these things in detail now,

00:56:27.270 --> 00:56:31.575
I'm just sort of very quickly mentioning them and if anyone's interested, they can look.

00:56:31.575 --> 00:56:34.830
People have used the noise-contrastive estimation idea that we

00:56:34.830 --> 00:56:38.235
saw with Word2vec in this context as well.

00:56:38.235 --> 00:56:42.660
So this is a way to get much faster training which is important,

00:56:42.660 --> 00:56:45.315
it's not really a way to solve, um,

00:56:45.315 --> 00:56:47.790
speed at translation time but, you know,

00:56:47.790 --> 00:56:50.580
if this means you can train your system in six hours instead of

00:56:50.580 --> 00:56:55.155
six days that's a big win and so that's a good technique to use.

00:56:55.155 --> 00:57:00.330
Um, people have done much smarter things, so really, um,

00:57:00.330 --> 00:57:03.750
the large vocabulary problem is basically solved

00:57:03.750 --> 00:57:07.650
now and so the kind of things that you can do is you can produce

00:57:07.650 --> 00:57:11.970
subsets of your vocabulary and train on particular subsets of

00:57:11.970 --> 00:57:16.380
vocabulary at a time and then when you're testing,

00:57:16.380 --> 00:57:20.820
you adaptively choose kind of a likely list of words that might

00:57:20.820 --> 00:57:25.290
appear in the translation of particular sentences or passages and then

00:57:25.290 --> 00:57:28.200
you can effectively work with sort of an appropriate subset of

00:57:28.200 --> 00:57:32.850
a vocabulary and that's sort of an efficient technique by which you can

00:57:32.850 --> 00:57:36.330
deal with an unlimited vocabulary but only be using

00:57:36.330 --> 00:57:41.955
a moderate sized softmax for any particular paragraph that you're translating,

00:57:41.955 --> 00:57:44.790
there's a paper that talks about that method.

00:57:44.790 --> 00:57:49.425
Um, another idea is you can use attention when you do translation,

00:57:49.425 --> 00:57:51.930
the idea talked about at the end of last time.

00:57:51.930 --> 00:57:55.095
So if you have attention, that sort of means that you can,

00:57:55.095 --> 00:57:57.660
you're pointing somewhere in the source and you

00:57:57.660 --> 00:58:00.660
know what you're translating at any point in time.

00:58:00.660 --> 00:58:05.070
So, if that word is a rare word that's not in your vocabulary,

00:58:05.070 --> 00:58:07.560
there are things that you could do to deal with that.

00:58:07.560 --> 00:58:09.930
I mean, firstly, if it's a rare word,

00:58:09.930 --> 00:58:13.140
its translation is much more likely to be constant,

00:58:13.140 --> 00:58:17.475
so you might just look it up in a dictionary or word list, um, and,

00:58:17.475 --> 00:58:19.830
um, stick in its translation,

00:58:19.830 --> 00:58:22.485
sometimes it's appropriate to do other things.

00:58:22.485 --> 00:58:24.450
I mean, turns out that, you know,

00:58:24.450 --> 00:58:29.685
quite a lot of things that unknown words turn out to be other things like, you know,

00:58:29.685 --> 00:58:32.970
hexadecimal numbers, or FedEx tracking IDs,

00:58:32.970 --> 00:58:35.685
or GitHub shards, or things like that.

00:58:35.685 --> 00:58:37.020
So for a lot of things like that,

00:58:37.020 --> 00:58:39.390
the right thing to do is just to copy them across.

00:58:39.390 --> 00:58:42.660
And so, another thing that people have looked at is copying models,

00:58:42.660 --> 00:58:45.220
um, in machine translation.

00:58:45.220 --> 00:58:48.215
Okay, um, there are more ideas that you can,

00:58:48.215 --> 00:58:50.840
we can get into to solve this and actually, um,

00:58:50.840 --> 00:58:52.790
next week we're gonna start dealing with

00:58:52.790 --> 00:58:55.085
some of the other ways that you could solve this, um,

00:58:55.085 --> 00:58:59.405
but I hope there to have given you sort of a sense of,

00:58:59.405 --> 00:59:01.805
um, sort of what these UNKs are about,

00:59:01.805 --> 00:59:03.635
why you see them and, uh,

00:59:03.635 --> 00:59:06.140
that there are sort of some ways that you might

00:59:06.140 --> 00:59:08.600
deal with them but you're not expected to be doing that,

00:59:08.600 --> 00:59:10.900
um, for assignment four.

00:59:10.900 --> 00:59:16.680
Okay, then I just wanted to give a teeny bit more on evaluation.

00:59:16.680 --> 00:59:19.515
Um, so Abby said a little bit about

00:59:19.515 --> 00:59:23.370
evaluation with blue and that then comes up in the assignment,

00:59:23.370 --> 00:59:26.130
so I just thought I'd give you a little bit more context on

00:59:26.130 --> 00:59:29.095
that since they're being quite a few questions about it.

00:59:29.095 --> 00:59:33.045
So, um, so the general context here is, you know,

00:59:33.045 --> 00:59:38.895
how do you evaluate machine translation quality and sort of to this day,

00:59:38.895 --> 00:59:43.980
if you wanted to do a first rate bang up evaluation of machine translation quality,

00:59:43.980 --> 00:59:47.670
the way you do it is you get human beings to assess quality,

00:59:47.670 --> 00:59:50.835
you take translations and you send them to

00:59:50.835 --> 00:59:54.870
human beings with good bilingual skills and get them to score things.

00:59:54.870 --> 00:59:57.255
And there are two ways that are commonly used.

00:59:57.255 --> 00:59:59.550
One is sort of rating on

00:59:59.550 --> 01:00:04.290
Likert scales for things like adequacy and fluency of translations,

01:00:04.290 --> 01:00:09.030
um, but another way that often works better is asking for comparative judgments.

01:00:09.030 --> 01:00:14.035
So here are two translations of this sentence which is better, um.

01:00:14.035 --> 01:00:16.940
And so that's, you know,

01:00:16.940 --> 01:00:20.075
sort of still our gold standard of translation.

01:00:20.075 --> 01:00:22.880
Um, another way you can evaluate translation is

01:00:22.880 --> 01:00:25.925
use your translations in the downstream task.

01:00:25.925 --> 01:00:28.640
So, you could say "I'm gonna build

01:00:28.640 --> 01:00:33.500
a cross-lingual question answering system and inside that system I'm,

01:00:33.500 --> 01:00:35.780
gonna use machine translation.

01:00:35.780 --> 01:00:37.970
I'm gonna translate the questions um,

01:00:37.970 --> 01:00:40.625
and then try and match them against the documents.

01:00:40.625 --> 01:00:45.830
Um, and then my score will be how good my question answering system is,

01:00:45.830 --> 01:00:48.800
and so the machine translation system is better

01:00:48.800 --> 01:00:52.190
if my question-answering score um, goes up."

01:00:52.190 --> 01:00:57.245
I mean, that's kind of a nice way to do things because you're kinda then taking them in, run around needing,

01:00:57.245 --> 01:01:00.110
needing human beings, and yet you do have

01:01:00.110 --> 01:01:03.485
a clear numerical measure that's coming out the back end.

01:01:03.485 --> 01:01:06.545
But it sort of has some catches because, you know,

01:01:06.545 --> 01:01:09.980
often there will be a fairly indirect connection between

01:01:09.980 --> 01:01:14.090
your end task and the quality of the machine translation,

01:01:14.090 --> 01:01:16.640
and it might turn out that there certain aspects of

01:01:16.640 --> 01:01:20.510
the machine translation like whether you get agreement endings,

01:01:20.510 --> 01:01:22.970
right on nouns and verbs or something.

01:01:22.970 --> 01:01:26.120
They are actually just irrelevant to your performance in the task and say you're

01:01:26.120 --> 01:01:29.645
not assessing all aspects of um, quality.

01:01:29.645 --> 01:01:32.810
Um, and so then the third way to do it is to come up with

01:01:32.810 --> 01:01:35.840
some way to score the direct tasks.

01:01:35.840 --> 01:01:40.415
So, here, um, the direct task is machine translation,

01:01:40.415 --> 01:01:44.450
and this has been a valuable tool.

01:01:44.450 --> 01:01:47.300
For, you know, really the last so

01:01:47.300 --> 01:01:51.289
25 years when people are doing machine learning models,

01:01:51.289 --> 01:01:55.100
because as soon as you have an automatic way to score things,

01:01:55.100 --> 01:02:02.060
you can then run automated experiments to say "Let me try out these 50 different options.

01:02:02.060 --> 01:02:07.250
Let me start varying these hyper-parameters and work out which way to do things is best."

01:02:07.250 --> 01:02:10.760
And that importance has only grown in the deep learning era,

01:02:10.760 --> 01:02:15.200
when all the time what we want you to do is as Abby discussed, um,

01:02:15.200 --> 01:02:18.140
build end-to-end systems and then back

01:02:18.140 --> 01:02:21.200
propagate throughout the entire system to improve them,

01:02:21.200 --> 01:02:22.910
and we're doing that based on having

01:02:22.910 --> 01:02:26.465
some objective measure which is our automatic metric.

01:02:26.465 --> 01:02:29.405
And so, that led into the development of

01:02:29.405 --> 01:02:33.364
automatic metrics to try and assess machine translation quality,

01:02:33.364 --> 01:02:38.135
and the most famous and still most used one is this one called BLEU.

01:02:38.135 --> 01:02:41.375
And so, as Abby briefly mentioned,

01:02:41.375 --> 01:02:44.900
we have a reference translation done by human beings.

01:02:44.900 --> 01:02:49.790
At some time a human being has to translate each piece of source material once,

01:02:49.790 --> 01:02:53.180
but then you take a machine translation and you

01:02:53.180 --> 01:02:57.320
score it based on the extent to which there

01:02:57.320 --> 01:03:00.920
are one or more word sequences that appear in

01:03:00.920 --> 01:03:06.065
the reference translation and also appear in the machine translation.

01:03:06.065 --> 01:03:12.530
And so you are working out n-gram preci-precision scores for different values of n. So,

01:03:12.530 --> 01:03:16.010
the standard way of doing it is you do it for one grams,

01:03:16.010 --> 01:03:18.560
bigrams, trigrams, and four-grams.

01:03:18.560 --> 01:03:21.395
So, word sequences of size one to four,

01:03:21.395 --> 01:03:26.270
and you try and find for ones of those in the machine translation,

01:03:26.270 --> 01:03:31.760
whether they also appear in the reference translation,

01:03:31.760 --> 01:03:34.415
and there are two tricks at work here.

01:03:34.415 --> 01:03:39.515
Um, one trick is you have to do a kind of a bipartite matching um,

01:03:39.515 --> 01:03:42.665
because it just can't be that um,

01:03:42.665 --> 01:03:45.185
there's a word um,

01:03:45.185 --> 01:03:49.550
in the, in the reference translation somewhere.

01:03:49.550 --> 01:03:51.230
Um, [NOISE] I don't know if there's.

01:03:51.230 --> 01:03:53.510
I've got a good example here [NOISE].

01:03:53.510 --> 01:03:57.770
Um, maybe I can only do a silly example,

01:03:57.770 --> 01:03:59.555
but I'll do a silly example.

01:03:59.555 --> 01:04:03.320
Um, that it's- it doesn't seem like you wanna say "Okay.

01:04:03.320 --> 01:04:05.420
Because there's a "the" in the reference,

01:04:05.420 --> 01:04:08.975
that means that this "the" is right and this "the" is right,

01:04:08.975 --> 01:04:12.800
and this "the" is right and every other "the" is also right."

01:04:12.800 --> 01:04:14.495
That sort of seems unfair.

01:04:14.495 --> 01:04:20.825
So, you're only allowed to use each thing in the reference once in matching n-grams,

01:04:20.825 --> 01:04:24.140
but you are allowed to use it multiple times for different order n-grams.

01:04:24.140 --> 01:04:26.570
So, you can use it both in the uh unigram,

01:04:26.570 --> 01:04:28.985
bigram, trigram and 4-gram.

01:04:28.985 --> 01:04:32.270
The other idea is that although you're measuring

01:04:32.270 --> 01:04:37.205
the precision of n-grams that are in the machine translation,

01:04:37.205 --> 01:04:39.860
you wouldn't want people to be able to cheat by

01:04:39.860 --> 01:04:42.710
putting almost nothing into the machine translation.

01:04:42.710 --> 01:04:47.450
So, you might wanna game it by no matter what the source document is.

01:04:47.450 --> 01:04:49.520
If the target language is English,

01:04:49.520 --> 01:04:51.110
you could just um say,

01:04:51.110 --> 01:04:52.790
"My translation is the,

01:04:52.790 --> 01:04:55.490
because I'm pretty sure that will be in

01:04:55.490 --> 01:04:59.315
the reference translation somewhere and I'll get 0.3 unigram,

01:04:59.315 --> 01:05:02.840
and that's not great but I'll get something for that and I am done."

01:05:02.840 --> 01:05:04.880
And so you wouldn't want that and so,

01:05:04.880 --> 01:05:08.870
you're then being penalized by something called the brevity penalty if

01:05:08.870 --> 01:05:14.040
your translation is shorter than the reference translation,

01:05:14.040 --> 01:05:18.370
and so this BLEU metric is um forming

01:05:18.370 --> 01:05:24.280
a geometric average of n-gram precision up to some n. Normally,

01:05:24.280 --> 01:05:25.300
it's sort of up to four,

01:05:25.300 --> 01:05:26.485
is how it's done.

01:05:26.485 --> 01:05:29.004
Where it's a weighted geometric average,

01:05:29.004 --> 01:05:32.415
where you're putting weights on the different n-grams.

01:05:32.415 --> 01:05:35.870
Um, for the assignment, we're only using unigrams and bigrams.

01:05:35.870 --> 01:05:39.455
So, you could say that means we're putting a weight of zero on um,

01:05:39.455 --> 01:05:42.650
the trigrams and 4-grams.

01:05:42.650 --> 01:05:46.235
Okay. Um, and so that's basically what we're doing.

01:05:46.235 --> 01:05:49.280
I-I've just mentioned um couple of other things.

01:05:49.280 --> 01:05:51.845
You might think that this is kind of random,

01:05:51.845 --> 01:05:53.780
and so people have um,

01:05:53.780 --> 01:05:57.530
used this idea of rather than just having one reference translation,

01:05:57.530 --> 01:06:00.080
we could have multiple reference translations,

01:06:00.080 --> 01:06:02.720
because that way we can allow for there being

01:06:02.720 --> 01:06:05.540
variation and good ways of translating things,

01:06:05.540 --> 01:06:09.740
because in language there's always lots of good ways that you can translate one sentence.

01:06:09.740 --> 01:06:12.425
Um, people have done that quite a bit,

01:06:12.425 --> 01:06:16.820
but people have also decided that even if you have one translation,

01:06:16.820 --> 01:06:20.990
provided it's independent and on a kind of statistical basis,

01:06:20.990 --> 01:06:25.340
you're still more likely to match it if your translation is a good translation.

01:06:25.340 --> 01:06:27.560
So, it's probably okay.

01:06:27.560 --> 01:06:32.930
Um, so when BLEU was originally um, introduced,

01:06:32.930 --> 01:06:37.370
BLEU seemed marvelous and people drew graphs like this showing how

01:06:37.370 --> 01:06:41.915
closely BLEU scores correlated um,

01:06:41.915 --> 01:06:45.605
with human judgments of translation quality.

01:06:45.605 --> 01:06:48.710
However, um, like a lot of things in life,

01:06:48.710 --> 01:06:50.900
there are a lot of things that are great measures,

01:06:50.900 --> 01:06:53.870
providing people aren't directly trying to optimize it,

01:06:53.870 --> 01:06:56.720
and so what's happened since then um,

01:06:56.720 --> 01:07:00.620
is that everybody has been trying to optimize BLEU scores,

01:07:00.620 --> 01:07:06.380
and the result of that is that BLEU scores have gone up massively but the correlation

01:07:06.380 --> 01:07:08.540
between BLEU scores and human judgments of

01:07:08.540 --> 01:07:12.185
translation in quality have gone down massively,

01:07:12.185 --> 01:07:16.550
and so we're in this current state that um, the BLEU scores,

01:07:16.550 --> 01:07:22.640
the machines, um are pretty near the scores of human translations.

01:07:22.640 --> 01:07:24.800
So, you know, according to BLEU scores,

01:07:24.800 --> 01:07:28.565
we're producing almost human quality machine translation,

01:07:28.565 --> 01:07:32.690
but if you actually look at the real quality of the translations,

01:07:32.690 --> 01:07:34.100
they're still well behind

01:07:34.100 --> 01:07:39.560
human beings um and because you could say the metric is being gamed.

01:07:39.560 --> 01:07:45.950
Okay. I'll hope those things help for giving more sense um for assignment four.

01:07:45.950 --> 01:07:48.260
Um, so now for the last um,

01:07:48.260 --> 01:07:50.135
about 12 minutes, um,

01:07:50.135 --> 01:07:51.500
I just now wanna um,

01:07:51.500 --> 01:07:58.160
return to um final projects and say a little bit more um about final projects.

01:07:58.160 --> 01:08:01.205
Um so, there many,

01:08:01.205 --> 01:08:03.710
many different ways you can do final projects,

01:08:03.710 --> 01:08:06.290
but just to sort of go through the steps.

01:08:06.290 --> 01:08:09.170
I mean, you know, for a simple straightforward project,

01:08:09.170 --> 01:08:11.510
this is kind of the steps that you want to go through.

01:08:11.510 --> 01:08:13.295
So, you choose some tasks,

01:08:13.295 --> 01:08:17.375
summarizing text um, producing a shorter version of a text.

01:08:17.375 --> 01:08:20.180
You work out some dataset that you can use.

01:08:20.180 --> 01:08:22.970
So, this is an example of the kind of tasks that there

01:08:22.970 --> 01:08:26.015
are academic data sets for that other people have used,

01:08:26.015 --> 01:08:28.250
and so you could just use one of those,

01:08:28.250 --> 01:08:31.730
and that's it, you're already done or you could think "Oh no!

01:08:31.730 --> 01:08:33.350
I'm much too creative for that.

01:08:33.350 --> 01:08:38.780
I'm gonna come up with my own dataset [NOISE] um and get some online source and do it."

01:08:38.780 --> 01:08:40.370
Um, and you know,

01:08:40.370 --> 01:08:45.800
summaries of the kind of things you can find online and produce your own dataset.

01:08:45.800 --> 01:08:48.805
Um [NOISE] I wanna say a bit in,

01:08:48.805 --> 01:08:50.395
in just after this,

01:08:50.395 --> 01:08:53.380
about separating off um data sets for

01:08:53.380 --> 01:08:56.860
training and test data, so I'll delay that, but that's important.

01:08:56.860 --> 01:09:01.445
Then, you want to work out a way to evaluate your um,

01:09:01.445 --> 01:09:04.940
system including an automatic evaluation.

01:09:04.940 --> 01:09:06.530
Um, normally, for summarization,

01:09:06.530 --> 01:09:08.510
people use a slightly different metric called

01:09:08.510 --> 01:09:12.335
ROUGE but it's sort of related to BLEU hence its name.

01:09:12.335 --> 01:09:14.960
Um, it's the same story that it sort of works,

01:09:14.960 --> 01:09:17.165
but human evaluation is much better.

01:09:17.165 --> 01:09:21.335
Um, but you need- so you need to work out some metrics you can use for the project.

01:09:21.335 --> 01:09:25.535
Um, the next thing you should do is establish a baseline.

01:09:25.535 --> 01:09:29.555
So, if it's a well-worked on problem there might already be one,

01:09:29.555 --> 01:09:33.170
but it's not bad to try and calculate one for yourself anyway,

01:09:33.170 --> 01:09:36.170
and in particular what you should first have is

01:09:36.170 --> 01:09:39.440
a very simple model and see how well it works.

01:09:39.440 --> 01:09:42.155
So, for human language material,

01:09:42.155 --> 01:09:45.020
often doing things like bag of words models,

01:09:45.020 --> 01:09:48.050
whether they're just a simple classifier over

01:09:48.050 --> 01:09:52.540
words or a new bag of words, averaging word vectors.

01:09:52.540 --> 01:09:56.995
It's just useful to try that on the task and see how it works,

01:09:56.995 --> 01:09:59.680
see what kinds of things it already gets right,

01:09:59.680 --> 01:10:01.825
what kind of things it gets wrong.

01:10:01.825 --> 01:10:03.880
You know, one possibility is you will find that

01:10:03.880 --> 01:10:07.135
a very simple model already does great on your task.

01:10:07.135 --> 01:10:08.575
If that's the case, um,

01:10:08.575 --> 01:10:10.270
you have too easy a task,

01:10:10.270 --> 01:10:16.460
and you probably need to find a task that's more challenging to work on. Um, yes.

01:10:16.460 --> 01:10:20.090
So after that, you'll then sort of think about what could be a good kind

01:10:20.090 --> 01:10:23.930
of neural network model that might do well, implement it,

01:10:23.930 --> 01:10:28.640
test it um, see what kind of errors that makes and you know,

01:10:28.640 --> 01:10:30.545
that's sort of if you've gotten that far,

01:10:30.545 --> 01:10:33.605
you're sort of in the right space for a class project.

01:10:33.605 --> 01:10:37.400
But, you know, it's sort of hoped that you could do more than that.

01:10:37.400 --> 01:10:39.935
But after you've seen the errors from the first version,

01:10:39.935 --> 01:10:43.865
you could think about how to make it better and come up with a better project,

01:10:43.865 --> 01:10:46.055
and so I would encourage everyone,

01:10:46.055 --> 01:10:48.680
you know, you really do want to look at the data, right?

01:10:48.680 --> 01:10:54.620
You don't just wanna be sort of having things and files and run and say "Okay, 0.71.

01:10:54.620 --> 01:10:57.370
Let me make some random change 0.70.

01:10:57.370 --> 01:11:00.235
Oh, that's not a good one," repeat over.

01:11:00.235 --> 01:11:04.330
You actually want to be sort of looking at your dataset in any way you can.

01:11:04.330 --> 01:11:06.760
It's good to visualize the dataset to understand what's

01:11:06.760 --> 01:11:09.500
important in it that you might be able to take advantage of,

01:11:09.500 --> 01:11:11.110
you want to be able to look at what kind of

01:11:11.110 --> 01:11:12.970
errors are being made because that might give you

01:11:12.970 --> 01:11:16.865
ideas of how you could put more stuff into the model that would do better.

01:11:16.865 --> 01:11:20.465
Um, you might wanna do some graphing of the effect of hyper-parameters,

01:11:20.465 --> 01:11:22.460
so you can kind of understand that better.

01:11:22.460 --> 01:11:24.370
And so, the hope is that you will try out

01:11:24.370 --> 01:11:27.250
some other kinds of models and make things better.

01:11:27.250 --> 01:11:29.525
And sort of one of the goals here is,

01:11:29.525 --> 01:11:34.085
it's good if you've sort of got a well-setup experimental setup,

01:11:34.085 --> 01:11:37.300
so you can easily turn around experiments because then you're just more

01:11:37.300 --> 01:11:41.855
likely to be able to try several things in the time available.

01:11:41.855 --> 01:11:45.395
Okay. Um, couple of other things I wanted to mention.

01:11:45.395 --> 01:11:49.615
Um, one is sort of different amounts of data.

01:11:49.615 --> 01:11:53.510
So, it's really, really important for all the stuff that we do,

01:11:53.510 --> 01:11:56.870
that we have different sets of data.

01:11:56.870 --> 01:11:58.635
So, we have trained data,

01:11:58.635 --> 01:12:00.425
we have dev test data,

01:12:00.425 --> 01:12:03.130
we have test data at least,

01:12:03.130 --> 01:12:05.540
and sometimes it's useful to have even,

01:12:05.540 --> 01:12:08.240
um, more data available.

01:12:08.240 --> 01:12:14.080
So, for many of the public datasets, they're already split into different subsets like this,

01:12:14.080 --> 01:12:15.095
but there are some that aren't.

01:12:15.095 --> 01:12:17.285
There are some that might only have a training set,

01:12:17.285 --> 01:12:19.000
and a test set.

01:12:19.000 --> 01:12:21.260
And what you don't want to do is think,

01:12:21.260 --> 01:12:23.500
"Oh, there's only a training set and a test set.

01:12:23.500 --> 01:12:26.180
Therefore I'll just run every time on the test set."

01:12:26.180 --> 01:12:29.890
That- that's a really invalid way to go about your research.

01:12:29.890 --> 01:12:30.990
So, if there aren't

01:12:30.990 --> 01:12:34.385
dev sets available or you need to do some more tuning,

01:12:34.385 --> 01:12:36.375
and you need some separate tuning data,

01:12:36.375 --> 01:12:39.460
you sort of have to, um,

01:12:39.460 --> 01:12:43.400
make it for yourself by splitting off some of the training data,

01:12:43.400 --> 01:12:47.775
and not using it for the basic training and using it for tuning,

01:12:47.775 --> 01:12:50.435
and fo- as dev data.

01:12:50.435 --> 01:12:52.530
Um, yes.

01:12:52.530 --> 01:12:56.490
So, to go on about that, um, more, more.

01:12:56.490 --> 01:13:02.675
So, the basic issue is this issue of fitting and overfitting to particular datasets.

01:13:02.675 --> 01:13:05.610
So, when we train a model, um,

01:13:05.610 --> 01:13:07.560
on some training data,

01:13:07.560 --> 01:13:10.460
we train it and the error rate goes down.

01:13:10.460 --> 01:13:15.900
And over time, we gradually overfit to the training data because we sort of

01:13:15.900 --> 01:13:21.820
pick up on our neural network f- facts about the particular training data items,

01:13:21.820 --> 01:13:24.030
and we just sort of start to learn them.

01:13:24.030 --> 01:13:25.790
Now in the old days,

01:13:25.790 --> 01:13:30.060
the fact that you overfit to the training data was seen as evil.

01:13:30.060 --> 01:13:32.130
In modern neural network think,

01:13:32.130 --> 01:13:35.630
we don't think it is evil what we overfit to the training data

01:13:35.630 --> 01:13:40.115
because all neural nets that are any good overfit to the training data,

01:13:40.115 --> 01:13:42.875
and we would be very sad if they didn't.

01:13:42.875 --> 01:13:44.660
I'll come back to that in a moment.

01:13:44.660 --> 01:13:47.565
But nevertheless, they're overfitting like crazy.

01:13:47.565 --> 01:13:52.920
So, what we, but and what we want to build is something that generalizes well.

01:13:52.920 --> 01:13:55.085
So, we have to have some separate data,

01:13:55.085 --> 01:13:56.815
that's our validation data,

01:13:56.815 --> 01:14:01.030
and say look at what performance looks like on the validation data.

01:14:01.030 --> 01:14:04.875
And commonly we find that training up until some point,

01:14:04.875 --> 01:14:08.500
improves our performance on separate validation data,

01:14:08.500 --> 01:14:11.050
and then we start to overfit to

01:14:11.050 --> 01:14:15.765
the training data in a way that our validation set performance gets worse.

01:14:15.765 --> 01:14:17.595
Um, and so, then,

01:14:17.595 --> 01:14:21.965
further training on the training data isn't useful because we're starting

01:14:21.965 --> 01:14:26.705
to build a model that generalizes worse when run on other data.

01:14:26.705 --> 01:14:28.810
But there's- the whole point here is,

01:14:28.810 --> 01:14:34.835
we can only do this experiment if our validation data is separate from our training data.

01:14:34.835 --> 01:14:37.910
If it's the same data or if it's overlapping data,

01:14:37.910 --> 01:14:39.950
we can't draw this graph.

01:14:39.950 --> 01:14:42.810
Um, and so, therefore, we can't do valid experiments.

01:14:42.810 --> 01:14:47.085
Um, now you might think, "Oh, well,

01:14:47.085 --> 01:14:49.040
maybe I can, um,

01:14:49.040 --> 01:14:52.175
do this and just use the test set of data."

01:14:52.175 --> 01:14:55.805
Um, but that's also invalid,

01:14:55.805 --> 01:14:58.920
and the reason why that's invalid is,

01:14:58.920 --> 01:15:00.835
as you do experiments,

01:15:00.835 --> 01:15:05.495
you also start slowly over fitting to your development data.

01:15:05.495 --> 01:15:11.560
So, the standard practice is you do a run and you get a score on the development data.

01:15:11.560 --> 01:15:13.145
You do a second run.

01:15:13.145 --> 01:15:15.040
You do worse on the development data,

01:15:15.040 --> 01:15:17.770
and so you throw that second model away.

01:15:17.770 --> 01:15:19.020
You do a third experiment.

01:15:19.020 --> 01:15:20.950
You do better on the development data,

01:15:20.950 --> 01:15:24.905
and so you keep that model and you repeat over 50 times.

01:15:24.905 --> 01:15:28.520
And while some of those subsequent models you keep,

01:15:28.520 --> 01:15:34.195
are genuinely better because you sort of worked out something good to do.

01:15:34.195 --> 01:15:38.885
But it turns out that some of those subsequent models only sort of just happened.

01:15:38.885 --> 01:15:42.985
You just got lucky and they happened to score better on the development data.

01:15:42.985 --> 01:15:46.905
And so, if you kind of keep repeating that process 60 or 100 times,

01:15:46.905 --> 01:15:50.570
you're also gradually [NOISE] overfitting on your development data,

01:15:50.570 --> 01:15:53.575
and you get unrealistically good dev scores.

01:15:53.575 --> 01:15:55.475
And so, that means two things.

01:15:55.475 --> 01:15:59.820
You know, if you want to be rigorous and do a huge amount of hyper-parameter exploration,

01:15:59.820 --> 01:16:02.830
it can be good to have a second development se- test set,

01:16:02.830 --> 01:16:05.660
so that you have one, that you haven't overfit as much.

01:16:05.660 --> 01:16:08.450
And if you want to have valid scores on te-

01:16:08.450 --> 01:16:12.595
on as to what is my actual performance on independent data,

01:16:12.595 --> 01:16:15.725
it's vital that you have separate test data that you are

01:16:15.725 --> 01:16:19.265
not using at all in this process, right?

01:16:19.265 --> 01:16:21.395
So, the ideal state is that,

01:16:21.395 --> 01:16:24.860
for your real test data, um,

01:16:24.860 --> 01:16:29.590
that you never used it at all until you've finished training your data, uh,

01:16:29.590 --> 01:16:34.060
training your model, and then you run your final model once on the test data,

01:16:34.060 --> 01:16:36.510
and you write up your paper and those are your results.

01:16:36.510 --> 01:16:39.495
Now, I will be honest and say the world usually isn't

01:16:39.495 --> 01:16:42.790
quite that perfect because after you've done that,

01:16:42.790 --> 01:16:44.960
you then go to sleep [NOISE] and wake up thinking.

01:16:44.960 --> 01:16:47.640
"I've got a fantastic idea of how to make my model better."

01:16:47.640 --> 01:16:49.520
and you run off and implement that,

01:16:49.520 --> 01:16:51.700
and it works great on the dev data,

01:16:51.700 --> 01:16:55.385
and then for you, run it on the test data again and the numbers go up.

01:16:55.385 --> 01:16:57.640
Um, sort of everybody does that.

01:16:57.640 --> 01:16:59.035
Um, and you know,

01:16:59.035 --> 01:17:01.295
in modicum it's okay,

01:17:01.295 --> 01:17:06.325
you know, if that means you occasionally run on the test data it's not so bad, um,

01:17:06.325 --> 01:17:10.550
but you really need to be aware of the slippery slope because,

01:17:10.550 --> 01:17:13.560
if you then start falling into, "I've got a new model.

01:17:13.560 --> 01:17:14.885
Let me try that one on the test data.

01:17:14.885 --> 01:17:16.925
I've got a new model. Let me try this one on the test data."

01:17:16.925 --> 01:17:20.130
Then you're just sort of overfitting to the test data,

01:17:20.130 --> 01:17:23.100
and getting an unrealistically high score.

01:17:23.100 --> 01:17:27.605
And that's precisely why a lot of the competitions like Kaggle competitions,

01:17:27.605 --> 01:17:31.680
have a secret test dataset that you can't run on.

01:17:31.680 --> 01:17:33.615
So, that they can do a genuine,

01:17:33.615 --> 01:17:37.150
independent test on the actual test data.

01:17:37.150 --> 01:17:42.550
Okay. Um, let's see, um, a couple more minutes.

01:17:42.550 --> 01:17:46.515
So, yeah, getting your neural network to train.

01:17:46.515 --> 01:17:49.135
Um, my two messages are, you know,

01:17:49.135 --> 01:17:52.425
first of all, you should start with a positive attitude.

01:17:52.425 --> 01:17:54.565
Neural networks want to learn.

01:17:54.565 --> 01:17:55.955
If they're not learning,

01:17:55.955 --> 01:17:58.500
you're doing something to stop them from learning.

01:17:58.500 --> 01:18:00.070
And so, you should just stop that,

01:18:00.070 --> 01:18:02.260
and they will learn because they want to learn.

01:18:02.260 --> 01:18:03.935
They're just like little children.

01:18:03.935 --> 01:18:09.790
Um, but, if the follow up to that is the grim reality that there are just tons

01:18:09.790 --> 01:18:11.910
of things you can do that will cause

01:18:11.910 --> 01:18:15.710
your neural networks not to learn very well or at all,

01:18:15.710 --> 01:18:17.820
and this is the frustrating part of

01:18:17.820 --> 01:18:21.605
this whole field because you know, it's not like a compile error.

01:18:21.605 --> 01:18:25.335
It can just be hard to find and fix them.

01:18:25.335 --> 01:18:27.715
And, you know, it is just really

01:18:27.715 --> 01:18:32.015
standard that you spend more time dealing with trying to find,

01:18:32.015 --> 01:18:35.225
and fix why it doesn't work well and getting it to work well than

01:18:35.225 --> 01:18:39.265
you- than the time you spent writing the code for your model.

01:18:39.265 --> 01:18:43.734
So, remember to budget for that when you're doing your final project,

01:18:43.734 --> 01:18:48.470
it just won't work if you finish the code a day or two before the deadline.

01:18:48.470 --> 01:18:51.990
Um, so, you need to work out what those things are,

01:18:51.990 --> 01:18:54.970
"That can be hard," but you know experience,

01:18:54.970 --> 01:18:57.260
experimental care, rules of thumb help.

01:18:57.260 --> 01:18:59.750
So, there are just lots of things that are important.

01:18:59.750 --> 01:19:02.480
So, you know, your learning rates are important.

01:19:02.480 --> 01:19:05.775
If your learning rates are way too high, things won't learn.

01:19:05.775 --> 01:19:07.960
If your learning rates are way too low,

01:19:07.960 --> 01:19:10.655
they will learn very slowly and badly.

01:19:10.655 --> 01:19:13.270
Um, initialization makes a difference.

01:19:13.270 --> 01:19:19.040
Having good initialization often determines how well neural networks, um, learn.

01:19:19.040 --> 01:19:23.435
Um, I have a separate slide here that I probably haven't got time to go

01:19:23.435 --> 01:19:28.225
through all of on sort of for sequence [NOISE] models,

01:19:28.225 --> 01:19:31.950
some of the tips of what people normally think are

01:19:31.950 --> 01:19:35.735
good ways to get those models, um, working.

01:19:35.735 --> 01:19:38.415
But I'll just say this one last thing.

01:19:38.415 --> 01:19:41.850
Um, I think the strategy that you really want to

01:19:41.850 --> 01:19:45.920
take is to work incrementally and build up slowly.

01:19:45.920 --> 01:19:47.490
It just doesn't work to think,

01:19:47.490 --> 01:19:49.534
"Oh I've got the mother of all models,

01:19:49.534 --> 01:19:51.660
and build this enormously complex thing,

01:19:51.660 --> 01:19:53.000
and then run it on the data,

01:19:53.000 --> 01:19:54.784
and it crashes and burns."

01:19:54.784 --> 01:19:57.455
You have no idea what to do at that point,

01:19:57.455 --> 01:20:00.645
that the only good way is to sort of build up slowly.

01:20:00.645 --> 01:20:02.935
So [NOISE] start with a very simple model,

01:20:02.935 --> 01:20:04.300
get it to work,

01:20:04.300 --> 01:20:05.820
add your bells and whistles,

01:20:05.820 --> 01:20:07.490
extra layers and so on.

01:20:07.490 --> 01:20:09.585
Get them to work or abandon them.

01:20:09.585 --> 01:20:14.230
And so, try and proceed from one working model to another as much as possible.

01:20:14.230 --> 01:20:18.975
One of- another way that you can start small and build up is with data.

01:20:18.975 --> 01:20:22.580
The easiest way to see bugs and problems in your model,

01:20:22.580 --> 01:20:25.610
is with the minutest possible amount of data.

01:20:25.610 --> 01:20:29.035
So, start with a dataset of eight items.

01:20:29.035 --> 01:20:32.660
Sometimes it's even best if those eight items are ones that are

01:20:32.660 --> 01:20:34.925
artificial data that you designed yourself

01:20:34.925 --> 01:20:37.565
because then you can often more easily see problems,

01:20:37.565 --> 01:20:38.805
and what's going wrong.

01:20:38.805 --> 01:20:40.560
So, you should train on that,

01:20:40.560 --> 01:20:42.420
um, because it's only eight items,

01:20:42.420 --> 01:20:44.119
training will only take seconds,

01:20:44.119 --> 01:20:47.205
and that's really, really useful for being able to iterate quickly.

01:20:47.205 --> 01:20:49.560
And you know, if you can't have your model get

01:20:49.560 --> 01:20:55.055
100 percent accuracy on training and testing on those eight examples,

01:20:55.055 --> 01:20:59.734
well, you know, either the model is woefully under powered or the model is broken,

01:20:59.734 --> 01:21:02.900
and you've got clear things to do right there.

01:21:02.900 --> 01:21:06.395
Um, when you go to a bigger model, um,

01:21:06.395 --> 01:21:10.115
the standard practice with modern neural networks is,

01:21:10.115 --> 01:21:12.330
you want to train your models.

01:21:12.330 --> 01:21:16.240
You want models that can overfit massively on the training set.

01:21:16.240 --> 01:21:19.565
So, in general, your models should still be getting

01:21:19.565 --> 01:21:23.375
close to 100 percent accuracy on the training set after you've

01:21:23.375 --> 01:21:27.160
trained it for a long time because powerful neural network models are

01:21:27.160 --> 01:21:31.090
just really good at over-fitting to, and memorizing data.

01:21:31.090 --> 01:21:33.455
Um, if that's not the case well, you know,

01:21:33.455 --> 01:21:34.805
maybe you want a bigger model.

01:21:34.805 --> 01:21:38.165
Maybe you want to have higher hidden dimensions or

01:21:38.165 --> 01:21:41.910
add an extra layer to your neural network or something like that.

01:21:41.910 --> 01:21:44.925
You shouldn't be scared of overfitting on the training data.

01:21:44.925 --> 01:21:47.180
But once you've proved you can do that,

01:21:47.180 --> 01:21:50.555
you then do want a model that also generalizes well.

01:21:50.555 --> 01:21:55.415
And so, normally the way that you're addressing that is then by regularizing the model,

01:21:55.415 --> 01:21:57.845
and there are different ways to regularize your model,

01:21:57.845 --> 01:22:01.295
but we talked about in the assignment, doing dropout.

01:22:01.295 --> 01:22:03.755
I mean, using generous dropout is

01:22:03.755 --> 01:22:07.975
one very common and effective strategy for regularizing your models.

01:22:07.975 --> 01:22:11.735
And so, then you've, what you want to be doing is regularizing

01:22:11.735 --> 01:22:16.265
your model enough that the curve no longer looks like this,

01:22:16.265 --> 01:22:21.095
but instead that your validation performance kind of levels out,

01:22:21.095 --> 01:22:23.510
but doesn't start ramping back up again,

01:22:23.510 --> 01:22:26.820
and that's then a sort of a sign of a well regularized model.

01:22:26.820 --> 01:22:29.210
Okay. I will stop there,

01:22:29.210 --> 01:22:33.310
and then we'll come back to the question-answering project on Thursday.

